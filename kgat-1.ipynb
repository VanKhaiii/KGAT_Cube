{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7990392,"sourceType":"datasetVersion","datasetId":4703931}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T13:55:27.058921Z","iopub.execute_input":"2024-03-31T13:55:27.059279Z","iopub.status.idle":"2024-03-31T13:55:27.994323Z","shell.execute_reply.started":"2024-03-31T13:55:27.059242Z","shell.execute_reply":"2024-03-31T13:55:27.993383Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/d/khaivan0906/mooccubex/test.txt\n/kaggle/input/d/khaivan0906/mooccubex/kg_final.txt\n/kaggle/input/d/khaivan0906/mooccubex/train.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gitpython","metadata":{"execution":{"iopub.status.busy":"2024-03-31T13:55:27.996280Z","iopub.execute_input":"2024-03-31T13:55:27.997073Z","iopub.status.idle":"2024-03-31T13:55:41.355895Z","shell.execute_reply.started":"2024-03-31T13:55:27.997036Z","shell.execute_reply":"2024-03-31T13:55:41.354756Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython in /opt/conda/lib/python3.10/site-packages (3.1.41)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython) (4.0.11)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import git\ngit.Repo.clone_from('https://github.com/VanKhaiii/KGAT_Cube.git', '/kaggle/working/sample')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T13:55:41.357358Z","iopub.execute_input":"2024-03-31T13:55:41.357672Z","iopub.status.idle":"2024-03-31T13:55:42.022558Z","shell.execute_reply.started":"2024-03-31T13:55:41.357646Z","shell.execute_reply":"2024-03-31T13:55:42.021652Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<git.repo.base.Repo '/kaggle/working/sample/.git'>"},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-03-31T13:55:42.024391Z","iopub.execute_input":"2024-03-31T13:55:42.024669Z","iopub.status.idle":"2024-03-31T13:55:42.030819Z","shell.execute_reply.started":"2024-03-31T13:55:42.024645Z","shell.execute_reply":"2024-03-31T13:55:42.029936Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**KGAT**","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/sample/KGAT-pytorch/main_kgat.py --data_dir \"/kaggle/input/\" \\\n                    --data_name mooccubex \\\n                    --use_pretrain 0 \\\n                    --n_epoch 10 \\\n                    --cf_batch_size 1024 \\\n                    --kg_batch_size 2048 \\\n                    --test_batch_size 256 \\\n                    --cf_print_every 50 \\\n                    --kg_print_every 50 \\\n                    --evaluate_every 1","metadata":{"execution":{"iopub.status.busy":"2024-03-31T13:57:02.754320Z","iopub.execute_input":"2024-03-31T13:57:02.755075Z","iopub.status.idle":"2024-03-31T21:44:03.991354Z","shell.execute_reply.started":"2024-03-31T13:57:02.755040Z","shell.execute_reply":"2024-03-31T21:44:03.990211Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"All logs will be saved to trained_model/KGAT/mooccubex/embed-dim64_relation-dim64_random-walk_bi-interaction_64-32-16_lr0.0001_pretrain0/log1.log\n2024-03-31 13:57:06,508 - root - INFO - Namespace(seed=2019, data_name='mooccubex', data_dir='/kaggle/input/', use_pretrain=0, pretrain_embedding_dir='datasets/pretrain/', pretrain_model_path='trained_model/model.pth', cf_batch_size=1024, kg_batch_size=2048, test_batch_size=256, embed_dim=64, relation_dim=64, laplacian_type='random-walk', aggregation_type='bi-interaction', conv_dim_list='[64, 32, 16]', mess_dropout='[0.1, 0.1, 0.1]', kg_l2loss_lambda=1e-05, cf_l2loss_lambda=1e-05, lr=0.0001, n_epoch=10, stopping_steps=10, cf_print_every=50, kg_print_every=50, evaluate_every=1, Ks='[20, 40, 60, 80, 100]', save_dir='trained_model/KGAT/mooccubex/embed-dim64_relation-dim64_random-walk_bi-interaction_64-32-16_lr0.0001_pretrain0/')\n2024-03-31 14:05:08,306 - root - INFO - n_users:           182153\n2024-03-31 14:05:08,306 - root - INFO - n_items:           2947\n2024-03-31 14:05:08,306 - root - INFO - n_entities:        4719\n2024-03-31 14:05:08,307 - root - INFO - n_users_entities:  186872\n2024-03-31 14:05:08,307 - root - INFO - n_relations:       10\n2024-03-31 14:05:08,308 - root - INFO - n_h_list:          11145170\n2024-03-31 14:05:08,308 - root - INFO - n_t_list:          11145170\n2024-03-31 14:05:08,308 - root - INFO - n_r_list:          11145170\n2024-03-31 14:05:08,308 - root - INFO - n_cf_train:        5539469\n2024-03-31 14:05:08,308 - root - INFO - n_cf_test:         710398\n2024-03-31 14:05:08,309 - root - INFO - n_kg_train:        11145170\n/kaggle/working/sample/KGAT-pytorch/data_loader/loader_kgat.py:119: RuntimeWarning: divide by zero encountered in power\n  d_inv = np.power(rowsum, -1.0).flatten()\n/kaggle/working/sample/KGAT-pytorch/data_loader/loader_kgat.py:92: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:605.)\n  return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n/kaggle/working/sample/KGAT-pytorch/model/KGAT.py:111: UserWarning: torch.sparse.SparseTensor(shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(shape, dtype=, device=). (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:634.)\n  self.A_in = nn.Parameter(torch.sparse.FloatTensor(self.n_users + self.n_entities, self.n_users + self.n_entities))\n2024-03-31 14:05:16,727 - root - INFO - KGAT(\n  (entity_user_embed): Embedding(186872, 64)\n  (relation_embed): Embedding(10, 64)\n  (aggregator_layers): ModuleList(\n    (0): Aggregator(\n      (message_dropout): Dropout(p=0.1, inplace=False)\n      (activation): LeakyReLU(negative_slope=0.01)\n      (linear1): Linear(in_features=64, out_features=64, bias=True)\n      (linear2): Linear(in_features=64, out_features=64, bias=True)\n    )\n    (1): Aggregator(\n      (message_dropout): Dropout(p=0.1, inplace=False)\n      (activation): LeakyReLU(negative_slope=0.01)\n      (linear1): Linear(in_features=64, out_features=32, bias=True)\n      (linear2): Linear(in_features=64, out_features=32, bias=True)\n    )\n    (2): Aggregator(\n      (message_dropout): Dropout(p=0.1, inplace=False)\n      (activation): LeakyReLU(negative_slope=0.01)\n      (linear1): Linear(in_features=32, out_features=16, bias=True)\n      (linear2): Linear(in_features=32, out_features=16, bias=True)\n    )\n  )\n)\n2024-03-31 14:05:17,992 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.\n2024-03-31 14:05:43,043 - root - INFO - CF Training: Epoch 0001 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.6939 | Iter Mean Loss 0.6973\n2024-03-31 14:06:05,249 - root - INFO - CF Training: Epoch 0001 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.6653 | Iter Mean Loss 0.6922\n2024-03-31 14:06:27,411 - root - INFO - CF Training: Epoch 0001 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.5278 | Iter Mean Loss 0.6641\n2024-03-31 14:06:49,599 - root - INFO - CF Training: Epoch 0001 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.4674 | Iter Mean Loss 0.6201\n2024-03-31 14:07:11,817 - root - INFO - CF Training: Epoch 0001 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.4472 | Iter Mean Loss 0.5847\n2024-03-31 14:07:34,003 - root - INFO - CF Training: Epoch 0001 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.4200 | Iter Mean Loss 0.5577\n2024-03-31 14:07:56,179 - root - INFO - CF Training: Epoch 0001 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.3986 | Iter Mean Loss 0.5362\n2024-03-31 14:08:18,377 - root - INFO - CF Training: Epoch 0001 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.3897 | Iter Mean Loss 0.5186\n2024-03-31 14:08:40,556 - root - INFO - CF Training: Epoch 0001 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.3812 | Iter Mean Loss 0.5041\n2024-03-31 14:09:02,739 - root - INFO - CF Training: Epoch 0001 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.3712 | Iter Mean Loss 0.4920\n2024-03-31 14:09:24,986 - root - INFO - CF Training: Epoch 0001 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.3810 | Iter Mean Loss 0.4817\n2024-03-31 14:09:47,194 - root - INFO - CF Training: Epoch 0001 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.3822 | Iter Mean Loss 0.4727\n2024-03-31 14:10:09,398 - root - INFO - CF Training: Epoch 0001 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.3631 | Iter Mean Loss 0.4647\n2024-03-31 14:10:31,632 - root - INFO - CF Training: Epoch 0001 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.3631 | Iter Mean Loss 0.4576\n2024-03-31 14:10:53,898 - root - INFO - CF Training: Epoch 0001 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.3552 | Iter Mean Loss 0.4512\n2024-03-31 14:11:16,298 - root - INFO - CF Training: Epoch 0001 Iter 0800 / 5410 | Time 0.5s | Iter Loss 0.3296 | Iter Mean Loss 0.4452\n2024-03-31 14:11:38,632 - root - INFO - CF Training: Epoch 0001 Iter 0850 / 5410 | Time 0.5s | Iter Loss 0.3462 | Iter Mean Loss 0.4398\n2024-03-31 14:12:00,942 - root - INFO - CF Training: Epoch 0001 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.3545 | Iter Mean Loss 0.4347\n2024-03-31 14:12:23,254 - root - INFO - CF Training: Epoch 0001 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.3365 | Iter Mean Loss 0.4298\n2024-03-31 14:12:45,568 - root - INFO - CF Training: Epoch 0001 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.3321 | Iter Mean Loss 0.4252\n2024-03-31 14:13:07,777 - root - INFO - CF Training: Epoch 0001 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2971 | Iter Mean Loss 0.4210\n2024-03-31 14:13:29,979 - root - INFO - CF Training: Epoch 0001 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.3258 | Iter Mean Loss 0.4170\n2024-03-31 14:13:52,206 - root - INFO - CF Training: Epoch 0001 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.3173 | Iter Mean Loss 0.4131\n2024-03-31 14:14:14,409 - root - INFO - CF Training: Epoch 0001 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.3164 | Iter Mean Loss 0.4094\n2024-03-31 14:14:36,596 - root - INFO - CF Training: Epoch 0001 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.3176 | Iter Mean Loss 0.4061\n2024-03-31 14:14:58,777 - root - INFO - CF Training: Epoch 0001 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.3064 | Iter Mean Loss 0.4028\n2024-03-31 14:15:21,003 - root - INFO - CF Training: Epoch 0001 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.3410 | Iter Mean Loss 0.3997\n2024-03-31 14:15:43,192 - root - INFO - CF Training: Epoch 0001 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.3046 | Iter Mean Loss 0.3968\n2024-03-31 14:16:05,467 - root - INFO - CF Training: Epoch 0001 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.3237 | Iter Mean Loss 0.3941\n2024-03-31 14:16:27,756 - root - INFO - CF Training: Epoch 0001 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.3189 | Iter Mean Loss 0.3916\n2024-03-31 14:16:50,030 - root - INFO - CF Training: Epoch 0001 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.3207 | Iter Mean Loss 0.3891\n2024-03-31 14:17:12,304 - root - INFO - CF Training: Epoch 0001 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.3118 | Iter Mean Loss 0.3868\n2024-03-31 14:17:34,596 - root - INFO - CF Training: Epoch 0001 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.3307 | Iter Mean Loss 0.3845\n2024-03-31 14:17:56,852 - root - INFO - CF Training: Epoch 0001 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.3111 | Iter Mean Loss 0.3824\n2024-03-31 14:18:19,062 - root - INFO - CF Training: Epoch 0001 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.3102 | Iter Mean Loss 0.3803\n2024-03-31 14:18:41,308 - root - INFO - CF Training: Epoch 0001 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.3185 | Iter Mean Loss 0.3783\n2024-03-31 14:19:03,524 - root - INFO - CF Training: Epoch 0001 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2991 | Iter Mean Loss 0.3762\n2024-03-31 14:19:25,724 - root - INFO - CF Training: Epoch 0001 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.3075 | Iter Mean Loss 0.3742\n2024-03-31 14:19:47,950 - root - INFO - CF Training: Epoch 0001 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2970 | Iter Mean Loss 0.3722\n2024-03-31 14:20:10,169 - root - INFO - CF Training: Epoch 0001 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2909 | Iter Mean Loss 0.3703\n2024-03-31 14:20:32,355 - root - INFO - CF Training: Epoch 0001 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2959 | Iter Mean Loss 0.3685\n2024-03-31 14:20:54,546 - root - INFO - CF Training: Epoch 0001 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2937 | Iter Mean Loss 0.3667\n2024-03-31 14:21:16,739 - root - INFO - CF Training: Epoch 0001 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2864 | Iter Mean Loss 0.3650\n2024-03-31 14:21:38,908 - root - INFO - CF Training: Epoch 0001 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2851 | Iter Mean Loss 0.3633\n2024-03-31 14:22:01,057 - root - INFO - CF Training: Epoch 0001 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2784 | Iter Mean Loss 0.3617\n2024-03-31 14:22:23,229 - root - INFO - CF Training: Epoch 0001 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.3066 | Iter Mean Loss 0.3602\n2024-03-31 14:22:45,424 - root - INFO - CF Training: Epoch 0001 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2787 | Iter Mean Loss 0.3587\n2024-03-31 14:23:07,584 - root - INFO - CF Training: Epoch 0001 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2958 | Iter Mean Loss 0.3572\n2024-03-31 14:23:29,737 - root - INFO - CF Training: Epoch 0001 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2781 | Iter Mean Loss 0.3558\n2024-03-31 14:23:51,891 - root - INFO - CF Training: Epoch 0001 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2673 | Iter Mean Loss 0.3544\n2024-03-31 14:24:14,057 - root - INFO - CF Training: Epoch 0001 Iter 2550 / 5410 | Time 0.5s | Iter Loss 0.2810 | Iter Mean Loss 0.3530\n2024-03-31 14:24:36,185 - root - INFO - CF Training: Epoch 0001 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.2844 | Iter Mean Loss 0.3518\n2024-03-31 14:24:58,290 - root - INFO - CF Training: Epoch 0001 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2903 | Iter Mean Loss 0.3506\n2024-03-31 14:25:20,458 - root - INFO - CF Training: Epoch 0001 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2754 | Iter Mean Loss 0.3493\n2024-03-31 14:25:42,623 - root - INFO - CF Training: Epoch 0001 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.2979 | Iter Mean Loss 0.3480\n2024-03-31 14:26:04,776 - root - INFO - CF Training: Epoch 0001 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2923 | Iter Mean Loss 0.3469\n2024-03-31 14:26:26,940 - root - INFO - CF Training: Epoch 0001 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2735 | Iter Mean Loss 0.3457\n2024-03-31 14:26:49,115 - root - INFO - CF Training: Epoch 0001 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2801 | Iter Mean Loss 0.3446\n2024-03-31 14:27:11,271 - root - INFO - CF Training: Epoch 0001 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2893 | Iter Mean Loss 0.3435\n2024-03-31 14:27:33,427 - root - INFO - CF Training: Epoch 0001 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2637 | Iter Mean Loss 0.3423\n2024-03-31 14:27:55,591 - root - INFO - CF Training: Epoch 0001 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2525 | Iter Mean Loss 0.3412\n2024-03-31 14:28:17,776 - root - INFO - CF Training: Epoch 0001 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2785 | Iter Mean Loss 0.3402\n2024-03-31 14:28:39,963 - root - INFO - CF Training: Epoch 0001 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2717 | Iter Mean Loss 0.3391\n2024-03-31 14:29:02,226 - root - INFO - CF Training: Epoch 0001 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2907 | Iter Mean Loss 0.3381\n2024-03-31 14:29:24,422 - root - INFO - CF Training: Epoch 0001 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2948 | Iter Mean Loss 0.3371\n2024-03-31 14:29:46,610 - root - INFO - CF Training: Epoch 0001 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2702 | Iter Mean Loss 0.3361\n2024-03-31 14:30:08,825 - root - INFO - CF Training: Epoch 0001 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2756 | Iter Mean Loss 0.3351\n2024-03-31 14:30:31,068 - root - INFO - CF Training: Epoch 0001 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2612 | Iter Mean Loss 0.3341\n2024-03-31 14:30:53,271 - root - INFO - CF Training: Epoch 0001 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2824 | Iter Mean Loss 0.3332\n2024-03-31 14:31:15,467 - root - INFO - CF Training: Epoch 0001 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2546 | Iter Mean Loss 0.3322\n2024-03-31 14:31:37,687 - root - INFO - CF Training: Epoch 0001 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2547 | Iter Mean Loss 0.3313\n2024-03-31 14:31:59,896 - root - INFO - CF Training: Epoch 0001 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2691 | Iter Mean Loss 0.3304\n2024-03-31 14:32:22,121 - root - INFO - CF Training: Epoch 0001 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2607 | Iter Mean Loss 0.3294\n2024-03-31 14:32:44,315 - root - INFO - CF Training: Epoch 0001 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2876 | Iter Mean Loss 0.3285\n2024-03-31 14:33:06,526 - root - INFO - CF Training: Epoch 0001 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2584 | Iter Mean Loss 0.3277\n2024-03-31 14:33:28,747 - root - INFO - CF Training: Epoch 0001 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2471 | Iter Mean Loss 0.3268\n2024-03-31 14:33:50,979 - root - INFO - CF Training: Epoch 0001 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2385 | Iter Mean Loss 0.3260\n2024-03-31 14:34:13,182 - root - INFO - CF Training: Epoch 0001 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2583 | Iter Mean Loss 0.3251\n2024-03-31 14:34:35,353 - root - INFO - CF Training: Epoch 0001 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2551 | Iter Mean Loss 0.3243\n2024-03-31 14:34:57,469 - root - INFO - CF Training: Epoch 0001 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2315 | Iter Mean Loss 0.3234\n2024-03-31 14:35:19,573 - root - INFO - CF Training: Epoch 0001 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2560 | Iter Mean Loss 0.3226\n2024-03-31 14:35:41,684 - root - INFO - CF Training: Epoch 0001 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2585 | Iter Mean Loss 0.3218\n2024-03-31 14:36:03,832 - root - INFO - CF Training: Epoch 0001 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2523 | Iter Mean Loss 0.3210\n2024-03-31 14:36:26,033 - root - INFO - CF Training: Epoch 0001 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.2578 | Iter Mean Loss 0.3202\n2024-03-31 14:36:48,241 - root - INFO - CF Training: Epoch 0001 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.2656 | Iter Mean Loss 0.3194\n2024-03-31 14:37:10,338 - root - INFO - CF Training: Epoch 0001 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2529 | Iter Mean Loss 0.3187\n2024-03-31 14:37:32,487 - root - INFO - CF Training: Epoch 0001 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2522 | Iter Mean Loss 0.3179\n2024-03-31 14:37:54,584 - root - INFO - CF Training: Epoch 0001 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2514 | Iter Mean Loss 0.3172\n2024-03-31 14:38:16,822 - root - INFO - CF Training: Epoch 0001 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2481 | Iter Mean Loss 0.3165\n2024-03-31 14:38:39,117 - root - INFO - CF Training: Epoch 0001 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2468 | Iter Mean Loss 0.3157\n2024-03-31 14:39:01,438 - root - INFO - CF Training: Epoch 0001 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.2533 | Iter Mean Loss 0.3150\n2024-03-31 14:39:23,777 - root - INFO - CF Training: Epoch 0001 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2321 | Iter Mean Loss 0.3143\n2024-03-31 14:39:46,072 - root - INFO - CF Training: Epoch 0001 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2332 | Iter Mean Loss 0.3136\n2024-03-31 14:40:08,348 - root - INFO - CF Training: Epoch 0001 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2580 | Iter Mean Loss 0.3129\n2024-03-31 14:40:30,503 - root - INFO - CF Training: Epoch 0001 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2699 | Iter Mean Loss 0.3123\n2024-03-31 14:40:52,671 - root - INFO - CF Training: Epoch 0001 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.2422 | Iter Mean Loss 0.3116\n2024-03-31 14:41:14,815 - root - INFO - CF Training: Epoch 0001 Iter 4850 / 5410 | Time 0.5s | Iter Loss 0.2589 | Iter Mean Loss 0.3110\n2024-03-31 14:41:36,944 - root - INFO - CF Training: Epoch 0001 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.2518 | Iter Mean Loss 0.3104\n2024-03-31 14:41:59,094 - root - INFO - CF Training: Epoch 0001 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2474 | Iter Mean Loss 0.3098\n2024-03-31 14:42:21,270 - root - INFO - CF Training: Epoch 0001 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2262 | Iter Mean Loss 0.3091\n2024-03-31 14:42:43,473 - root - INFO - CF Training: Epoch 0001 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.2365 | Iter Mean Loss 0.3085\n2024-03-31 14:43:05,725 - root - INFO - CF Training: Epoch 0001 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2408 | Iter Mean Loss 0.3079\n2024-03-31 14:43:27,964 - root - INFO - CF Training: Epoch 0001 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2319 | Iter Mean Loss 0.3073\n2024-03-31 14:43:50,214 - root - INFO - CF Training: Epoch 0001 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2373 | Iter Mean Loss 0.3068\n2024-03-31 14:44:12,481 - root - INFO - CF Training: Epoch 0001 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2413 | Iter Mean Loss 0.3062\n2024-03-31 14:44:34,798 - root - INFO - CF Training: Epoch 0001 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2482 | Iter Mean Loss 0.3056\n2024-03-31 14:44:57,084 - root - INFO - CF Training: Epoch 0001 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2553 | Iter Mean Loss 0.3050\n2024-03-31 14:45:19,400 - root - INFO - CF Training: Epoch 0001 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2649 | Iter Mean Loss 0.3045\n2024-03-31 14:45:23,863 - root - INFO - CF Training: Epoch 0001 Total Iter 5410 | Total Time 2404.0s | Iter Mean Loss 0.3044\n2024-03-31 14:45:29,597 - root - INFO - KG Training: Epoch 0001 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.6262 | Iter Mean Loss 0.6611\n2024-03-31 14:45:35,318 - root - INFO - KG Training: Epoch 0001 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.5501 | Iter Mean Loss 0.6256\n2024-03-31 14:45:41,151 - root - INFO - KG Training: Epoch 0001 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.4686 | Iter Mean Loss 0.5862\n2024-03-31 14:45:46,785 - root - INFO - KG Training: Epoch 0001 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.3804 | Iter Mean Loss 0.5455\n2024-03-31 14:45:52,459 - root - INFO - KG Training: Epoch 0001 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.3176 | Iter Mean Loss 0.5060\n2024-03-31 14:45:58,094 - root - INFO - KG Training: Epoch 0001 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.2632 | Iter Mean Loss 0.4699\n2024-03-31 14:46:03,780 - root - INFO - KG Training: Epoch 0001 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.2262 | Iter Mean Loss 0.4371\n2024-03-31 14:46:09,524 - root - INFO - KG Training: Epoch 0001 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.1922 | Iter Mean Loss 0.4079\n2024-03-31 14:46:15,298 - root - INFO - KG Training: Epoch 0001 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.1642 | Iter Mean Loss 0.3819\n2024-03-31 14:46:20,993 - root - INFO - KG Training: Epoch 0001 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.1455 | Iter Mean Loss 0.3588\n2024-03-31 14:46:26,632 - root - INFO - KG Training: Epoch 0001 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.1220 | Iter Mean Loss 0.3383\n2024-03-31 14:46:32,264 - root - INFO - KG Training: Epoch 0001 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.1138 | Iter Mean Loss 0.3199\n2024-03-31 14:46:37,992 - root - INFO - KG Training: Epoch 0001 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0974 | Iter Mean Loss 0.3033\n2024-03-31 14:46:43,785 - root - INFO - KG Training: Epoch 0001 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0847 | Iter Mean Loss 0.2884\n2024-03-31 14:46:49,418 - root - INFO - KG Training: Epoch 0001 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0769 | Iter Mean Loss 0.2749\n2024-03-31 14:46:55,007 - root - INFO - KG Training: Epoch 0001 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0731 | Iter Mean Loss 0.2625\n2024-03-31 14:47:00,638 - root - INFO - KG Training: Epoch 0001 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0646 | Iter Mean Loss 0.2512\n2024-03-31 14:47:06,237 - root - INFO - KG Training: Epoch 0001 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0612 | Iter Mean Loss 0.2409\n2024-03-31 14:47:11,826 - root - INFO - KG Training: Epoch 0001 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0620 | Iter Mean Loss 0.2314\n2024-03-31 14:47:17,514 - root - INFO - KG Training: Epoch 0001 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0545 | Iter Mean Loss 0.2227\n2024-03-31 14:47:23,125 - root - INFO - KG Training: Epoch 0001 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0483 | Iter Mean Loss 0.2146\n2024-03-31 14:47:28,784 - root - INFO - KG Training: Epoch 0001 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0509 | Iter Mean Loss 0.2070\n2024-03-31 14:47:34,397 - root - INFO - KG Training: Epoch 0001 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0476 | Iter Mean Loss 0.2000\n2024-03-31 14:47:40,012 - root - INFO - KG Training: Epoch 0001 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0405 | Iter Mean Loss 0.1935\n2024-03-31 14:47:45,820 - root - INFO - KG Training: Epoch 0001 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0386 | Iter Mean Loss 0.1874\n2024-03-31 14:47:51,444 - root - INFO - KG Training: Epoch 0001 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0354 | Iter Mean Loss 0.1817\n2024-03-31 14:47:57,006 - root - INFO - KG Training: Epoch 0001 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0346 | Iter Mean Loss 0.1763\n2024-03-31 14:48:02,591 - root - INFO - KG Training: Epoch 0001 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0319 | Iter Mean Loss 0.1713\n2024-03-31 14:48:08,209 - root - INFO - KG Training: Epoch 0001 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0334 | Iter Mean Loss 0.1665\n2024-03-31 14:48:14,020 - root - INFO - KG Training: Epoch 0001 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0320 | Iter Mean Loss 0.1620\n2024-03-31 14:48:19,740 - root - INFO - KG Training: Epoch 0001 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0311 | Iter Mean Loss 0.1578\n2024-03-31 14:48:25,449 - root - INFO - KG Training: Epoch 0001 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0308 | Iter Mean Loss 0.1538\n2024-03-31 14:48:31,035 - root - INFO - KG Training: Epoch 0001 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0309 | Iter Mean Loss 0.1500\n2024-03-31 14:48:36,794 - root - INFO - KG Training: Epoch 0001 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0262 | Iter Mean Loss 0.1464\n2024-03-31 14:48:42,571 - root - INFO - KG Training: Epoch 0001 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0281 | Iter Mean Loss 0.1429\n2024-03-31 14:48:48,346 - root - INFO - KG Training: Epoch 0001 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0263 | Iter Mean Loss 0.1397\n2024-03-31 14:48:54,045 - root - INFO - KG Training: Epoch 0001 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0219 | Iter Mean Loss 0.1366\n2024-03-31 14:48:59,657 - root - INFO - KG Training: Epoch 0001 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0206 | Iter Mean Loss 0.1336\n2024-03-31 14:49:05,323 - root - INFO - KG Training: Epoch 0001 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0202 | Iter Mean Loss 0.1308\n2024-03-31 14:49:10,911 - root - INFO - KG Training: Epoch 0001 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0204 | Iter Mean Loss 0.1281\n2024-03-31 14:49:16,615 - root - INFO - KG Training: Epoch 0001 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0246 | Iter Mean Loss 0.1255\n2024-03-31 14:49:22,266 - root - INFO - KG Training: Epoch 0001 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0243 | Iter Mean Loss 0.1231\n2024-03-31 14:49:27,904 - root - INFO - KG Training: Epoch 0001 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0219 | Iter Mean Loss 0.1207\n2024-03-31 14:49:33,635 - root - INFO - KG Training: Epoch 0001 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0226 | Iter Mean Loss 0.1184\n2024-03-31 14:49:39,370 - root - INFO - KG Training: Epoch 0001 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0177 | Iter Mean Loss 0.1162\n2024-03-31 14:49:45,051 - root - INFO - KG Training: Epoch 0001 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0196 | Iter Mean Loss 0.1141\n2024-03-31 14:49:50,888 - root - INFO - KG Training: Epoch 0001 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0197 | Iter Mean Loss 0.1121\n2024-03-31 14:49:56,480 - root - INFO - KG Training: Epoch 0001 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0183 | Iter Mean Loss 0.1102\n2024-03-31 14:50:02,030 - root - INFO - KG Training: Epoch 0001 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0197 | Iter Mean Loss 0.1084\n2024-03-31 14:50:07,665 - root - INFO - KG Training: Epoch 0001 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0182 | Iter Mean Loss 0.1066\n2024-03-31 14:50:13,270 - root - INFO - KG Training: Epoch 0001 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0189 | Iter Mean Loss 0.1048\n2024-03-31 14:50:18,832 - root - INFO - KG Training: Epoch 0001 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0167 | Iter Mean Loss 0.1031\n2024-03-31 14:50:24,470 - root - INFO - KG Training: Epoch 0001 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0187 | Iter Mean Loss 0.1015\n2024-03-31 14:50:29,897 - root - INFO - KG Training: Epoch 0001 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0184 | Iter Mean Loss 0.1000\n2024-03-31 14:50:35,438 - root - INFO - KG Training: Epoch 0001 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0169 | Iter Mean Loss 0.0984\n2024-03-31 14:50:41,004 - root - INFO - KG Training: Epoch 0001 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0970\n2024-03-31 14:50:46,617 - root - INFO - KG Training: Epoch 0001 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0167 | Iter Mean Loss 0.0956\n2024-03-31 14:50:52,291 - root - INFO - KG Training: Epoch 0001 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0201 | Iter Mean Loss 0.0942\n2024-03-31 14:50:57,930 - root - INFO - KG Training: Epoch 0001 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0179 | Iter Mean Loss 0.0929\n2024-03-31 14:51:03,583 - root - INFO - KG Training: Epoch 0001 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0190 | Iter Mean Loss 0.0916\n2024-03-31 14:51:09,127 - root - INFO - KG Training: Epoch 0001 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0177 | Iter Mean Loss 0.0903\n2024-03-31 14:51:14,721 - root - INFO - KG Training: Epoch 0001 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0183 | Iter Mean Loss 0.0891\n2024-03-31 14:51:20,341 - root - INFO - KG Training: Epoch 0001 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0163 | Iter Mean Loss 0.0880\n2024-03-31 14:51:25,939 - root - INFO - KG Training: Epoch 0001 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0163 | Iter Mean Loss 0.0868\n2024-03-31 14:51:31,457 - root - INFO - KG Training: Epoch 0001 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0121 | Iter Mean Loss 0.0857\n2024-03-31 14:51:37,033 - root - INFO - KG Training: Epoch 0001 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0162 | Iter Mean Loss 0.0847\n2024-03-31 14:51:42,469 - root - INFO - KG Training: Epoch 0001 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0157 | Iter Mean Loss 0.0836\n2024-03-31 14:51:47,996 - root - INFO - KG Training: Epoch 0001 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0186 | Iter Mean Loss 0.0826\n2024-03-31 14:51:53,547 - root - INFO - KG Training: Epoch 0001 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0136 | Iter Mean Loss 0.0816\n2024-03-31 14:51:59,149 - root - INFO - KG Training: Epoch 0001 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0806\n2024-03-31 14:52:04,658 - root - INFO - KG Training: Epoch 0001 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0797\n2024-03-31 14:52:10,127 - root - INFO - KG Training: Epoch 0001 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0788\n2024-03-31 14:52:15,628 - root - INFO - KG Training: Epoch 0001 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0139 | Iter Mean Loss 0.0779\n2024-03-31 14:52:21,130 - root - INFO - KG Training: Epoch 0001 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0121 | Iter Mean Loss 0.0770\n2024-03-31 14:52:26,888 - root - INFO - KG Training: Epoch 0001 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0141 | Iter Mean Loss 0.0762\n2024-03-31 14:52:32,454 - root - INFO - KG Training: Epoch 0001 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0145 | Iter Mean Loss 0.0754\n2024-03-31 14:52:37,923 - root - INFO - KG Training: Epoch 0001 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0140 | Iter Mean Loss 0.0745\n2024-03-31 14:52:43,419 - root - INFO - KG Training: Epoch 0001 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0738\n2024-03-31 14:52:48,890 - root - INFO - KG Training: Epoch 0001 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0730\n2024-03-31 14:52:54,496 - root - INFO - KG Training: Epoch 0001 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0185 | Iter Mean Loss 0.0722\n2024-03-31 14:53:00,104 - root - INFO - KG Training: Epoch 0001 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0715\n2024-03-31 14:53:05,741 - root - INFO - KG Training: Epoch 0001 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0179 | Iter Mean Loss 0.0708\n2024-03-31 14:53:11,245 - root - INFO - KG Training: Epoch 0001 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0141 | Iter Mean Loss 0.0701\n2024-03-31 14:53:16,820 - root - INFO - KG Training: Epoch 0001 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0694\n2024-03-31 14:53:22,346 - root - INFO - KG Training: Epoch 0001 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0687\n2024-03-31 14:53:27,868 - root - INFO - KG Training: Epoch 0001 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0681\n2024-03-31 14:53:33,566 - root - INFO - KG Training: Epoch 0001 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0674\n2024-03-31 14:53:39,079 - root - INFO - KG Training: Epoch 0001 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0124 | Iter Mean Loss 0.0668\n2024-03-31 14:53:44,611 - root - INFO - KG Training: Epoch 0001 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0126 | Iter Mean Loss 0.0662\n2024-03-31 14:53:50,107 - root - INFO - KG Training: Epoch 0001 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0656\n2024-03-31 14:53:55,687 - root - INFO - KG Training: Epoch 0001 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0155 | Iter Mean Loss 0.0650\n2024-03-31 14:54:01,305 - root - INFO - KG Training: Epoch 0001 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0128 | Iter Mean Loss 0.0645\n2024-03-31 14:54:06,826 - root - INFO - KG Training: Epoch 0001 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0639\n2024-03-31 14:54:12,412 - root - INFO - KG Training: Epoch 0001 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0634\n2024-03-31 14:54:17,972 - root - INFO - KG Training: Epoch 0001 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0628\n2024-03-31 14:54:23,617 - root - INFO - KG Training: Epoch 0001 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0623\n2024-03-31 14:54:29,130 - root - INFO - KG Training: Epoch 0001 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0618\n2024-03-31 14:54:34,790 - root - INFO - KG Training: Epoch 0001 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0136 | Iter Mean Loss 0.0613\n2024-03-31 14:54:40,318 - root - INFO - KG Training: Epoch 0001 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0608\n2024-03-31 14:54:46,009 - root - INFO - KG Training: Epoch 0001 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0603\n2024-03-31 14:54:51,556 - root - INFO - KG Training: Epoch 0001 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0598\n2024-03-31 14:54:57,161 - root - INFO - KG Training: Epoch 0001 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0593\n2024-03-31 14:55:02,601 - root - INFO - KG Training: Epoch 0001 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0589\n2024-03-31 14:55:08,283 - root - INFO - KG Training: Epoch 0001 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0584\n2024-03-31 14:55:13,882 - root - INFO - KG Training: Epoch 0001 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0580\n2024-03-31 14:55:19,397 - root - INFO - KG Training: Epoch 0001 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0128 | Iter Mean Loss 0.0575\n2024-03-31 14:55:25,055 - root - INFO - KG Training: Epoch 0001 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0571\n2024-03-31 14:55:30,521 - root - INFO - KG Training: Epoch 0001 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0567\n2024-03-31 14:55:35,211 - root - INFO - KG Training: Epoch 0001 Total Iter 5442 | Total Time 611.3s | Iter Mean Loss 0.0563\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 14:55:38,056 - root - INFO - Update Attention: Epoch 0001 | Total Time 2.8s\n2024-03-31 14:55:38,056 - root - INFO - CF + KG Training: Epoch 0001 | Total Time 3018.2s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:12<00:00,  5.38it/s]\n2024-03-31 14:57:50,469 - root - INFO - CF Evaluation: Epoch 0001 | Total Time 132.4s | Precision [0.0183, 0.0127], Recall [0.1143, 0.3514], NDCG [0.0614, 0.1239]\n2024-03-31 14:57:50,967 - root - INFO - Save model on epoch 0001!\n2024-03-31 14:58:09,072 - root - INFO - CF Training: Epoch 0002 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.3324 | Iter Mean Loss 0.4081\n2024-03-31 14:58:27,135 - root - INFO - CF Training: Epoch 0002 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2774 | Iter Mean Loss 0.3605\n2024-03-31 14:58:45,213 - root - INFO - CF Training: Epoch 0002 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2896 | Iter Mean Loss 0.3352\n2024-03-31 14:59:03,308 - root - INFO - CF Training: Epoch 0002 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2754 | Iter Mean Loss 0.3200\n2024-03-31 14:59:21,371 - root - INFO - CF Training: Epoch 0002 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2724 | Iter Mean Loss 0.3107\n2024-03-31 14:59:39,433 - root - INFO - CF Training: Epoch 0002 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2855 | Iter Mean Loss 0.3040\n2024-03-31 14:59:57,488 - root - INFO - CF Training: Epoch 0002 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2514 | Iter Mean Loss 0.2982\n2024-03-31 15:00:15,571 - root - INFO - CF Training: Epoch 0002 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2714 | Iter Mean Loss 0.2940\n2024-03-31 15:00:33,661 - root - INFO - CF Training: Epoch 0002 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2685 | Iter Mean Loss 0.2901\n2024-03-31 15:00:51,697 - root - INFO - CF Training: Epoch 0002 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2533 | Iter Mean Loss 0.2869\n2024-03-31 15:01:09,766 - root - INFO - CF Training: Epoch 0002 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2539 | Iter Mean Loss 0.2843\n2024-03-31 15:01:27,856 - root - INFO - CF Training: Epoch 0002 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.2756 | Iter Mean Loss 0.2822\n2024-03-31 15:01:45,926 - root - INFO - CF Training: Epoch 0002 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2432 | Iter Mean Loss 0.2802\n2024-03-31 15:02:04,003 - root - INFO - CF Training: Epoch 0002 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2545 | Iter Mean Loss 0.2784\n2024-03-31 15:02:22,064 - root - INFO - CF Training: Epoch 0002 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2599 | Iter Mean Loss 0.2768\n2024-03-31 15:02:40,138 - root - INFO - CF Training: Epoch 0002 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2468 | Iter Mean Loss 0.2753\n2024-03-31 15:02:58,147 - root - INFO - CF Training: Epoch 0002 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2523 | Iter Mean Loss 0.2741\n2024-03-31 15:03:16,179 - root - INFO - CF Training: Epoch 0002 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2489 | Iter Mean Loss 0.2729\n2024-03-31 15:03:34,192 - root - INFO - CF Training: Epoch 0002 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.2430 | Iter Mean Loss 0.2717\n2024-03-31 15:03:52,242 - root - INFO - CF Training: Epoch 0002 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.2375 | Iter Mean Loss 0.2707\n2024-03-31 15:04:10,320 - root - INFO - CF Training: Epoch 0002 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2249 | Iter Mean Loss 0.2697\n2024-03-31 15:04:28,412 - root - INFO - CF Training: Epoch 0002 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2613 | Iter Mean Loss 0.2688\n2024-03-31 15:04:46,502 - root - INFO - CF Training: Epoch 0002 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.2612 | Iter Mean Loss 0.2678\n2024-03-31 15:05:04,614 - root - INFO - CF Training: Epoch 0002 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2325 | Iter Mean Loss 0.2669\n2024-03-31 15:05:22,668 - root - INFO - CF Training: Epoch 0002 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.2373 | Iter Mean Loss 0.2662\n2024-03-31 15:05:40,740 - root - INFO - CF Training: Epoch 0002 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2498 | Iter Mean Loss 0.2654\n2024-03-31 15:05:58,795 - root - INFO - CF Training: Epoch 0002 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.2433 | Iter Mean Loss 0.2646\n2024-03-31 15:06:16,899 - root - INFO - CF Training: Epoch 0002 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2477 | Iter Mean Loss 0.2638\n2024-03-31 15:06:34,981 - root - INFO - CF Training: Epoch 0002 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.2458 | Iter Mean Loss 0.2631\n2024-03-31 15:06:53,053 - root - INFO - CF Training: Epoch 0002 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2608 | Iter Mean Loss 0.2625\n2024-03-31 15:07:11,090 - root - INFO - CF Training: Epoch 0002 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2525 | Iter Mean Loss 0.2619\n2024-03-31 15:07:29,155 - root - INFO - CF Training: Epoch 0002 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.2383 | Iter Mean Loss 0.2614\n2024-03-31 15:07:47,197 - root - INFO - CF Training: Epoch 0002 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2301 | Iter Mean Loss 0.2608\n2024-03-31 15:08:05,205 - root - INFO - CF Training: Epoch 0002 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2498 | Iter Mean Loss 0.2602\n2024-03-31 15:08:23,214 - root - INFO - CF Training: Epoch 0002 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2382 | Iter Mean Loss 0.2597\n2024-03-31 15:08:41,218 - root - INFO - CF Training: Epoch 0002 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2493 | Iter Mean Loss 0.2591\n2024-03-31 15:08:59,177 - root - INFO - CF Training: Epoch 0002 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2375 | Iter Mean Loss 0.2586\n2024-03-31 15:09:17,156 - root - INFO - CF Training: Epoch 0002 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.2414 | Iter Mean Loss 0.2581\n2024-03-31 15:09:35,157 - root - INFO - CF Training: Epoch 0002 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2593 | Iter Mean Loss 0.2577\n2024-03-31 15:09:53,150 - root - INFO - CF Training: Epoch 0002 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2218 | Iter Mean Loss 0.2573\n2024-03-31 15:10:11,149 - root - INFO - CF Training: Epoch 0002 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2367 | Iter Mean Loss 0.2568\n2024-03-31 15:10:29,198 - root - INFO - CF Training: Epoch 0002 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2444 | Iter Mean Loss 0.2564\n2024-03-31 15:10:47,247 - root - INFO - CF Training: Epoch 0002 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2368 | Iter Mean Loss 0.2561\n2024-03-31 15:11:05,319 - root - INFO - CF Training: Epoch 0002 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2559 | Iter Mean Loss 0.2556\n2024-03-31 15:11:23,415 - root - INFO - CF Training: Epoch 0002 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2364 | Iter Mean Loss 0.2553\n2024-03-31 15:11:41,553 - root - INFO - CF Training: Epoch 0002 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2341 | Iter Mean Loss 0.2549\n2024-03-31 15:11:59,685 - root - INFO - CF Training: Epoch 0002 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2285 | Iter Mean Loss 0.2546\n2024-03-31 15:12:17,742 - root - INFO - CF Training: Epoch 0002 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2487 | Iter Mean Loss 0.2542\n2024-03-31 15:12:35,882 - root - INFO - CF Training: Epoch 0002 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2575 | Iter Mean Loss 0.2539\n2024-03-31 15:12:53,963 - root - INFO - CF Training: Epoch 0002 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2345 | Iter Mean Loss 0.2535\n2024-03-31 15:13:11,972 - root - INFO - CF Training: Epoch 0002 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2309 | Iter Mean Loss 0.2532\n2024-03-31 15:13:30,049 - root - INFO - CF Training: Epoch 0002 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.2491 | Iter Mean Loss 0.2529\n2024-03-31 15:13:48,203 - root - INFO - CF Training: Epoch 0002 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2392 | Iter Mean Loss 0.2526\n2024-03-31 15:14:06,380 - root - INFO - CF Training: Epoch 0002 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2425 | Iter Mean Loss 0.2523\n2024-03-31 15:14:24,519 - root - INFO - CF Training: Epoch 0002 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.2428 | Iter Mean Loss 0.2520\n2024-03-31 15:14:42,670 - root - INFO - CF Training: Epoch 0002 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2547 | Iter Mean Loss 0.2518\n2024-03-31 15:15:00,765 - root - INFO - CF Training: Epoch 0002 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2439 | Iter Mean Loss 0.2515\n2024-03-31 15:15:18,875 - root - INFO - CF Training: Epoch 0002 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2399 | Iter Mean Loss 0.2512\n2024-03-31 15:15:36,887 - root - INFO - CF Training: Epoch 0002 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2401 | Iter Mean Loss 0.2509\n2024-03-31 15:15:54,850 - root - INFO - CF Training: Epoch 0002 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2265 | Iter Mean Loss 0.2506\n2024-03-31 15:16:12,827 - root - INFO - CF Training: Epoch 0002 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2192 | Iter Mean Loss 0.2503\n2024-03-31 15:16:30,786 - root - INFO - CF Training: Epoch 0002 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2218 | Iter Mean Loss 0.2501\n2024-03-31 15:16:48,765 - root - INFO - CF Training: Epoch 0002 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2249 | Iter Mean Loss 0.2498\n2024-03-31 15:17:06,751 - root - INFO - CF Training: Epoch 0002 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2482 | Iter Mean Loss 0.2496\n2024-03-31 15:17:24,718 - root - INFO - CF Training: Epoch 0002 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2387 | Iter Mean Loss 0.2494\n2024-03-31 15:17:42,681 - root - INFO - CF Training: Epoch 0002 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2347 | Iter Mean Loss 0.2492\n2024-03-31 15:18:00,593 - root - INFO - CF Training: Epoch 0002 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2291 | Iter Mean Loss 0.2489\n2024-03-31 15:18:18,561 - root - INFO - CF Training: Epoch 0002 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2525 | Iter Mean Loss 0.2487\n2024-03-31 15:18:36,526 - root - INFO - CF Training: Epoch 0002 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2264 | Iter Mean Loss 0.2485\n2024-03-31 15:18:54,473 - root - INFO - CF Training: Epoch 0002 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2199 | Iter Mean Loss 0.2482\n2024-03-31 15:19:12,416 - root - INFO - CF Training: Epoch 0002 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2463 | Iter Mean Loss 0.2480\n2024-03-31 15:19:30,372 - root - INFO - CF Training: Epoch 0002 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2479 | Iter Mean Loss 0.2478\n2024-03-31 15:19:48,378 - root - INFO - CF Training: Epoch 0002 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2346 | Iter Mean Loss 0.2475\n2024-03-31 15:20:06,361 - root - INFO - CF Training: Epoch 0002 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2521 | Iter Mean Loss 0.2474\n2024-03-31 15:20:24,350 - root - INFO - CF Training: Epoch 0002 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2524 | Iter Mean Loss 0.2472\n2024-03-31 15:20:42,373 - root - INFO - CF Training: Epoch 0002 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2172 | Iter Mean Loss 0.2470\n2024-03-31 15:21:00,421 - root - INFO - CF Training: Epoch 0002 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2418 | Iter Mean Loss 0.2468\n2024-03-31 15:21:18,490 - root - INFO - CF Training: Epoch 0002 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2277 | Iter Mean Loss 0.2467\n2024-03-31 15:21:36,563 - root - INFO - CF Training: Epoch 0002 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2351 | Iter Mean Loss 0.2465\n2024-03-31 15:21:54,663 - root - INFO - CF Training: Epoch 0002 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2355 | Iter Mean Loss 0.2463\n2024-03-31 15:22:12,752 - root - INFO - CF Training: Epoch 0002 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2419 | Iter Mean Loss 0.2461\n2024-03-31 15:22:30,823 - root - INFO - CF Training: Epoch 0002 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2237 | Iter Mean Loss 0.2459\n2024-03-31 15:22:48,898 - root - INFO - CF Training: Epoch 0002 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2286 | Iter Mean Loss 0.2457\n2024-03-31 15:23:06,993 - root - INFO - CF Training: Epoch 0002 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.2361 | Iter Mean Loss 0.2456\n2024-03-31 15:23:25,121 - root - INFO - CF Training: Epoch 0002 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.2448 | Iter Mean Loss 0.2454\n2024-03-31 15:23:43,180 - root - INFO - CF Training: Epoch 0002 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2260 | Iter Mean Loss 0.2452\n2024-03-31 15:24:01,268 - root - INFO - CF Training: Epoch 0002 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2326 | Iter Mean Loss 0.2451\n2024-03-31 15:24:19,344 - root - INFO - CF Training: Epoch 0002 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2267 | Iter Mean Loss 0.2449\n2024-03-31 15:24:37,425 - root - INFO - CF Training: Epoch 0002 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2380 | Iter Mean Loss 0.2447\n2024-03-31 15:24:55,517 - root - INFO - CF Training: Epoch 0002 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2273 | Iter Mean Loss 0.2446\n2024-03-31 15:25:13,592 - root - INFO - CF Training: Epoch 0002 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.2232 | Iter Mean Loss 0.2444\n2024-03-31 15:25:31,657 - root - INFO - CF Training: Epoch 0002 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2197 | Iter Mean Loss 0.2442\n2024-03-31 15:25:49,744 - root - INFO - CF Training: Epoch 0002 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2307 | Iter Mean Loss 0.2441\n2024-03-31 15:26:07,747 - root - INFO - CF Training: Epoch 0002 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2350 | Iter Mean Loss 0.2439\n2024-03-31 15:26:25,746 - root - INFO - CF Training: Epoch 0002 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2211 | Iter Mean Loss 0.2438\n2024-03-31 15:26:43,730 - root - INFO - CF Training: Epoch 0002 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.2349 | Iter Mean Loss 0.2436\n2024-03-31 15:27:01,727 - root - INFO - CF Training: Epoch 0002 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2360 | Iter Mean Loss 0.2434\n2024-03-31 15:27:19,737 - root - INFO - CF Training: Epoch 0002 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.2394 | Iter Mean Loss 0.2433\n2024-03-31 15:27:37,739 - root - INFO - CF Training: Epoch 0002 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2316 | Iter Mean Loss 0.2432\n2024-03-31 15:27:55,748 - root - INFO - CF Training: Epoch 0002 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2343 | Iter Mean Loss 0.2430\n2024-03-31 15:28:13,773 - root - INFO - CF Training: Epoch 0002 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.2567 | Iter Mean Loss 0.2429\n2024-03-31 15:28:31,816 - root - INFO - CF Training: Epoch 0002 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2273 | Iter Mean Loss 0.2427\n2024-03-31 15:28:49,865 - root - INFO - CF Training: Epoch 0002 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2139 | Iter Mean Loss 0.2426\n2024-03-31 15:29:07,874 - root - INFO - CF Training: Epoch 0002 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2240 | Iter Mean Loss 0.2424\n2024-03-31 15:29:25,917 - root - INFO - CF Training: Epoch 0002 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2169 | Iter Mean Loss 0.2423\n2024-03-31 15:29:43,931 - root - INFO - CF Training: Epoch 0002 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2160 | Iter Mean Loss 0.2422\n2024-03-31 15:30:01,964 - root - INFO - CF Training: Epoch 0002 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2340 | Iter Mean Loss 0.2420\n2024-03-31 15:30:20,006 - root - INFO - CF Training: Epoch 0002 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2531 | Iter Mean Loss 0.2419\n2024-03-31 15:30:23,622 - root - INFO - CF Training: Epoch 0002 Total Iter 5410 | Total Time 1952.7s | Iter Mean Loss 0.2419\n2024-03-31 15:30:29,115 - root - INFO - KG Training: Epoch 0002 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0117\n2024-03-31 15:30:34,495 - root - INFO - KG Training: Epoch 0002 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0117\n2024-03-31 15:30:40,110 - root - INFO - KG Training: Epoch 0002 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0117\n2024-03-31 15:30:45,648 - root - INFO - KG Training: Epoch 0002 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0117\n2024-03-31 15:30:51,180 - root - INFO - KG Training: Epoch 0002 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0117\n2024-03-31 15:30:56,749 - root - INFO - KG Training: Epoch 0002 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0150 | Iter Mean Loss 0.0116\n2024-03-31 15:31:02,326 - root - INFO - KG Training: Epoch 0002 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0121 | Iter Mean Loss 0.0116\n2024-03-31 15:31:07,896 - root - INFO - KG Training: Epoch 0002 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0130 | Iter Mean Loss 0.0116\n2024-03-31 15:31:13,466 - root - INFO - KG Training: Epoch 0002 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0132 | Iter Mean Loss 0.0116\n2024-03-31 15:31:18,902 - root - INFO - KG Training: Epoch 0002 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0116\n2024-03-31 15:31:24,471 - root - INFO - KG Training: Epoch 0002 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0131 | Iter Mean Loss 0.0116\n2024-03-31 15:31:29,997 - root - INFO - KG Training: Epoch 0002 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0116\n2024-03-31 15:31:35,410 - root - INFO - KG Training: Epoch 0002 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0116\n2024-03-31 15:31:40,882 - root - INFO - KG Training: Epoch 0002 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0137 | Iter Mean Loss 0.0116\n2024-03-31 15:31:46,498 - root - INFO - KG Training: Epoch 0002 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0115\n2024-03-31 15:31:51,998 - root - INFO - KG Training: Epoch 0002 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0168 | Iter Mean Loss 0.0115\n2024-03-31 15:31:57,545 - root - INFO - KG Training: Epoch 0002 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0115\n2024-03-31 15:32:03,115 - root - INFO - KG Training: Epoch 0002 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0115\n2024-03-31 15:32:08,768 - root - INFO - KG Training: Epoch 0002 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0115\n2024-03-31 15:32:14,462 - root - INFO - KG Training: Epoch 0002 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0155 | Iter Mean Loss 0.0114\n2024-03-31 15:32:20,005 - root - INFO - KG Training: Epoch 0002 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0114\n2024-03-31 15:32:25,650 - root - INFO - KG Training: Epoch 0002 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0147 | Iter Mean Loss 0.0115\n2024-03-31 15:32:31,056 - root - INFO - KG Training: Epoch 0002 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0120 | Iter Mean Loss 0.0114\n2024-03-31 15:32:36,490 - root - INFO - KG Training: Epoch 0002 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0150 | Iter Mean Loss 0.0114\n2024-03-31 15:32:42,067 - root - INFO - KG Training: Epoch 0002 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0114\n2024-03-31 15:32:47,693 - root - INFO - KG Training: Epoch 0002 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0114\n2024-03-31 15:32:53,127 - root - INFO - KG Training: Epoch 0002 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0114\n2024-03-31 15:32:58,589 - root - INFO - KG Training: Epoch 0002 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0113\n2024-03-31 15:33:04,036 - root - INFO - KG Training: Epoch 0002 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0113\n2024-03-31 15:33:09,350 - root - INFO - KG Training: Epoch 0002 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0113\n2024-03-31 15:33:14,908 - root - INFO - KG Training: Epoch 0002 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0113\n2024-03-31 15:33:20,477 - root - INFO - KG Training: Epoch 0002 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0113\n2024-03-31 15:33:26,003 - root - INFO - KG Training: Epoch 0002 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0113 | Iter Mean Loss 0.0113\n2024-03-31 15:33:31,370 - root - INFO - KG Training: Epoch 0002 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0142 | Iter Mean Loss 0.0113\n2024-03-31 15:33:36,926 - root - INFO - KG Training: Epoch 0002 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0147 | Iter Mean Loss 0.0112\n2024-03-31 15:33:42,374 - root - INFO - KG Training: Epoch 0002 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0112\n2024-03-31 15:33:47,971 - root - INFO - KG Training: Epoch 0002 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0112\n2024-03-31 15:33:53,503 - root - INFO - KG Training: Epoch 0002 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0112\n2024-03-31 15:33:59,131 - root - INFO - KG Training: Epoch 0002 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0112 | Iter Mean Loss 0.0112\n2024-03-31 15:34:04,704 - root - INFO - KG Training: Epoch 0002 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0112\n2024-03-31 15:34:10,141 - root - INFO - KG Training: Epoch 0002 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0111\n2024-03-31 15:34:15,604 - root - INFO - KG Training: Epoch 0002 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0120 | Iter Mean Loss 0.0111\n2024-03-31 15:34:21,264 - root - INFO - KG Training: Epoch 0002 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0111\n2024-03-31 15:34:26,751 - root - INFO - KG Training: Epoch 0002 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0111\n2024-03-31 15:34:32,309 - root - INFO - KG Training: Epoch 0002 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0111\n2024-03-31 15:34:37,834 - root - INFO - KG Training: Epoch 0002 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0142 | Iter Mean Loss 0.0111\n2024-03-31 15:34:43,338 - root - INFO - KG Training: Epoch 0002 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0111\n2024-03-31 15:34:48,881 - root - INFO - KG Training: Epoch 0002 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0110\n2024-03-31 15:34:54,544 - root - INFO - KG Training: Epoch 0002 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0124 | Iter Mean Loss 0.0110\n2024-03-31 15:35:00,149 - root - INFO - KG Training: Epoch 0002 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0110\n2024-03-31 15:35:05,709 - root - INFO - KG Training: Epoch 0002 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0110\n2024-03-31 15:35:11,205 - root - INFO - KG Training: Epoch 0002 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0110\n2024-03-31 15:35:16,797 - root - INFO - KG Training: Epoch 0002 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0110\n2024-03-31 15:35:22,497 - root - INFO - KG Training: Epoch 0002 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0110\n2024-03-31 15:35:28,116 - root - INFO - KG Training: Epoch 0002 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0110\n2024-03-31 15:35:33,745 - root - INFO - KG Training: Epoch 0002 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0110\n2024-03-31 15:35:39,383 - root - INFO - KG Training: Epoch 0002 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0110\n2024-03-31 15:35:44,936 - root - INFO - KG Training: Epoch 0002 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0109\n2024-03-31 15:35:50,464 - root - INFO - KG Training: Epoch 0002 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0113 | Iter Mean Loss 0.0109\n2024-03-31 15:35:56,191 - root - INFO - KG Training: Epoch 0002 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0109\n2024-03-31 15:36:01,775 - root - INFO - KG Training: Epoch 0002 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0109\n2024-03-31 15:36:07,427 - root - INFO - KG Training: Epoch 0002 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0109\n2024-03-31 15:36:13,037 - root - INFO - KG Training: Epoch 0002 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0157 | Iter Mean Loss 0.0109\n2024-03-31 15:36:18,656 - root - INFO - KG Training: Epoch 0002 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0143 | Iter Mean Loss 0.0109\n2024-03-31 15:36:24,200 - root - INFO - KG Training: Epoch 0002 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0109\n2024-03-31 15:36:29,889 - root - INFO - KG Training: Epoch 0002 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0128 | Iter Mean Loss 0.0109\n2024-03-31 15:36:35,542 - root - INFO - KG Training: Epoch 0002 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0130 | Iter Mean Loss 0.0109\n2024-03-31 15:36:41,041 - root - INFO - KG Training: Epoch 0002 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0044 | Iter Mean Loss 0.0108\n2024-03-31 15:36:46,644 - root - INFO - KG Training: Epoch 0002 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0108\n2024-03-31 15:36:52,112 - root - INFO - KG Training: Epoch 0002 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0108\n2024-03-31 15:36:57,747 - root - INFO - KG Training: Epoch 0002 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0143 | Iter Mean Loss 0.0108\n2024-03-31 15:37:03,313 - root - INFO - KG Training: Epoch 0002 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0108\n2024-03-31 15:37:08,859 - root - INFO - KG Training: Epoch 0002 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0136 | Iter Mean Loss 0.0108\n2024-03-31 15:37:14,403 - root - INFO - KG Training: Epoch 0002 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0108\n2024-03-31 15:37:19,892 - root - INFO - KG Training: Epoch 0002 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0124 | Iter Mean Loss 0.0108\n2024-03-31 15:37:25,457 - root - INFO - KG Training: Epoch 0002 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0108\n2024-03-31 15:37:31,018 - root - INFO - KG Training: Epoch 0002 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0108\n2024-03-31 15:37:36,513 - root - INFO - KG Training: Epoch 0002 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0108\n2024-03-31 15:37:42,077 - root - INFO - KG Training: Epoch 0002 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0108\n2024-03-31 15:37:47,528 - root - INFO - KG Training: Epoch 0002 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0108\n2024-03-31 15:37:52,932 - root - INFO - KG Training: Epoch 0002 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0121 | Iter Mean Loss 0.0107\n2024-03-31 15:37:58,443 - root - INFO - KG Training: Epoch 0002 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0107\n2024-03-31 15:38:04,032 - root - INFO - KG Training: Epoch 0002 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0107\n2024-03-31 15:38:09,599 - root - INFO - KG Training: Epoch 0002 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0107\n2024-03-31 15:38:15,222 - root - INFO - KG Training: Epoch 0002 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0107\n2024-03-31 15:38:20,634 - root - INFO - KG Training: Epoch 0002 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0107\n2024-03-31 15:38:26,126 - root - INFO - KG Training: Epoch 0002 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0107\n2024-03-31 15:38:31,724 - root - INFO - KG Training: Epoch 0002 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0147 | Iter Mean Loss 0.0107\n2024-03-31 15:38:37,352 - root - INFO - KG Training: Epoch 0002 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0132 | Iter Mean Loss 0.0107\n2024-03-31 15:38:42,893 - root - INFO - KG Training: Epoch 0002 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0107\n2024-03-31 15:38:48,367 - root - INFO - KG Training: Epoch 0002 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0107\n2024-03-31 15:38:53,954 - root - INFO - KG Training: Epoch 0002 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0106\n2024-03-31 15:38:59,481 - root - INFO - KG Training: Epoch 0002 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0106\n2024-03-31 15:39:05,162 - root - INFO - KG Training: Epoch 0002 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0106\n2024-03-31 15:39:10,746 - root - INFO - KG Training: Epoch 0002 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0120 | Iter Mean Loss 0.0106\n2024-03-31 15:39:16,221 - root - INFO - KG Training: Epoch 0002 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0106\n2024-03-31 15:39:21,806 - root - INFO - KG Training: Epoch 0002 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0106\n2024-03-31 15:39:27,386 - root - INFO - KG Training: Epoch 0002 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0106\n2024-03-31 15:39:32,972 - root - INFO - KG Training: Epoch 0002 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0106\n2024-03-31 15:39:38,503 - root - INFO - KG Training: Epoch 0002 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0106\n2024-03-31 15:39:43,970 - root - INFO - KG Training: Epoch 0002 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0106\n2024-03-31 15:39:49,327 - root - INFO - KG Training: Epoch 0002 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0106\n2024-03-31 15:39:54,749 - root - INFO - KG Training: Epoch 0002 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0106\n2024-03-31 15:40:00,286 - root - INFO - KG Training: Epoch 0002 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0106\n2024-03-31 15:40:05,895 - root - INFO - KG Training: Epoch 0002 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0106\n2024-03-31 15:40:11,464 - root - INFO - KG Training: Epoch 0002 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0105\n2024-03-31 15:40:17,049 - root - INFO - KG Training: Epoch 0002 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0135 | Iter Mean Loss 0.0105\n2024-03-31 15:40:22,503 - root - INFO - KG Training: Epoch 0002 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0105\n2024-03-31 15:40:27,102 - root - INFO - KG Training: Epoch 0002 Total Iter 5442 | Total Time 603.5s | Iter Mean Loss 0.0105\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 15:40:29,754 - root - INFO - Update Attention: Epoch 0002 | Total Time 2.7s\n2024-03-31 15:40:29,755 - root - INFO - CF + KG Training: Epoch 0002 | Total Time 2558.8s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:11<00:00,  5.40it/s]\n2024-03-31 15:42:41,710 - root - INFO - CF Evaluation: Epoch 0002 | Total Time 132.0s | Precision [0.0250, 0.0156], Recall [0.1564, 0.4282], NDCG [0.0857, 0.1584]\n2024-03-31 15:42:42,222 - root - INFO - Save model on epoch 0002!\n2024-03-31 15:43:00,278 - root - INFO - CF Training: Epoch 0003 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2392 | Iter Mean Loss 0.2403\n2024-03-31 15:43:18,378 - root - INFO - CF Training: Epoch 0003 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2380 | Iter Mean Loss 0.2387\n2024-03-31 15:43:36,427 - root - INFO - CF Training: Epoch 0003 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2486 | Iter Mean Loss 0.2368\n2024-03-31 15:43:54,474 - root - INFO - CF Training: Epoch 0003 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2173 | Iter Mean Loss 0.2367\n2024-03-31 15:44:12,537 - root - INFO - CF Training: Epoch 0003 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2221 | Iter Mean Loss 0.2361\n2024-03-31 15:44:30,598 - root - INFO - CF Training: Epoch 0003 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2351 | Iter Mean Loss 0.2358\n2024-03-31 15:44:48,633 - root - INFO - CF Training: Epoch 0003 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2221 | Iter Mean Loss 0.2354\n2024-03-31 15:45:06,639 - root - INFO - CF Training: Epoch 0003 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2217 | Iter Mean Loss 0.2351\n2024-03-31 15:45:24,702 - root - INFO - CF Training: Epoch 0003 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2494 | Iter Mean Loss 0.2349\n2024-03-31 15:45:42,756 - root - INFO - CF Training: Epoch 0003 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2282 | Iter Mean Loss 0.2347\n2024-03-31 15:46:00,830 - root - INFO - CF Training: Epoch 0003 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2462 | Iter Mean Loss 0.2344\n2024-03-31 15:46:18,902 - root - INFO - CF Training: Epoch 0003 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.2140 | Iter Mean Loss 0.2341\n2024-03-31 15:46:36,978 - root - INFO - CF Training: Epoch 0003 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2217 | Iter Mean Loss 0.2339\n2024-03-31 15:46:55,052 - root - INFO - CF Training: Epoch 0003 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2333 | Iter Mean Loss 0.2337\n2024-03-31 15:47:13,074 - root - INFO - CF Training: Epoch 0003 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2286 | Iter Mean Loss 0.2334\n2024-03-31 15:47:31,188 - root - INFO - CF Training: Epoch 0003 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2394 | Iter Mean Loss 0.2331\n2024-03-31 15:47:49,185 - root - INFO - CF Training: Epoch 0003 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2195 | Iter Mean Loss 0.2330\n2024-03-31 15:48:07,228 - root - INFO - CF Training: Epoch 0003 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2203 | Iter Mean Loss 0.2328\n2024-03-31 15:48:25,301 - root - INFO - CF Training: Epoch 0003 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.2340 | Iter Mean Loss 0.2325\n2024-03-31 15:48:43,396 - root - INFO - CF Training: Epoch 0003 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.2292 | Iter Mean Loss 0.2323\n2024-03-31 15:49:01,505 - root - INFO - CF Training: Epoch 0003 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2433 | Iter Mean Loss 0.2320\n2024-03-31 15:49:19,517 - root - INFO - CF Training: Epoch 0003 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2216 | Iter Mean Loss 0.2318\n2024-03-31 15:49:37,580 - root - INFO - CF Training: Epoch 0003 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.2513 | Iter Mean Loss 0.2316\n2024-03-31 15:49:55,652 - root - INFO - CF Training: Epoch 0003 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2230 | Iter Mean Loss 0.2314\n2024-03-31 15:50:13,693 - root - INFO - CF Training: Epoch 0003 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.2285 | Iter Mean Loss 0.2313\n2024-03-31 15:50:31,728 - root - INFO - CF Training: Epoch 0003 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2315 | Iter Mean Loss 0.2311\n2024-03-31 15:50:49,779 - root - INFO - CF Training: Epoch 0003 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.2223 | Iter Mean Loss 0.2309\n2024-03-31 15:51:07,844 - root - INFO - CF Training: Epoch 0003 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2090 | Iter Mean Loss 0.2308\n2024-03-31 15:51:25,898 - root - INFO - CF Training: Epoch 0003 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.2292 | Iter Mean Loss 0.2307\n2024-03-31 15:51:43,977 - root - INFO - CF Training: Epoch 0003 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2169 | Iter Mean Loss 0.2306\n2024-03-31 15:52:01,990 - root - INFO - CF Training: Epoch 0003 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2154 | Iter Mean Loss 0.2304\n2024-03-31 15:52:20,019 - root - INFO - CF Training: Epoch 0003 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.2098 | Iter Mean Loss 0.2303\n2024-03-31 15:52:38,088 - root - INFO - CF Training: Epoch 0003 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2607 | Iter Mean Loss 0.2301\n2024-03-31 15:52:56,122 - root - INFO - CF Training: Epoch 0003 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2217 | Iter Mean Loss 0.2299\n2024-03-31 15:53:14,163 - root - INFO - CF Training: Epoch 0003 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2288 | Iter Mean Loss 0.2298\n2024-03-31 15:53:32,220 - root - INFO - CF Training: Epoch 0003 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2245 | Iter Mean Loss 0.2297\n2024-03-31 15:53:50,267 - root - INFO - CF Training: Epoch 0003 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2120 | Iter Mean Loss 0.2296\n2024-03-31 15:54:08,326 - root - INFO - CF Training: Epoch 0003 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.2247 | Iter Mean Loss 0.2294\n2024-03-31 15:54:26,401 - root - INFO - CF Training: Epoch 0003 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2182 | Iter Mean Loss 0.2293\n2024-03-31 15:54:44,453 - root - INFO - CF Training: Epoch 0003 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2179 | Iter Mean Loss 0.2292\n2024-03-31 15:55:02,469 - root - INFO - CF Training: Epoch 0003 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2323 | Iter Mean Loss 0.2291\n2024-03-31 15:55:20,521 - root - INFO - CF Training: Epoch 0003 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2178 | Iter Mean Loss 0.2290\n2024-03-31 15:55:38,551 - root - INFO - CF Training: Epoch 0003 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2197 | Iter Mean Loss 0.2289\n2024-03-31 15:55:56,614 - root - INFO - CF Training: Epoch 0003 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2200 | Iter Mean Loss 0.2288\n2024-03-31 15:56:14,651 - root - INFO - CF Training: Epoch 0003 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2211 | Iter Mean Loss 0.2287\n2024-03-31 15:56:32,690 - root - INFO - CF Training: Epoch 0003 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2069 | Iter Mean Loss 0.2285\n2024-03-31 15:56:50,756 - root - INFO - CF Training: Epoch 0003 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2102 | Iter Mean Loss 0.2284\n2024-03-31 15:57:08,791 - root - INFO - CF Training: Epoch 0003 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2077 | Iter Mean Loss 0.2283\n2024-03-31 15:57:26,806 - root - INFO - CF Training: Epoch 0003 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2417 | Iter Mean Loss 0.2282\n2024-03-31 15:57:44,853 - root - INFO - CF Training: Epoch 0003 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2307 | Iter Mean Loss 0.2281\n2024-03-31 15:58:02,906 - root - INFO - CF Training: Epoch 0003 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2257 | Iter Mean Loss 0.2280\n2024-03-31 15:58:20,938 - root - INFO - CF Training: Epoch 0003 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.2295 | Iter Mean Loss 0.2279\n2024-03-31 15:58:38,986 - root - INFO - CF Training: Epoch 0003 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2262 | Iter Mean Loss 0.2277\n2024-03-31 15:58:57,014 - root - INFO - CF Training: Epoch 0003 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2215 | Iter Mean Loss 0.2276\n2024-03-31 15:59:15,013 - root - INFO - CF Training: Epoch 0003 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.2224 | Iter Mean Loss 0.2275\n2024-03-31 15:59:33,008 - root - INFO - CF Training: Epoch 0003 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2344 | Iter Mean Loss 0.2274\n2024-03-31 15:59:51,063 - root - INFO - CF Training: Epoch 0003 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2364 | Iter Mean Loss 0.2273\n2024-03-31 16:00:09,131 - root - INFO - CF Training: Epoch 0003 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2220 | Iter Mean Loss 0.2271\n2024-03-31 16:00:27,216 - root - INFO - CF Training: Epoch 0003 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2212 | Iter Mean Loss 0.2270\n2024-03-31 16:00:45,298 - root - INFO - CF Training: Epoch 0003 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2281 | Iter Mean Loss 0.2269\n2024-03-31 16:01:03,353 - root - INFO - CF Training: Epoch 0003 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2115 | Iter Mean Loss 0.2268\n2024-03-31 16:01:21,418 - root - INFO - CF Training: Epoch 0003 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2085 | Iter Mean Loss 0.2267\n2024-03-31 16:01:39,516 - root - INFO - CF Training: Epoch 0003 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2272 | Iter Mean Loss 0.2266\n2024-03-31 16:01:57,627 - root - INFO - CF Training: Epoch 0003 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2123 | Iter Mean Loss 0.2265\n2024-03-31 16:02:15,722 - root - INFO - CF Training: Epoch 0003 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2238 | Iter Mean Loss 0.2265\n2024-03-31 16:02:33,767 - root - INFO - CF Training: Epoch 0003 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.2264\n2024-03-31 16:02:51,805 - root - INFO - CF Training: Epoch 0003 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2315 | Iter Mean Loss 0.2263\n2024-03-31 16:03:09,820 - root - INFO - CF Training: Epoch 0003 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2125 | Iter Mean Loss 0.2262\n2024-03-31 16:03:27,857 - root - INFO - CF Training: Epoch 0003 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.2261\n2024-03-31 16:03:45,907 - root - INFO - CF Training: Epoch 0003 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2153 | Iter Mean Loss 0.2261\n2024-03-31 16:04:03,900 - root - INFO - CF Training: Epoch 0003 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2265 | Iter Mean Loss 0.2260\n2024-03-31 16:04:21,924 - root - INFO - CF Training: Epoch 0003 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2159 | Iter Mean Loss 0.2259\n2024-03-31 16:04:39,946 - root - INFO - CF Training: Epoch 0003 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2373 | Iter Mean Loss 0.2258\n2024-03-31 16:04:57,965 - root - INFO - CF Training: Epoch 0003 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2120 | Iter Mean Loss 0.2257\n2024-03-31 16:05:15,977 - root - INFO - CF Training: Epoch 0003 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2492 | Iter Mean Loss 0.2257\n2024-03-31 16:05:34,006 - root - INFO - CF Training: Epoch 0003 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2048 | Iter Mean Loss 0.2256\n2024-03-31 16:05:52,112 - root - INFO - CF Training: Epoch 0003 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2134 | Iter Mean Loss 0.2255\n2024-03-31 16:06:10,138 - root - INFO - CF Training: Epoch 0003 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2316 | Iter Mean Loss 0.2254\n2024-03-31 16:06:28,192 - root - INFO - CF Training: Epoch 0003 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2235 | Iter Mean Loss 0.2254\n2024-03-31 16:06:46,185 - root - INFO - CF Training: Epoch 0003 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2300 | Iter Mean Loss 0.2253\n2024-03-31 16:07:04,194 - root - INFO - CF Training: Epoch 0003 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2334 | Iter Mean Loss 0.2252\n2024-03-31 16:07:22,220 - root - INFO - CF Training: Epoch 0003 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2226 | Iter Mean Loss 0.2251\n2024-03-31 16:07:40,281 - root - INFO - CF Training: Epoch 0003 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.2251\n2024-03-31 16:07:58,333 - root - INFO - CF Training: Epoch 0003 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.2297 | Iter Mean Loss 0.2250\n2024-03-31 16:08:16,365 - root - INFO - CF Training: Epoch 0003 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.2300 | Iter Mean Loss 0.2249\n2024-03-31 16:08:34,397 - root - INFO - CF Training: Epoch 0003 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2194 | Iter Mean Loss 0.2248\n2024-03-31 16:08:52,412 - root - INFO - CF Training: Epoch 0003 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2359 | Iter Mean Loss 0.2248\n2024-03-31 16:09:10,465 - root - INFO - CF Training: Epoch 0003 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2158 | Iter Mean Loss 0.2247\n2024-03-31 16:09:28,506 - root - INFO - CF Training: Epoch 0003 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2161 | Iter Mean Loss 0.2247\n2024-03-31 16:09:46,541 - root - INFO - CF Training: Epoch 0003 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2153 | Iter Mean Loss 0.2246\n2024-03-31 16:10:04,583 - root - INFO - CF Training: Epoch 0003 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.2242 | Iter Mean Loss 0.2245\n2024-03-31 16:10:22,618 - root - INFO - CF Training: Epoch 0003 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2279 | Iter Mean Loss 0.2245\n2024-03-31 16:10:40,697 - root - INFO - CF Training: Epoch 0003 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2076 | Iter Mean Loss 0.2244\n2024-03-31 16:10:58,751 - root - INFO - CF Training: Epoch 0003 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2291 | Iter Mean Loss 0.2244\n2024-03-31 16:11:16,784 - root - INFO - CF Training: Epoch 0003 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2146 | Iter Mean Loss 0.2243\n2024-03-31 16:11:34,842 - root - INFO - CF Training: Epoch 0003 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.2242\n2024-03-31 16:11:52,916 - root - INFO - CF Training: Epoch 0003 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2233 | Iter Mean Loss 0.2242\n2024-03-31 16:12:10,982 - root - INFO - CF Training: Epoch 0003 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.2116 | Iter Mean Loss 0.2241\n2024-03-31 16:12:29,081 - root - INFO - CF Training: Epoch 0003 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2041 | Iter Mean Loss 0.2240\n2024-03-31 16:12:47,152 - root - INFO - CF Training: Epoch 0003 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2250 | Iter Mean Loss 0.2240\n2024-03-31 16:13:05,258 - root - INFO - CF Training: Epoch 0003 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.2041 | Iter Mean Loss 0.2239\n2024-03-31 16:13:23,297 - root - INFO - CF Training: Epoch 0003 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2173 | Iter Mean Loss 0.2238\n2024-03-31 16:13:41,395 - root - INFO - CF Training: Epoch 0003 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2201 | Iter Mean Loss 0.2237\n2024-03-31 16:13:59,463 - root - INFO - CF Training: Epoch 0003 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2094 | Iter Mean Loss 0.2237\n2024-03-31 16:14:17,555 - root - INFO - CF Training: Epoch 0003 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2147 | Iter Mean Loss 0.2236\n2024-03-31 16:14:35,613 - root - INFO - CF Training: Epoch 0003 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2304 | Iter Mean Loss 0.2235\n2024-03-31 16:14:53,648 - root - INFO - CF Training: Epoch 0003 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2280 | Iter Mean Loss 0.2235\n2024-03-31 16:15:11,702 - root - INFO - CF Training: Epoch 0003 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.2234\n2024-03-31 16:15:15,323 - root - INFO - CF Training: Epoch 0003 Total Iter 5410 | Total Time 1953.1s | Iter Mean Loss 0.2234\n2024-03-31 16:15:20,803 - root - INFO - KG Training: Epoch 0003 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0096\n2024-03-31 16:15:26,241 - root - INFO - KG Training: Epoch 0003 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0097\n2024-03-31 16:15:31,734 - root - INFO - KG Training: Epoch 0003 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0098\n2024-03-31 16:15:37,306 - root - INFO - KG Training: Epoch 0003 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0124 | Iter Mean Loss 0.0097\n2024-03-31 16:15:42,990 - root - INFO - KG Training: Epoch 0003 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0097\n2024-03-31 16:15:48,502 - root - INFO - KG Training: Epoch 0003 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0097\n2024-03-31 16:15:53,935 - root - INFO - KG Training: Epoch 0003 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:15:59,421 - root - INFO - KG Training: Epoch 0003 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0096\n2024-03-31 16:16:05,012 - root - INFO - KG Training: Epoch 0003 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0131 | Iter Mean Loss 0.0097\n2024-03-31 16:16:10,564 - root - INFO - KG Training: Epoch 0003 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0097\n2024-03-31 16:16:16,007 - root - INFO - KG Training: Epoch 0003 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0097\n2024-03-31 16:16:21,444 - root - INFO - KG Training: Epoch 0003 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0097\n2024-03-31 16:16:27,044 - root - INFO - KG Training: Epoch 0003 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0097\n2024-03-31 16:16:32,550 - root - INFO - KG Training: Epoch 0003 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0098\n2024-03-31 16:16:38,141 - root - INFO - KG Training: Epoch 0003 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0112 | Iter Mean Loss 0.0098\n2024-03-31 16:16:43,727 - root - INFO - KG Training: Epoch 0003 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:16:49,195 - root - INFO - KG Training: Epoch 0003 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0097\n2024-03-31 16:16:54,683 - root - INFO - KG Training: Epoch 0003 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0098\n2024-03-31 16:17:00,178 - root - INFO - KG Training: Epoch 0003 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0097\n2024-03-31 16:17:05,849 - root - INFO - KG Training: Epoch 0003 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0097\n2024-03-31 16:17:11,277 - root - INFO - KG Training: Epoch 0003 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0097\n2024-03-31 16:17:16,794 - root - INFO - KG Training: Epoch 0003 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0097\n2024-03-31 16:17:22,355 - root - INFO - KG Training: Epoch 0003 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:17:27,889 - root - INFO - KG Training: Epoch 0003 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:17:33,488 - root - INFO - KG Training: Epoch 0003 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0097\n2024-03-31 16:17:39,187 - root - INFO - KG Training: Epoch 0003 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0097\n2024-03-31 16:17:44,630 - root - INFO - KG Training: Epoch 0003 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0097\n2024-03-31 16:17:49,866 - root - INFO - KG Training: Epoch 0003 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0097\n2024-03-31 16:17:55,461 - root - INFO - KG Training: Epoch 0003 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0097\n2024-03-31 16:18:00,829 - root - INFO - KG Training: Epoch 0003 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0097\n2024-03-31 16:18:06,240 - root - INFO - KG Training: Epoch 0003 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:18:12,155 - root - INFO - KG Training: Epoch 0003 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0097\n2024-03-31 16:18:17,780 - root - INFO - KG Training: Epoch 0003 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0097\n2024-03-31 16:18:23,322 - root - INFO - KG Training: Epoch 0003 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0097\n2024-03-31 16:18:29,016 - root - INFO - KG Training: Epoch 0003 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0141 | Iter Mean Loss 0.0097\n2024-03-31 16:18:34,601 - root - INFO - KG Training: Epoch 0003 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0097\n2024-03-31 16:18:40,228 - root - INFO - KG Training: Epoch 0003 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0097\n2024-03-31 16:18:45,616 - root - INFO - KG Training: Epoch 0003 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0097\n2024-03-31 16:18:51,295 - root - INFO - KG Training: Epoch 0003 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0097\n2024-03-31 16:18:56,913 - root - INFO - KG Training: Epoch 0003 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0097\n2024-03-31 16:19:02,457 - root - INFO - KG Training: Epoch 0003 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0096\n2024-03-31 16:19:07,925 - root - INFO - KG Training: Epoch 0003 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0096\n2024-03-31 16:19:13,508 - root - INFO - KG Training: Epoch 0003 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0124 | Iter Mean Loss 0.0096\n2024-03-31 16:19:19,050 - root - INFO - KG Training: Epoch 0003 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0096\n2024-03-31 16:19:24,756 - root - INFO - KG Training: Epoch 0003 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0096\n2024-03-31 16:19:30,437 - root - INFO - KG Training: Epoch 0003 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0096\n2024-03-31 16:19:36,096 - root - INFO - KG Training: Epoch 0003 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0096\n2024-03-31 16:19:41,950 - root - INFO - KG Training: Epoch 0003 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0096\n2024-03-31 16:19:47,546 - root - INFO - KG Training: Epoch 0003 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0096\n2024-03-31 16:19:53,240 - root - INFO - KG Training: Epoch 0003 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0096\n2024-03-31 16:19:58,644 - root - INFO - KG Training: Epoch 0003 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0096\n2024-03-31 16:20:04,048 - root - INFO - KG Training: Epoch 0003 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0048 | Iter Mean Loss 0.0096\n2024-03-31 16:20:09,429 - root - INFO - KG Training: Epoch 0003 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0096\n2024-03-31 16:20:14,877 - root - INFO - KG Training: Epoch 0003 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0096\n2024-03-31 16:20:20,185 - root - INFO - KG Training: Epoch 0003 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0096\n2024-03-31 16:20:25,684 - root - INFO - KG Training: Epoch 0003 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0096\n2024-03-31 16:20:30,932 - root - INFO - KG Training: Epoch 0003 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0096\n2024-03-31 16:20:36,212 - root - INFO - KG Training: Epoch 0003 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0096\n2024-03-31 16:20:41,587 - root - INFO - KG Training: Epoch 0003 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0096\n2024-03-31 16:20:47,041 - root - INFO - KG Training: Epoch 0003 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0096\n2024-03-31 16:20:52,378 - root - INFO - KG Training: Epoch 0003 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0096\n2024-03-31 16:20:57,830 - root - INFO - KG Training: Epoch 0003 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0096\n2024-03-31 16:21:03,243 - root - INFO - KG Training: Epoch 0003 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0096\n2024-03-31 16:21:08,654 - root - INFO - KG Training: Epoch 0003 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0096\n2024-03-31 16:21:13,989 - root - INFO - KG Training: Epoch 0003 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0096\n2024-03-31 16:21:19,290 - root - INFO - KG Training: Epoch 0003 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0130 | Iter Mean Loss 0.0096\n2024-03-31 16:21:24,702 - root - INFO - KG Training: Epoch 0003 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0096\n2024-03-31 16:21:30,095 - root - INFO - KG Training: Epoch 0003 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0096\n2024-03-31 16:21:35,446 - root - INFO - KG Training: Epoch 0003 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0096\n2024-03-31 16:21:40,815 - root - INFO - KG Training: Epoch 0003 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0096\n2024-03-31 16:21:46,276 - root - INFO - KG Training: Epoch 0003 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0096\n2024-03-31 16:21:51,592 - root - INFO - KG Training: Epoch 0003 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0139 | Iter Mean Loss 0.0096\n2024-03-31 16:21:57,102 - root - INFO - KG Training: Epoch 0003 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0096\n2024-03-31 16:22:02,421 - root - INFO - KG Training: Epoch 0003 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0096\n2024-03-31 16:22:07,950 - root - INFO - KG Training: Epoch 0003 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0095\n2024-03-31 16:22:13,375 - root - INFO - KG Training: Epoch 0003 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0095\n2024-03-31 16:22:18,914 - root - INFO - KG Training: Epoch 0003 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0095\n2024-03-31 16:22:24,410 - root - INFO - KG Training: Epoch 0003 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0095\n2024-03-31 16:22:29,916 - root - INFO - KG Training: Epoch 0003 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0096\n2024-03-31 16:22:35,402 - root - INFO - KG Training: Epoch 0003 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0096\n2024-03-31 16:22:40,917 - root - INFO - KG Training: Epoch 0003 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0095\n2024-03-31 16:22:46,567 - root - INFO - KG Training: Epoch 0003 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0131 | Iter Mean Loss 0.0096\n2024-03-31 16:22:51,928 - root - INFO - KG Training: Epoch 0003 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0095\n2024-03-31 16:22:57,359 - root - INFO - KG Training: Epoch 0003 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0095\n2024-03-31 16:23:02,834 - root - INFO - KG Training: Epoch 0003 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0095\n2024-03-31 16:23:08,273 - root - INFO - KG Training: Epoch 0003 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0095\n2024-03-31 16:23:13,779 - root - INFO - KG Training: Epoch 0003 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0095\n2024-03-31 16:23:19,206 - root - INFO - KG Training: Epoch 0003 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0095\n2024-03-31 16:23:24,802 - root - INFO - KG Training: Epoch 0003 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0095\n2024-03-31 16:23:30,247 - root - INFO - KG Training: Epoch 0003 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0095\n2024-03-31 16:23:35,831 - root - INFO - KG Training: Epoch 0003 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0095\n2024-03-31 16:23:41,303 - root - INFO - KG Training: Epoch 0003 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0095\n2024-03-31 16:23:46,877 - root - INFO - KG Training: Epoch 0003 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0095\n2024-03-31 16:23:52,470 - root - INFO - KG Training: Epoch 0003 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0095\n2024-03-31 16:23:57,946 - root - INFO - KG Training: Epoch 0003 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0135 | Iter Mean Loss 0.0095\n2024-03-31 16:24:03,504 - root - INFO - KG Training: Epoch 0003 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0095\n2024-03-31 16:24:09,024 - root - INFO - KG Training: Epoch 0003 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0095\n2024-03-31 16:24:14,506 - root - INFO - KG Training: Epoch 0003 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0095\n2024-03-31 16:24:19,997 - root - INFO - KG Training: Epoch 0003 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0095\n2024-03-31 16:24:25,481 - root - INFO - KG Training: Epoch 0003 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0095\n2024-03-31 16:24:30,991 - root - INFO - KG Training: Epoch 0003 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0095\n2024-03-31 16:24:36,536 - root - INFO - KG Training: Epoch 0003 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0095\n2024-03-31 16:24:42,021 - root - INFO - KG Training: Epoch 0003 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0146 | Iter Mean Loss 0.0095\n2024-03-31 16:24:47,574 - root - INFO - KG Training: Epoch 0003 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0095\n2024-03-31 16:24:53,175 - root - INFO - KG Training: Epoch 0003 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0095\n2024-03-31 16:24:58,586 - root - INFO - KG Training: Epoch 0003 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0095\n2024-03-31 16:25:04,101 - root - INFO - KG Training: Epoch 0003 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0095\n2024-03-31 16:25:09,691 - root - INFO - KG Training: Epoch 0003 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0095\n2024-03-31 16:25:14,304 - root - INFO - KG Training: Epoch 0003 Total Iter 5442 | Total Time 599.0s | Iter Mean Loss 0.0095\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 16:25:16,898 - root - INFO - Update Attention: Epoch 0003 | Total Time 2.6s\n2024-03-31 16:25:16,898 - root - INFO - CF + KG Training: Epoch 0003 | Total Time 2554.7s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:10<00:00,  5.47it/s]\n2024-03-31 16:27:27,064 - root - INFO - CF Evaluation: Epoch 0003 | Total Time 130.2s | Precision [0.0248, 0.0159], Recall [0.1552, 0.4389], NDCG [0.0851, 0.1605]\n2024-03-31 16:27:45,063 - root - INFO - CF Training: Epoch 0004 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2315 | Iter Mean Loss 0.2235\n2024-03-31 16:28:03,040 - root - INFO - CF Training: Epoch 0004 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2184 | Iter Mean Loss 0.2214\n2024-03-31 16:28:20,995 - root - INFO - CF Training: Epoch 0004 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2159 | Iter Mean Loss 0.2219\n2024-03-31 16:28:38,953 - root - INFO - CF Training: Epoch 0004 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2280 | Iter Mean Loss 0.2214\n2024-03-31 16:28:56,953 - root - INFO - CF Training: Epoch 0004 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2190 | Iter Mean Loss 0.2212\n2024-03-31 16:29:14,938 - root - INFO - CF Training: Epoch 0004 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2204 | Iter Mean Loss 0.2212\n2024-03-31 16:29:32,917 - root - INFO - CF Training: Epoch 0004 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2322 | Iter Mean Loss 0.2208\n2024-03-31 16:29:50,864 - root - INFO - CF Training: Epoch 0004 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2226 | Iter Mean Loss 0.2205\n2024-03-31 16:30:08,808 - root - INFO - CF Training: Epoch 0004 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2163 | Iter Mean Loss 0.2204\n2024-03-31 16:30:26,782 - root - INFO - CF Training: Epoch 0004 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2269 | Iter Mean Loss 0.2203\n2024-03-31 16:30:44,772 - root - INFO - CF Training: Epoch 0004 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2252 | Iter Mean Loss 0.2201\n2024-03-31 16:31:02,785 - root - INFO - CF Training: Epoch 0004 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.1994 | Iter Mean Loss 0.2198\n2024-03-31 16:31:20,775 - root - INFO - CF Training: Epoch 0004 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2182 | Iter Mean Loss 0.2197\n2024-03-31 16:31:38,800 - root - INFO - CF Training: Epoch 0004 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2177 | Iter Mean Loss 0.2197\n2024-03-31 16:31:56,823 - root - INFO - CF Training: Epoch 0004 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.2197\n2024-03-31 16:32:14,872 - root - INFO - CF Training: Epoch 0004 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2271 | Iter Mean Loss 0.2196\n2024-03-31 16:32:33,108 - root - INFO - CF Training: Epoch 0004 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2305 | Iter Mean Loss 0.2194\n2024-03-31 16:32:51,326 - root - INFO - CF Training: Epoch 0004 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2072 | Iter Mean Loss 0.2192\n2024-03-31 16:33:09,510 - root - INFO - CF Training: Epoch 0004 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.2269 | Iter Mean Loss 0.2191\n2024-03-31 16:33:27,681 - root - INFO - CF Training: Epoch 0004 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.1936 | Iter Mean Loss 0.2190\n2024-03-31 16:33:45,827 - root - INFO - CF Training: Epoch 0004 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2181 | Iter Mean Loss 0.2188\n2024-03-31 16:34:04,037 - root - INFO - CF Training: Epoch 0004 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2129 | Iter Mean Loss 0.2187\n2024-03-31 16:34:22,103 - root - INFO - CF Training: Epoch 0004 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.2122 | Iter Mean Loss 0.2186\n2024-03-31 16:34:40,172 - root - INFO - CF Training: Epoch 0004 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2287 | Iter Mean Loss 0.2186\n2024-03-31 16:34:58,185 - root - INFO - CF Training: Epoch 0004 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.2162 | Iter Mean Loss 0.2185\n2024-03-31 16:35:16,265 - root - INFO - CF Training: Epoch 0004 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.1996 | Iter Mean Loss 0.2184\n2024-03-31 16:35:34,329 - root - INFO - CF Training: Epoch 0004 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.2173 | Iter Mean Loss 0.2184\n2024-03-31 16:35:52,315 - root - INFO - CF Training: Epoch 0004 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2245 | Iter Mean Loss 0.2183\n2024-03-31 16:36:10,313 - root - INFO - CF Training: Epoch 0004 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.2239 | Iter Mean Loss 0.2182\n2024-03-31 16:36:28,293 - root - INFO - CF Training: Epoch 0004 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2191 | Iter Mean Loss 0.2182\n2024-03-31 16:36:46,251 - root - INFO - CF Training: Epoch 0004 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2248 | Iter Mean Loss 0.2181\n2024-03-31 16:37:04,232 - root - INFO - CF Training: Epoch 0004 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.2156 | Iter Mean Loss 0.2180\n2024-03-31 16:37:22,216 - root - INFO - CF Training: Epoch 0004 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2037 | Iter Mean Loss 0.2179\n2024-03-31 16:37:40,245 - root - INFO - CF Training: Epoch 0004 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2251 | Iter Mean Loss 0.2178\n2024-03-31 16:37:58,216 - root - INFO - CF Training: Epoch 0004 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2022 | Iter Mean Loss 0.2177\n2024-03-31 16:38:16,229 - root - INFO - CF Training: Epoch 0004 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2239 | Iter Mean Loss 0.2176\n2024-03-31 16:38:34,230 - root - INFO - CF Training: Epoch 0004 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2193 | Iter Mean Loss 0.2175\n2024-03-31 16:38:52,230 - root - INFO - CF Training: Epoch 0004 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.2109 | Iter Mean Loss 0.2175\n2024-03-31 16:39:10,214 - root - INFO - CF Training: Epoch 0004 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2212 | Iter Mean Loss 0.2174\n2024-03-31 16:39:28,230 - root - INFO - CF Training: Epoch 0004 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2225 | Iter Mean Loss 0.2174\n2024-03-31 16:39:46,269 - root - INFO - CF Training: Epoch 0004 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2242 | Iter Mean Loss 0.2173\n2024-03-31 16:40:04,317 - root - INFO - CF Training: Epoch 0004 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2108 | Iter Mean Loss 0.2173\n2024-03-31 16:40:22,294 - root - INFO - CF Training: Epoch 0004 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2282 | Iter Mean Loss 0.2173\n2024-03-31 16:40:40,250 - root - INFO - CF Training: Epoch 0004 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.1909 | Iter Mean Loss 0.2173\n2024-03-31 16:40:58,243 - root - INFO - CF Training: Epoch 0004 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2114 | Iter Mean Loss 0.2172\n2024-03-31 16:41:16,225 - root - INFO - CF Training: Epoch 0004 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2377 | Iter Mean Loss 0.2172\n2024-03-31 16:41:34,176 - root - INFO - CF Training: Epoch 0004 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2228 | Iter Mean Loss 0.2172\n2024-03-31 16:41:52,167 - root - INFO - CF Training: Epoch 0004 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2170 | Iter Mean Loss 0.2171\n2024-03-31 16:42:10,147 - root - INFO - CF Training: Epoch 0004 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2055 | Iter Mean Loss 0.2171\n2024-03-31 16:42:28,121 - root - INFO - CF Training: Epoch 0004 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2301 | Iter Mean Loss 0.2170\n2024-03-31 16:42:46,076 - root - INFO - CF Training: Epoch 0004 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2072 | Iter Mean Loss 0.2169\n2024-03-31 16:43:04,136 - root - INFO - CF Training: Epoch 0004 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.2435 | Iter Mean Loss 0.2169\n2024-03-31 16:43:22,182 - root - INFO - CF Training: Epoch 0004 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2105 | Iter Mean Loss 0.2168\n2024-03-31 16:43:40,193 - root - INFO - CF Training: Epoch 0004 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2397 | Iter Mean Loss 0.2167\n2024-03-31 16:43:58,171 - root - INFO - CF Training: Epoch 0004 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.2229 | Iter Mean Loss 0.2167\n2024-03-31 16:44:16,112 - root - INFO - CF Training: Epoch 0004 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2054 | Iter Mean Loss 0.2166\n2024-03-31 16:44:34,096 - root - INFO - CF Training: Epoch 0004 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.1981 | Iter Mean Loss 0.2165\n2024-03-31 16:44:52,050 - root - INFO - CF Training: Epoch 0004 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2385 | Iter Mean Loss 0.2165\n2024-03-31 16:45:10,030 - root - INFO - CF Training: Epoch 0004 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2110 | Iter Mean Loss 0.2165\n2024-03-31 16:45:28,033 - root - INFO - CF Training: Epoch 0004 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2253 | Iter Mean Loss 0.2165\n2024-03-31 16:45:46,033 - root - INFO - CF Training: Epoch 0004 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2208 | Iter Mean Loss 0.2164\n2024-03-31 16:46:04,024 - root - INFO - CF Training: Epoch 0004 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2268 | Iter Mean Loss 0.2164\n2024-03-31 16:46:21,981 - root - INFO - CF Training: Epoch 0004 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2192 | Iter Mean Loss 0.2163\n2024-03-31 16:46:40,009 - root - INFO - CF Training: Epoch 0004 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2260 | Iter Mean Loss 0.2163\n2024-03-31 16:46:58,034 - root - INFO - CF Training: Epoch 0004 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2166 | Iter Mean Loss 0.2163\n2024-03-31 16:47:16,057 - root - INFO - CF Training: Epoch 0004 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2098 | Iter Mean Loss 0.2162\n2024-03-31 16:47:34,104 - root - INFO - CF Training: Epoch 0004 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2334 | Iter Mean Loss 0.2162\n2024-03-31 16:47:52,112 - root - INFO - CF Training: Epoch 0004 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2029 | Iter Mean Loss 0.2161\n2024-03-31 16:48:10,175 - root - INFO - CF Training: Epoch 0004 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2143 | Iter Mean Loss 0.2161\n2024-03-31 16:48:28,214 - root - INFO - CF Training: Epoch 0004 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2135 | Iter Mean Loss 0.2160\n2024-03-31 16:48:46,251 - root - INFO - CF Training: Epoch 0004 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2312 | Iter Mean Loss 0.2159\n2024-03-31 16:49:04,253 - root - INFO - CF Training: Epoch 0004 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2118 | Iter Mean Loss 0.2159\n2024-03-31 16:49:22,281 - root - INFO - CF Training: Epoch 0004 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2007 | Iter Mean Loss 0.2158\n2024-03-31 16:49:40,292 - root - INFO - CF Training: Epoch 0004 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2169 | Iter Mean Loss 0.2158\n2024-03-31 16:49:58,321 - root - INFO - CF Training: Epoch 0004 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2303 | Iter Mean Loss 0.2158\n2024-03-31 16:50:16,336 - root - INFO - CF Training: Epoch 0004 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.1900 | Iter Mean Loss 0.2157\n2024-03-31 16:50:34,374 - root - INFO - CF Training: Epoch 0004 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2198 | Iter Mean Loss 0.2157\n2024-03-31 16:50:52,423 - root - INFO - CF Training: Epoch 0004 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2115 | Iter Mean Loss 0.2157\n2024-03-31 16:51:10,451 - root - INFO - CF Training: Epoch 0004 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2118 | Iter Mean Loss 0.2156\n2024-03-31 16:51:28,488 - root - INFO - CF Training: Epoch 0004 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2180 | Iter Mean Loss 0.2156\n2024-03-31 16:51:46,521 - root - INFO - CF Training: Epoch 0004 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2275 | Iter Mean Loss 0.2155\n2024-03-31 16:52:04,541 - root - INFO - CF Training: Epoch 0004 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2273 | Iter Mean Loss 0.2155\n2024-03-31 16:52:22,541 - root - INFO - CF Training: Epoch 0004 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2176 | Iter Mean Loss 0.2155\n2024-03-31 16:52:40,547 - root - INFO - CF Training: Epoch 0004 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.2148 | Iter Mean Loss 0.2154\n2024-03-31 16:52:58,510 - root - INFO - CF Training: Epoch 0004 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.1968 | Iter Mean Loss 0.2154\n2024-03-31 16:53:16,514 - root - INFO - CF Training: Epoch 0004 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2281 | Iter Mean Loss 0.2154\n2024-03-31 16:53:34,514 - root - INFO - CF Training: Epoch 0004 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2152 | Iter Mean Loss 0.2153\n2024-03-31 16:53:52,573 - root - INFO - CF Training: Epoch 0004 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.2153\n2024-03-31 16:54:10,585 - root - INFO - CF Training: Epoch 0004 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2153\n2024-03-31 16:54:28,592 - root - INFO - CF Training: Epoch 0004 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2296 | Iter Mean Loss 0.2153\n2024-03-31 16:54:46,601 - root - INFO - CF Training: Epoch 0004 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.1989 | Iter Mean Loss 0.2152\n2024-03-31 16:55:04,594 - root - INFO - CF Training: Epoch 0004 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.1813 | Iter Mean Loss 0.2152\n2024-03-31 16:55:22,617 - root - INFO - CF Training: Epoch 0004 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2051 | Iter Mean Loss 0.2151\n2024-03-31 16:55:40,656 - root - INFO - CF Training: Epoch 0004 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2038 | Iter Mean Loss 0.2151\n2024-03-31 16:55:58,695 - root - INFO - CF Training: Epoch 0004 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2018 | Iter Mean Loss 0.2150\n2024-03-31 16:56:16,733 - root - INFO - CF Training: Epoch 0004 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.2138 | Iter Mean Loss 0.2150\n2024-03-31 16:56:34,732 - root - INFO - CF Training: Epoch 0004 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2028 | Iter Mean Loss 0.2150\n2024-03-31 16:56:52,758 - root - INFO - CF Training: Epoch 0004 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1882 | Iter Mean Loss 0.2149\n2024-03-31 16:57:10,792 - root - INFO - CF Training: Epoch 0004 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2178 | Iter Mean Loss 0.2149\n2024-03-31 16:57:28,857 - root - INFO - CF Training: Epoch 0004 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.1994 | Iter Mean Loss 0.2149\n2024-03-31 16:57:46,895 - root - INFO - CF Training: Epoch 0004 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.2116 | Iter Mean Loss 0.2148\n2024-03-31 16:58:04,922 - root - INFO - CF Training: Epoch 0004 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2228 | Iter Mean Loss 0.2148\n2024-03-31 16:58:23,030 - root - INFO - CF Training: Epoch 0004 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.1962 | Iter Mean Loss 0.2147\n2024-03-31 16:58:41,117 - root - INFO - CF Training: Epoch 0004 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2126 | Iter Mean Loss 0.2147\n2024-03-31 16:58:59,224 - root - INFO - CF Training: Epoch 0004 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2071 | Iter Mean Loss 0.2147\n2024-03-31 16:59:17,407 - root - INFO - CF Training: Epoch 0004 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2096 | Iter Mean Loss 0.2146\n2024-03-31 16:59:35,520 - root - INFO - CF Training: Epoch 0004 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2145 | Iter Mean Loss 0.2146\n2024-03-31 16:59:53,617 - root - INFO - CF Training: Epoch 0004 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2207 | Iter Mean Loss 0.2146\n2024-03-31 16:59:57,251 - root - INFO - CF Training: Epoch 0004 Total Iter 5410 | Total Time 1950.2s | Iter Mean Loss 0.2146\n2024-03-31 17:00:02,916 - root - INFO - KG Training: Epoch 0004 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0092\n2024-03-31 17:00:08,568 - root - INFO - KG Training: Epoch 0004 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0093\n2024-03-31 17:00:14,384 - root - INFO - KG Training: Epoch 0004 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0092\n2024-03-31 17:00:20,168 - root - INFO - KG Training: Epoch 0004 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0093\n2024-03-31 17:00:26,012 - root - INFO - KG Training: Epoch 0004 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0092\n2024-03-31 17:00:32,079 - root - INFO - KG Training: Epoch 0004 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0093\n2024-03-31 17:00:38,281 - root - INFO - KG Training: Epoch 0004 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0092\n2024-03-31 17:00:44,582 - root - INFO - KG Training: Epoch 0004 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0133 | Iter Mean Loss 0.0092\n2024-03-31 17:00:50,390 - root - INFO - KG Training: Epoch 0004 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0092\n2024-03-31 17:00:55,991 - root - INFO - KG Training: Epoch 0004 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0092\n2024-03-31 17:01:01,601 - root - INFO - KG Training: Epoch 0004 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0092\n2024-03-31 17:01:07,207 - root - INFO - KG Training: Epoch 0004 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0092\n2024-03-31 17:01:12,823 - root - INFO - KG Training: Epoch 0004 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0092\n2024-03-31 17:01:18,482 - root - INFO - KG Training: Epoch 0004 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0092\n2024-03-31 17:01:24,172 - root - INFO - KG Training: Epoch 0004 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0091\n2024-03-31 17:01:29,679 - root - INFO - KG Training: Epoch 0004 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0033 | Iter Mean Loss 0.0091\n2024-03-31 17:01:35,233 - root - INFO - KG Training: Epoch 0004 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0091\n2024-03-31 17:01:40,856 - root - INFO - KG Training: Epoch 0004 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0091\n2024-03-31 17:01:46,552 - root - INFO - KG Training: Epoch 0004 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0092\n2024-03-31 17:01:52,167 - root - INFO - KG Training: Epoch 0004 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0092\n2024-03-31 17:01:57,700 - root - INFO - KG Training: Epoch 0004 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0048 | Iter Mean Loss 0.0091\n2024-03-31 17:02:03,145 - root - INFO - KG Training: Epoch 0004 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0091\n2024-03-31 17:02:08,653 - root - INFO - KG Training: Epoch 0004 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0091\n2024-03-31 17:02:14,180 - root - INFO - KG Training: Epoch 0004 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0091\n2024-03-31 17:02:19,783 - root - INFO - KG Training: Epoch 0004 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0091\n2024-03-31 17:02:25,435 - root - INFO - KG Training: Epoch 0004 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0091\n2024-03-31 17:02:31,070 - root - INFO - KG Training: Epoch 0004 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0091\n2024-03-31 17:02:36,616 - root - INFO - KG Training: Epoch 0004 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0091\n2024-03-31 17:02:42,105 - root - INFO - KG Training: Epoch 0004 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0091\n2024-03-31 17:02:47,909 - root - INFO - KG Training: Epoch 0004 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0091\n2024-03-31 17:02:53,627 - root - INFO - KG Training: Epoch 0004 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0091\n2024-03-31 17:02:59,273 - root - INFO - KG Training: Epoch 0004 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0092\n2024-03-31 17:03:04,963 - root - INFO - KG Training: Epoch 0004 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0091\n2024-03-31 17:03:10,657 - root - INFO - KG Training: Epoch 0004 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0091\n2024-03-31 17:03:16,234 - root - INFO - KG Training: Epoch 0004 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0131 | Iter Mean Loss 0.0091\n2024-03-31 17:03:21,919 - root - INFO - KG Training: Epoch 0004 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0091\n2024-03-31 17:03:27,452 - root - INFO - KG Training: Epoch 0004 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0091\n2024-03-31 17:03:33,038 - root - INFO - KG Training: Epoch 0004 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0091\n2024-03-31 17:03:38,694 - root - INFO - KG Training: Epoch 0004 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0091\n2024-03-31 17:03:44,270 - root - INFO - KG Training: Epoch 0004 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0137 | Iter Mean Loss 0.0091\n2024-03-31 17:03:49,902 - root - INFO - KG Training: Epoch 0004 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0091\n2024-03-31 17:03:55,501 - root - INFO - KG Training: Epoch 0004 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0091\n2024-03-31 17:04:01,006 - root - INFO - KG Training: Epoch 0004 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0091\n2024-03-31 17:04:06,615 - root - INFO - KG Training: Epoch 0004 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0091\n2024-03-31 17:04:12,291 - root - INFO - KG Training: Epoch 0004 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0091\n2024-03-31 17:04:18,003 - root - INFO - KG Training: Epoch 0004 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0091\n2024-03-31 17:04:23,746 - root - INFO - KG Training: Epoch 0004 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0129 | Iter Mean Loss 0.0091\n2024-03-31 17:04:29,412 - root - INFO - KG Training: Epoch 0004 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0091\n2024-03-31 17:04:35,104 - root - INFO - KG Training: Epoch 0004 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0091\n2024-03-31 17:04:40,811 - root - INFO - KG Training: Epoch 0004 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0091\n2024-03-31 17:04:46,441 - root - INFO - KG Training: Epoch 0004 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0091\n2024-03-31 17:04:52,159 - root - INFO - KG Training: Epoch 0004 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0140 | Iter Mean Loss 0.0092\n2024-03-31 17:04:57,824 - root - INFO - KG Training: Epoch 0004 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0092\n2024-03-31 17:05:03,376 - root - INFO - KG Training: Epoch 0004 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0091\n2024-03-31 17:05:08,954 - root - INFO - KG Training: Epoch 0004 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0091\n2024-03-31 17:05:14,532 - root - INFO - KG Training: Epoch 0004 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0091\n2024-03-31 17:05:20,324 - root - INFO - KG Training: Epoch 0004 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0091\n2024-03-31 17:05:26,251 - root - INFO - KG Training: Epoch 0004 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0091\n2024-03-31 17:05:31,960 - root - INFO - KG Training: Epoch 0004 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0091\n2024-03-31 17:05:37,515 - root - INFO - KG Training: Epoch 0004 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0091\n2024-03-31 17:05:43,161 - root - INFO - KG Training: Epoch 0004 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0091\n2024-03-31 17:05:48,739 - root - INFO - KG Training: Epoch 0004 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0046 | Iter Mean Loss 0.0091\n2024-03-31 17:05:54,505 - root - INFO - KG Training: Epoch 0004 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0091\n2024-03-31 17:06:00,173 - root - INFO - KG Training: Epoch 0004 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0091\n2024-03-31 17:06:05,821 - root - INFO - KG Training: Epoch 0004 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0091\n2024-03-31 17:06:11,401 - root - INFO - KG Training: Epoch 0004 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0091\n2024-03-31 17:06:16,998 - root - INFO - KG Training: Epoch 0004 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0091\n2024-03-31 17:06:22,529 - root - INFO - KG Training: Epoch 0004 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0091\n2024-03-31 17:06:28,213 - root - INFO - KG Training: Epoch 0004 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0091\n2024-03-31 17:06:33,755 - root - INFO - KG Training: Epoch 0004 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0091\n2024-03-31 17:06:39,407 - root - INFO - KG Training: Epoch 0004 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0091\n2024-03-31 17:06:44,976 - root - INFO - KG Training: Epoch 0004 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0091\n2024-03-31 17:06:50,453 - root - INFO - KG Training: Epoch 0004 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0091\n2024-03-31 17:06:55,929 - root - INFO - KG Training: Epoch 0004 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0091\n2024-03-31 17:07:01,572 - root - INFO - KG Training: Epoch 0004 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0091\n2024-03-31 17:07:07,162 - root - INFO - KG Training: Epoch 0004 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0091\n2024-03-31 17:07:12,567 - root - INFO - KG Training: Epoch 0004 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0091\n2024-03-31 17:07:18,059 - root - INFO - KG Training: Epoch 0004 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0091\n2024-03-31 17:07:23,538 - root - INFO - KG Training: Epoch 0004 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0091\n2024-03-31 17:07:29,247 - root - INFO - KG Training: Epoch 0004 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0091\n2024-03-31 17:07:34,841 - root - INFO - KG Training: Epoch 0004 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0091\n2024-03-31 17:07:40,523 - root - INFO - KG Training: Epoch 0004 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0091\n2024-03-31 17:07:46,339 - root - INFO - KG Training: Epoch 0004 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0091\n2024-03-31 17:07:51,979 - root - INFO - KG Training: Epoch 0004 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0091\n2024-03-31 17:07:57,503 - root - INFO - KG Training: Epoch 0004 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0091\n2024-03-31 17:08:03,189 - root - INFO - KG Training: Epoch 0004 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0091\n2024-03-31 17:08:08,747 - root - INFO - KG Training: Epoch 0004 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0091\n2024-03-31 17:08:14,300 - root - INFO - KG Training: Epoch 0004 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0091\n2024-03-31 17:08:19,854 - root - INFO - KG Training: Epoch 0004 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0091\n2024-03-31 17:08:25,451 - root - INFO - KG Training: Epoch 0004 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0091\n2024-03-31 17:08:31,034 - root - INFO - KG Training: Epoch 0004 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0091\n2024-03-31 17:08:36,694 - root - INFO - KG Training: Epoch 0004 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0091\n2024-03-31 17:08:42,333 - root - INFO - KG Training: Epoch 0004 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0091\n2024-03-31 17:08:47,752 - root - INFO - KG Training: Epoch 0004 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0091\n2024-03-31 17:08:53,279 - root - INFO - KG Training: Epoch 0004 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0091\n2024-03-31 17:08:58,773 - root - INFO - KG Training: Epoch 0004 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0091\n2024-03-31 17:09:04,544 - root - INFO - KG Training: Epoch 0004 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0091\n2024-03-31 17:09:10,129 - root - INFO - KG Training: Epoch 0004 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0091\n2024-03-31 17:09:15,639 - root - INFO - KG Training: Epoch 0004 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0091\n2024-03-31 17:09:21,129 - root - INFO - KG Training: Epoch 0004 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0091\n2024-03-31 17:09:26,699 - root - INFO - KG Training: Epoch 0004 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0127 | Iter Mean Loss 0.0091\n2024-03-31 17:09:32,216 - root - INFO - KG Training: Epoch 0004 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0091\n2024-03-31 17:09:37,992 - root - INFO - KG Training: Epoch 0004 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0091\n2024-03-31 17:09:43,570 - root - INFO - KG Training: Epoch 0004 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0045 | Iter Mean Loss 0.0091\n2024-03-31 17:09:49,129 - root - INFO - KG Training: Epoch 0004 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0091\n2024-03-31 17:09:54,933 - root - INFO - KG Training: Epoch 0004 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0091\n2024-03-31 17:10:00,549 - root - INFO - KG Training: Epoch 0004 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0091\n2024-03-31 17:10:06,243 - root - INFO - KG Training: Epoch 0004 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0091\n2024-03-31 17:10:10,866 - root - INFO - KG Training: Epoch 0004 Total Iter 5442 | Total Time 613.6s | Iter Mean Loss 0.0091\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 17:10:13,456 - root - INFO - Update Attention: Epoch 0004 | Total Time 2.6s\n2024-03-31 17:10:13,457 - root - INFO - CF + KG Training: Epoch 0004 | Total Time 2566.4s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:14<00:00,  5.30it/s]\n2024-03-31 17:12:27,866 - root - INFO - CF Evaluation: Epoch 0004 | Total Time 134.4s | Precision [0.0254, 0.0163], Recall [0.1567, 0.4522], NDCG [0.0854, 0.1635]\n2024-03-31 17:12:28,370 - root - INFO - Save model on epoch 0004!\n2024-03-31 17:12:46,400 - root - INFO - CF Training: Epoch 0005 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2244 | Iter Mean Loss 0.2180\n2024-03-31 17:13:04,442 - root - INFO - CF Training: Epoch 0005 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2270 | Iter Mean Loss 0.2158\n2024-03-31 17:13:22,484 - root - INFO - CF Training: Epoch 0005 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2332 | Iter Mean Loss 0.2151\n2024-03-31 17:13:40,578 - root - INFO - CF Training: Epoch 0005 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2234 | Iter Mean Loss 0.2148\n2024-03-31 17:13:58,669 - root - INFO - CF Training: Epoch 0005 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2255 | Iter Mean Loss 0.2146\n2024-03-31 17:14:16,695 - root - INFO - CF Training: Epoch 0005 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.1960 | Iter Mean Loss 0.2144\n2024-03-31 17:14:34,759 - root - INFO - CF Training: Epoch 0005 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2159 | Iter Mean Loss 0.2141\n2024-03-31 17:14:52,839 - root - INFO - CF Training: Epoch 0005 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2222 | Iter Mean Loss 0.2138\n2024-03-31 17:15:10,872 - root - INFO - CF Training: Epoch 0005 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2125 | Iter Mean Loss 0.2138\n2024-03-31 17:15:28,902 - root - INFO - CF Training: Epoch 0005 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.2135\n2024-03-31 17:15:46,985 - root - INFO - CF Training: Epoch 0005 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2165 | Iter Mean Loss 0.2133\n2024-03-31 17:16:05,056 - root - INFO - CF Training: Epoch 0005 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.2077 | Iter Mean Loss 0.2131\n2024-03-31 17:16:23,108 - root - INFO - CF Training: Epoch 0005 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2214 | Iter Mean Loss 0.2131\n2024-03-31 17:16:41,137 - root - INFO - CF Training: Epoch 0005 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2088 | Iter Mean Loss 0.2129\n2024-03-31 17:16:59,194 - root - INFO - CF Training: Epoch 0005 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2236 | Iter Mean Loss 0.2128\n2024-03-31 17:17:17,234 - root - INFO - CF Training: Epoch 0005 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2185 | Iter Mean Loss 0.2128\n2024-03-31 17:17:35,272 - root - INFO - CF Training: Epoch 0005 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2106 | Iter Mean Loss 0.2127\n2024-03-31 17:17:53,302 - root - INFO - CF Training: Epoch 0005 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2090 | Iter Mean Loss 0.2126\n2024-03-31 17:18:11,346 - root - INFO - CF Training: Epoch 0005 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.2125\n2024-03-31 17:18:29,353 - root - INFO - CF Training: Epoch 0005 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.2123\n2024-03-31 17:18:47,357 - root - INFO - CF Training: Epoch 0005 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2284 | Iter Mean Loss 0.2123\n2024-03-31 17:19:05,375 - root - INFO - CF Training: Epoch 0005 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2123\n2024-03-31 17:19:23,397 - root - INFO - CF Training: Epoch 0005 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.2110 | Iter Mean Loss 0.2123\n2024-03-31 17:19:41,432 - root - INFO - CF Training: Epoch 0005 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2070 | Iter Mean Loss 0.2121\n2024-03-31 17:19:59,463 - root - INFO - CF Training: Epoch 0005 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.2024 | Iter Mean Loss 0.2121\n2024-03-31 17:20:17,467 - root - INFO - CF Training: Epoch 0005 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2233 | Iter Mean Loss 0.2120\n2024-03-31 17:20:35,504 - root - INFO - CF Training: Epoch 0005 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.1948 | Iter Mean Loss 0.2121\n2024-03-31 17:20:53,564 - root - INFO - CF Training: Epoch 0005 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2050 | Iter Mean Loss 0.2121\n2024-03-31 17:21:11,584 - root - INFO - CF Training: Epoch 0005 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1992 | Iter Mean Loss 0.2120\n2024-03-31 17:21:29,596 - root - INFO - CF Training: Epoch 0005 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2029 | Iter Mean Loss 0.2119\n2024-03-31 17:21:47,634 - root - INFO - CF Training: Epoch 0005 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2198 | Iter Mean Loss 0.2119\n2024-03-31 17:22:05,672 - root - INFO - CF Training: Epoch 0005 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1936 | Iter Mean Loss 0.2118\n2024-03-31 17:22:23,718 - root - INFO - CF Training: Epoch 0005 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.1980 | Iter Mean Loss 0.2118\n2024-03-31 17:22:41,728 - root - INFO - CF Training: Epoch 0005 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.1985 | Iter Mean Loss 0.2117\n2024-03-31 17:22:59,749 - root - INFO - CF Training: Epoch 0005 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2173 | Iter Mean Loss 0.2116\n2024-03-31 17:23:17,757 - root - INFO - CF Training: Epoch 0005 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2134 | Iter Mean Loss 0.2116\n2024-03-31 17:23:35,809 - root - INFO - CF Training: Epoch 0005 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2080 | Iter Mean Loss 0.2115\n2024-03-31 17:23:53,847 - root - INFO - CF Training: Epoch 0005 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.1968 | Iter Mean Loss 0.2115\n2024-03-31 17:24:11,861 - root - INFO - CF Training: Epoch 0005 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2189 | Iter Mean Loss 0.2115\n2024-03-31 17:24:29,876 - root - INFO - CF Training: Epoch 0005 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2132 | Iter Mean Loss 0.2116\n2024-03-31 17:24:47,891 - root - INFO - CF Training: Epoch 0005 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2413 | Iter Mean Loss 0.2115\n2024-03-31 17:25:05,902 - root - INFO - CF Training: Epoch 0005 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.1989 | Iter Mean Loss 0.2115\n2024-03-31 17:25:23,939 - root - INFO - CF Training: Epoch 0005 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2175 | Iter Mean Loss 0.2115\n2024-03-31 17:25:41,959 - root - INFO - CF Training: Epoch 0005 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2071 | Iter Mean Loss 0.2114\n2024-03-31 17:25:59,977 - root - INFO - CF Training: Epoch 0005 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2100 | Iter Mean Loss 0.2114\n2024-03-31 17:26:17,982 - root - INFO - CF Training: Epoch 0005 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2071 | Iter Mean Loss 0.2114\n2024-03-31 17:26:35,993 - root - INFO - CF Training: Epoch 0005 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.1981 | Iter Mean Loss 0.2114\n2024-03-31 17:26:54,006 - root - INFO - CF Training: Epoch 0005 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2218 | Iter Mean Loss 0.2113\n2024-03-31 17:27:11,995 - root - INFO - CF Training: Epoch 0005 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2164 | Iter Mean Loss 0.2112\n2024-03-31 17:27:29,997 - root - INFO - CF Training: Epoch 0005 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2028 | Iter Mean Loss 0.2112\n2024-03-31 17:27:48,044 - root - INFO - CF Training: Epoch 0005 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2052 | Iter Mean Loss 0.2111\n2024-03-31 17:28:06,064 - root - INFO - CF Training: Epoch 0005 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.1971 | Iter Mean Loss 0.2111\n2024-03-31 17:28:24,067 - root - INFO - CF Training: Epoch 0005 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2144 | Iter Mean Loss 0.2111\n2024-03-31 17:28:42,078 - root - INFO - CF Training: Epoch 0005 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2129 | Iter Mean Loss 0.2110\n2024-03-31 17:29:00,169 - root - INFO - CF Training: Epoch 0005 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.1914 | Iter Mean Loss 0.2110\n2024-03-31 17:29:18,240 - root - INFO - CF Training: Epoch 0005 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2148 | Iter Mean Loss 0.2109\n2024-03-31 17:29:36,278 - root - INFO - CF Training: Epoch 0005 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2014 | Iter Mean Loss 0.2109\n2024-03-31 17:29:54,330 - root - INFO - CF Training: Epoch 0005 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2009 | Iter Mean Loss 0.2108\n2024-03-31 17:30:12,392 - root - INFO - CF Training: Epoch 0005 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2099 | Iter Mean Loss 0.2108\n2024-03-31 17:30:30,426 - root - INFO - CF Training: Epoch 0005 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2191 | Iter Mean Loss 0.2107\n2024-03-31 17:30:48,469 - root - INFO - CF Training: Epoch 0005 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2065 | Iter Mean Loss 0.2107\n2024-03-31 17:31:06,530 - root - INFO - CF Training: Epoch 0005 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.1818 | Iter Mean Loss 0.2106\n2024-03-31 17:31:24,566 - root - INFO - CF Training: Epoch 0005 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2065 | Iter Mean Loss 0.2106\n2024-03-31 17:31:42,596 - root - INFO - CF Training: Epoch 0005 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2033 | Iter Mean Loss 0.2106\n2024-03-31 17:32:00,622 - root - INFO - CF Training: Epoch 0005 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.1943 | Iter Mean Loss 0.2106\n2024-03-31 17:32:18,662 - root - INFO - CF Training: Epoch 0005 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2168 | Iter Mean Loss 0.2106\n2024-03-31 17:32:36,662 - root - INFO - CF Training: Epoch 0005 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2192 | Iter Mean Loss 0.2106\n2024-03-31 17:32:54,689 - root - INFO - CF Training: Epoch 0005 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2123 | Iter Mean Loss 0.2106\n2024-03-31 17:33:12,721 - root - INFO - CF Training: Epoch 0005 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2200 | Iter Mean Loss 0.2105\n2024-03-31 17:33:30,731 - root - INFO - CF Training: Epoch 0005 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2105\n2024-03-31 17:33:48,794 - root - INFO - CF Training: Epoch 0005 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2117 | Iter Mean Loss 0.2105\n2024-03-31 17:34:06,878 - root - INFO - CF Training: Epoch 0005 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2137 | Iter Mean Loss 0.2104\n2024-03-31 17:34:24,939 - root - INFO - CF Training: Epoch 0005 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2022 | Iter Mean Loss 0.2104\n2024-03-31 17:34:42,995 - root - INFO - CF Training: Epoch 0005 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2104\n2024-03-31 17:35:01,017 - root - INFO - CF Training: Epoch 0005 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.2104\n2024-03-31 17:35:19,077 - root - INFO - CF Training: Epoch 0005 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2042 | Iter Mean Loss 0.2104\n2024-03-31 17:35:37,119 - root - INFO - CF Training: Epoch 0005 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.1944 | Iter Mean Loss 0.2103\n2024-03-31 17:35:55,248 - root - INFO - CF Training: Epoch 0005 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2108 | Iter Mean Loss 0.2103\n2024-03-31 17:36:13,304 - root - INFO - CF Training: Epoch 0005 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2342 | Iter Mean Loss 0.2103\n2024-03-31 17:36:31,392 - root - INFO - CF Training: Epoch 0005 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2079 | Iter Mean Loss 0.2103\n2024-03-31 17:36:49,458 - root - INFO - CF Training: Epoch 0005 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2028 | Iter Mean Loss 0.2102\n2024-03-31 17:37:07,526 - root - INFO - CF Training: Epoch 0005 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.1939 | Iter Mean Loss 0.2102\n2024-03-31 17:37:25,607 - root - INFO - CF Training: Epoch 0005 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2278 | Iter Mean Loss 0.2102\n2024-03-31 17:37:43,613 - root - INFO - CF Training: Epoch 0005 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.1841 | Iter Mean Loss 0.2102\n2024-03-31 17:38:01,685 - root - INFO - CF Training: Epoch 0005 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.2223 | Iter Mean Loss 0.2101\n2024-03-31 17:38:19,739 - root - INFO - CF Training: Epoch 0005 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.1931 | Iter Mean Loss 0.2101\n2024-03-31 17:38:37,706 - root - INFO - CF Training: Epoch 0005 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2013 | Iter Mean Loss 0.2101\n2024-03-31 17:38:55,734 - root - INFO - CF Training: Epoch 0005 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2043 | Iter Mean Loss 0.2100\n2024-03-31 17:39:13,719 - root - INFO - CF Training: Epoch 0005 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2100\n2024-03-31 17:39:31,766 - root - INFO - CF Training: Epoch 0005 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.2100\n2024-03-31 17:39:49,803 - root - INFO - CF Training: Epoch 0005 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.2100 | Iter Mean Loss 0.2100\n2024-03-31 17:40:07,905 - root - INFO - CF Training: Epoch 0005 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2068 | Iter Mean Loss 0.2100\n2024-03-31 17:40:25,995 - root - INFO - CF Training: Epoch 0005 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2086 | Iter Mean Loss 0.2099\n2024-03-31 17:40:44,052 - root - INFO - CF Training: Epoch 0005 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2063 | Iter Mean Loss 0.2099\n2024-03-31 17:41:02,122 - root - INFO - CF Training: Epoch 0005 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2174 | Iter Mean Loss 0.2098\n2024-03-31 17:41:20,122 - root - INFO - CF Training: Epoch 0005 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.2179 | Iter Mean Loss 0.2098\n2024-03-31 17:41:38,192 - root - INFO - CF Training: Epoch 0005 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2099 | Iter Mean Loss 0.2098\n2024-03-31 17:41:56,250 - root - INFO - CF Training: Epoch 0005 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1960 | Iter Mean Loss 0.2098\n2024-03-31 17:42:14,316 - root - INFO - CF Training: Epoch 0005 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2054 | Iter Mean Loss 0.2097\n2024-03-31 17:42:32,394 - root - INFO - CF Training: Epoch 0005 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2233 | Iter Mean Loss 0.2097\n2024-03-31 17:42:50,449 - root - INFO - CF Training: Epoch 0005 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.2088 | Iter Mean Loss 0.2097\n2024-03-31 17:43:08,498 - root - INFO - CF Training: Epoch 0005 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.1837 | Iter Mean Loss 0.2097\n2024-03-31 17:43:26,563 - root - INFO - CF Training: Epoch 0005 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2034 | Iter Mean Loss 0.2097\n2024-03-31 17:43:44,599 - root - INFO - CF Training: Epoch 0005 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2087 | Iter Mean Loss 0.2096\n2024-03-31 17:44:02,661 - root - INFO - CF Training: Epoch 0005 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.1899 | Iter Mean Loss 0.2096\n2024-03-31 17:44:20,725 - root - INFO - CF Training: Epoch 0005 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2238 | Iter Mean Loss 0.2096\n2024-03-31 17:44:38,828 - root - INFO - CF Training: Epoch 0005 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.1970 | Iter Mean Loss 0.2096\n2024-03-31 17:44:56,849 - root - INFO - CF Training: Epoch 0005 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2005 | Iter Mean Loss 0.2095\n2024-03-31 17:45:00,462 - root - INFO - CF Training: Epoch 0005 Total Iter 5410 | Total Time 1952.1s | Iter Mean Loss 0.2095\n2024-03-31 17:45:06,085 - root - INFO - KG Training: Epoch 0005 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0089\n2024-03-31 17:45:11,848 - root - INFO - KG Training: Epoch 0005 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0089\n2024-03-31 17:45:17,477 - root - INFO - KG Training: Epoch 0005 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0089\n2024-03-31 17:45:23,097 - root - INFO - KG Training: Epoch 0005 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0091\n2024-03-31 17:45:28,914 - root - INFO - KG Training: Epoch 0005 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0091\n2024-03-31 17:45:34,608 - root - INFO - KG Training: Epoch 0005 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0090\n2024-03-31 17:45:40,230 - root - INFO - KG Training: Epoch 0005 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0091\n2024-03-31 17:45:45,937 - root - INFO - KG Training: Epoch 0005 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0092\n2024-03-31 17:45:51,624 - root - INFO - KG Training: Epoch 0005 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0092\n2024-03-31 17:45:57,247 - root - INFO - KG Training: Epoch 0005 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0141 | Iter Mean Loss 0.0091\n2024-03-31 17:46:03,037 - root - INFO - KG Training: Epoch 0005 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0091\n2024-03-31 17:46:08,679 - root - INFO - KG Training: Epoch 0005 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0091\n2024-03-31 17:46:14,440 - root - INFO - KG Training: Epoch 0005 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0091\n2024-03-31 17:46:19,975 - root - INFO - KG Training: Epoch 0005 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0091\n2024-03-31 17:46:25,697 - root - INFO - KG Training: Epoch 0005 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0091\n2024-03-31 17:46:31,499 - root - INFO - KG Training: Epoch 0005 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0091\n2024-03-31 17:46:37,093 - root - INFO - KG Training: Epoch 0005 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0090\n2024-03-31 17:46:42,788 - root - INFO - KG Training: Epoch 0005 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0090\n2024-03-31 17:46:48,569 - root - INFO - KG Training: Epoch 0005 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0090\n2024-03-31 17:46:54,239 - root - INFO - KG Training: Epoch 0005 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0090\n2024-03-31 17:46:59,835 - root - INFO - KG Training: Epoch 0005 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0090\n2024-03-31 17:47:05,558 - root - INFO - KG Training: Epoch 0005 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0144 | Iter Mean Loss 0.0090\n2024-03-31 17:47:11,171 - root - INFO - KG Training: Epoch 0005 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0090\n2024-03-31 17:47:16,952 - root - INFO - KG Training: Epoch 0005 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0091\n2024-03-31 17:47:22,568 - root - INFO - KG Training: Epoch 0005 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0090\n2024-03-31 17:47:28,223 - root - INFO - KG Training: Epoch 0005 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0090\n2024-03-31 17:47:33,884 - root - INFO - KG Training: Epoch 0005 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0090\n2024-03-31 17:47:39,530 - root - INFO - KG Training: Epoch 0005 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0090\n2024-03-31 17:47:45,071 - root - INFO - KG Training: Epoch 0005 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0090\n2024-03-31 17:47:50,663 - root - INFO - KG Training: Epoch 0005 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0090\n2024-03-31 17:47:56,329 - root - INFO - KG Training: Epoch 0005 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0090\n2024-03-31 17:48:01,914 - root - INFO - KG Training: Epoch 0005 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0090\n2024-03-31 17:48:07,635 - root - INFO - KG Training: Epoch 0005 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0090\n2024-03-31 17:48:13,149 - root - INFO - KG Training: Epoch 0005 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0130 | Iter Mean Loss 0.0089\n2024-03-31 17:48:18,893 - root - INFO - KG Training: Epoch 0005 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0089\n2024-03-31 17:48:24,566 - root - INFO - KG Training: Epoch 0005 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0089\n2024-03-31 17:48:30,076 - root - INFO - KG Training: Epoch 0005 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0089\n2024-03-31 17:48:35,709 - root - INFO - KG Training: Epoch 0005 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0089\n2024-03-31 17:48:41,410 - root - INFO - KG Training: Epoch 0005 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0089\n2024-03-31 17:48:47,082 - root - INFO - KG Training: Epoch 0005 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0089\n2024-03-31 17:48:52,737 - root - INFO - KG Training: Epoch 0005 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0089\n2024-03-31 17:48:58,272 - root - INFO - KG Training: Epoch 0005 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0089\n2024-03-31 17:49:03,848 - root - INFO - KG Training: Epoch 0005 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0139 | Iter Mean Loss 0.0089\n2024-03-31 17:49:09,409 - root - INFO - KG Training: Epoch 0005 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0089\n2024-03-31 17:49:15,007 - root - INFO - KG Training: Epoch 0005 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0089\n2024-03-31 17:49:20,550 - root - INFO - KG Training: Epoch 0005 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0089\n2024-03-31 17:49:26,056 - root - INFO - KG Training: Epoch 0005 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0089\n2024-03-31 17:49:31,526 - root - INFO - KG Training: Epoch 0005 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0089\n2024-03-31 17:49:37,028 - root - INFO - KG Training: Epoch 0005 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0089\n2024-03-31 17:49:42,610 - root - INFO - KG Training: Epoch 0005 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0088\n2024-03-31 17:49:48,172 - root - INFO - KG Training: Epoch 0005 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0089\n2024-03-31 17:49:53,732 - root - INFO - KG Training: Epoch 0005 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0089\n2024-03-31 17:49:59,231 - root - INFO - KG Training: Epoch 0005 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0088\n2024-03-31 17:50:04,747 - root - INFO - KG Training: Epoch 0005 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0088\n2024-03-31 17:50:10,213 - root - INFO - KG Training: Epoch 0005 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0088\n2024-03-31 17:50:15,716 - root - INFO - KG Training: Epoch 0005 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0088\n2024-03-31 17:50:21,233 - root - INFO - KG Training: Epoch 0005 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0088\n2024-03-31 17:50:26,877 - root - INFO - KG Training: Epoch 0005 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0088\n2024-03-31 17:50:32,382 - root - INFO - KG Training: Epoch 0005 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0143 | Iter Mean Loss 0.0088\n2024-03-31 17:50:37,888 - root - INFO - KG Training: Epoch 0005 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0088\n2024-03-31 17:50:43,469 - root - INFO - KG Training: Epoch 0005 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0088\n2024-03-31 17:50:48,890 - root - INFO - KG Training: Epoch 0005 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0088\n2024-03-31 17:50:54,408 - root - INFO - KG Training: Epoch 0005 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0088\n2024-03-31 17:50:59,872 - root - INFO - KG Training: Epoch 0005 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0088\n2024-03-31 17:51:05,367 - root - INFO - KG Training: Epoch 0005 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0088\n2024-03-31 17:51:10,904 - root - INFO - KG Training: Epoch 0005 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0088\n2024-03-31 17:51:16,316 - root - INFO - KG Training: Epoch 0005 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0088\n2024-03-31 17:51:21,672 - root - INFO - KG Training: Epoch 0005 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0088\n2024-03-31 17:51:27,111 - root - INFO - KG Training: Epoch 0005 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0088\n2024-03-31 17:51:32,534 - root - INFO - KG Training: Epoch 0005 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0126 | Iter Mean Loss 0.0088\n2024-03-31 17:51:37,973 - root - INFO - KG Training: Epoch 0005 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0088\n2024-03-31 17:51:43,367 - root - INFO - KG Training: Epoch 0005 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0088\n2024-03-31 17:51:48,855 - root - INFO - KG Training: Epoch 0005 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0088\n2024-03-31 17:51:54,272 - root - INFO - KG Training: Epoch 0005 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0088\n2024-03-31 17:51:59,750 - root - INFO - KG Training: Epoch 0005 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0126 | Iter Mean Loss 0.0088\n2024-03-31 17:52:05,296 - root - INFO - KG Training: Epoch 0005 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0088\n2024-03-31 17:52:10,713 - root - INFO - KG Training: Epoch 0005 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0088\n2024-03-31 17:52:16,184 - root - INFO - KG Training: Epoch 0005 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0088\n2024-03-31 17:52:21,818 - root - INFO - KG Training: Epoch 0005 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0088\n2024-03-31 17:52:27,235 - root - INFO - KG Training: Epoch 0005 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0088\n2024-03-31 17:52:32,781 - root - INFO - KG Training: Epoch 0005 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0088\n2024-03-31 17:52:38,285 - root - INFO - KG Training: Epoch 0005 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0088\n2024-03-31 17:52:43,934 - root - INFO - KG Training: Epoch 0005 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0088\n2024-03-31 17:52:49,466 - root - INFO - KG Training: Epoch 0005 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0088\n2024-03-31 17:52:54,932 - root - INFO - KG Training: Epoch 0005 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0088\n2024-03-31 17:53:00,575 - root - INFO - KG Training: Epoch 0005 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0088\n2024-03-31 17:53:06,198 - root - INFO - KG Training: Epoch 0005 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0138 | Iter Mean Loss 0.0088\n2024-03-31 17:53:11,719 - root - INFO - KG Training: Epoch 0005 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0088\n2024-03-31 17:53:17,369 - root - INFO - KG Training: Epoch 0005 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0088\n2024-03-31 17:53:23,006 - root - INFO - KG Training: Epoch 0005 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0088\n2024-03-31 17:53:28,638 - root - INFO - KG Training: Epoch 0005 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0088\n2024-03-31 17:53:34,389 - root - INFO - KG Training: Epoch 0005 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0088\n2024-03-31 17:53:39,944 - root - INFO - KG Training: Epoch 0005 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0088\n2024-03-31 17:53:45,737 - root - INFO - KG Training: Epoch 0005 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0053 | Iter Mean Loss 0.0088\n2024-03-31 17:53:51,441 - root - INFO - KG Training: Epoch 0005 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0088\n2024-03-31 17:53:57,108 - root - INFO - KG Training: Epoch 0005 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0088\n2024-03-31 17:54:02,651 - root - INFO - KG Training: Epoch 0005 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0088\n2024-03-31 17:54:08,238 - root - INFO - KG Training: Epoch 0005 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0088\n2024-03-31 17:54:13,719 - root - INFO - KG Training: Epoch 0005 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0088\n2024-03-31 17:54:19,275 - root - INFO - KG Training: Epoch 0005 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0088\n2024-03-31 17:54:24,861 - root - INFO - KG Training: Epoch 0005 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0088\n2024-03-31 17:54:30,384 - root - INFO - KG Training: Epoch 0005 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0133 | Iter Mean Loss 0.0088\n2024-03-31 17:54:35,978 - root - INFO - KG Training: Epoch 0005 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0088\n2024-03-31 17:54:41,482 - root - INFO - KG Training: Epoch 0005 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0088\n2024-03-31 17:54:47,163 - root - INFO - KG Training: Epoch 0005 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0088\n2024-03-31 17:54:52,724 - root - INFO - KG Training: Epoch 0005 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0088\n2024-03-31 17:54:58,184 - root - INFO - KG Training: Epoch 0005 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0088\n2024-03-31 17:55:03,705 - root - INFO - KG Training: Epoch 0005 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0088\n2024-03-31 17:55:08,322 - root - INFO - KG Training: Epoch 0005 Total Iter 5442 | Total Time 607.9s | Iter Mean Loss 0.0088\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 17:55:10,893 - root - INFO - Update Attention: Epoch 0005 | Total Time 2.6s\n2024-03-31 17:55:10,893 - root - INFO - CF + KG Training: Epoch 0005 | Total Time 2562.5s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:10<00:00,  5.45it/s]\n2024-03-31 17:57:21,622 - root - INFO - CF Evaluation: Epoch 0005 | Total Time 130.7s | Precision [0.0258, 0.0162], Recall [0.1593, 0.4502], NDCG [0.0884, 0.1652]\n2024-03-31 17:57:22,123 - root - INFO - Save model on epoch 0005!\n2024-03-31 17:57:40,150 - root - INFO - CF Training: Epoch 0006 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2229 | Iter Mean Loss 0.2140\n2024-03-31 17:57:58,155 - root - INFO - CF Training: Epoch 0006 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2198 | Iter Mean Loss 0.2101\n2024-03-31 17:58:16,149 - root - INFO - CF Training: Epoch 0006 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.1966 | Iter Mean Loss 0.2104\n2024-03-31 17:58:34,153 - root - INFO - CF Training: Epoch 0006 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2064 | Iter Mean Loss 0.2095\n2024-03-31 17:58:52,144 - root - INFO - CF Training: Epoch 0006 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.2092\n2024-03-31 17:59:10,180 - root - INFO - CF Training: Epoch 0006 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2227 | Iter Mean Loss 0.2088\n2024-03-31 17:59:28,193 - root - INFO - CF Training: Epoch 0006 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2342 | Iter Mean Loss 0.2089\n2024-03-31 17:59:46,183 - root - INFO - CF Training: Epoch 0006 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.2091\n2024-03-31 18:00:04,212 - root - INFO - CF Training: Epoch 0006 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2238 | Iter Mean Loss 0.2088\n2024-03-31 18:00:22,190 - root - INFO - CF Training: Epoch 0006 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2036 | Iter Mean Loss 0.2087\n2024-03-31 18:00:40,237 - root - INFO - CF Training: Epoch 0006 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2085\n2024-03-31 18:00:58,253 - root - INFO - CF Training: Epoch 0006 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2085\n2024-03-31 18:01:16,258 - root - INFO - CF Training: Epoch 0006 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2107 | Iter Mean Loss 0.2085\n2024-03-31 18:01:34,299 - root - INFO - CF Training: Epoch 0006 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.1982 | Iter Mean Loss 0.2083\n2024-03-31 18:01:52,284 - root - INFO - CF Training: Epoch 0006 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.2082\n2024-03-31 18:02:10,321 - root - INFO - CF Training: Epoch 0006 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2071 | Iter Mean Loss 0.2083\n2024-03-31 18:02:28,351 - root - INFO - CF Training: Epoch 0006 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2246 | Iter Mean Loss 0.2081\n2024-03-31 18:02:46,374 - root - INFO - CF Training: Epoch 0006 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2227 | Iter Mean Loss 0.2081\n2024-03-31 18:03:04,439 - root - INFO - CF Training: Epoch 0006 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.2048 | Iter Mean Loss 0.2081\n2024-03-31 18:03:22,467 - root - INFO - CF Training: Epoch 0006 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.2068 | Iter Mean Loss 0.2081\n2024-03-31 18:03:40,493 - root - INFO - CF Training: Epoch 0006 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.1871 | Iter Mean Loss 0.2080\n2024-03-31 18:03:58,505 - root - INFO - CF Training: Epoch 0006 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.1982 | Iter Mean Loss 0.2078\n2024-03-31 18:04:16,554 - root - INFO - CF Training: Epoch 0006 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.1914 | Iter Mean Loss 0.2078\n2024-03-31 18:04:34,603 - root - INFO - CF Training: Epoch 0006 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2012 | Iter Mean Loss 0.2078\n2024-03-31 18:04:52,603 - root - INFO - CF Training: Epoch 0006 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.2008 | Iter Mean Loss 0.2078\n2024-03-31 18:05:10,643 - root - INFO - CF Training: Epoch 0006 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2042 | Iter Mean Loss 0.2077\n2024-03-31 18:05:28,674 - root - INFO - CF Training: Epoch 0006 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.2200 | Iter Mean Loss 0.2077\n2024-03-31 18:05:46,757 - root - INFO - CF Training: Epoch 0006 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2248 | Iter Mean Loss 0.2077\n2024-03-31 18:06:04,852 - root - INFO - CF Training: Epoch 0006 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1914 | Iter Mean Loss 0.2077\n2024-03-31 18:06:22,872 - root - INFO - CF Training: Epoch 0006 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.1947 | Iter Mean Loss 0.2077\n2024-03-31 18:06:40,931 - root - INFO - CF Training: Epoch 0006 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2330 | Iter Mean Loss 0.2077\n2024-03-31 18:06:58,985 - root - INFO - CF Training: Epoch 0006 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1978 | Iter Mean Loss 0.2077\n2024-03-31 18:07:17,085 - root - INFO - CF Training: Epoch 0006 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2144 | Iter Mean Loss 0.2077\n2024-03-31 18:07:35,117 - root - INFO - CF Training: Epoch 0006 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2022 | Iter Mean Loss 0.2077\n2024-03-31 18:07:53,204 - root - INFO - CF Training: Epoch 0006 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2046 | Iter Mean Loss 0.2076\n2024-03-31 18:08:11,239 - root - INFO - CF Training: Epoch 0006 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2154 | Iter Mean Loss 0.2076\n2024-03-31 18:08:29,243 - root - INFO - CF Training: Epoch 0006 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.1952 | Iter Mean Loss 0.2076\n2024-03-31 18:08:47,243 - root - INFO - CF Training: Epoch 0006 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.2201 | Iter Mean Loss 0.2075\n2024-03-31 18:09:05,227 - root - INFO - CF Training: Epoch 0006 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2048 | Iter Mean Loss 0.2075\n2024-03-31 18:09:23,248 - root - INFO - CF Training: Epoch 0006 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2024 | Iter Mean Loss 0.2074\n2024-03-31 18:09:41,287 - root - INFO - CF Training: Epoch 0006 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2158 | Iter Mean Loss 0.2074\n2024-03-31 18:09:59,334 - root - INFO - CF Training: Epoch 0006 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2076 | Iter Mean Loss 0.2074\n2024-03-31 18:10:17,381 - root - INFO - CF Training: Epoch 0006 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2089 | Iter Mean Loss 0.2074\n2024-03-31 18:10:35,432 - root - INFO - CF Training: Epoch 0006 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2006 | Iter Mean Loss 0.2074\n2024-03-31 18:10:53,510 - root - INFO - CF Training: Epoch 0006 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.1971 | Iter Mean Loss 0.2073\n2024-03-31 18:11:11,600 - root - INFO - CF Training: Epoch 0006 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2085 | Iter Mean Loss 0.2073\n2024-03-31 18:11:29,698 - root - INFO - CF Training: Epoch 0006 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2094 | Iter Mean Loss 0.2073\n2024-03-31 18:11:47,725 - root - INFO - CF Training: Epoch 0006 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.2072\n2024-03-31 18:12:05,804 - root - INFO - CF Training: Epoch 0006 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.2000 | Iter Mean Loss 0.2072\n2024-03-31 18:12:23,843 - root - INFO - CF Training: Epoch 0006 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2269 | Iter Mean Loss 0.2072\n2024-03-31 18:12:41,875 - root - INFO - CF Training: Epoch 0006 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2007 | Iter Mean Loss 0.2072\n2024-03-31 18:12:59,918 - root - INFO - CF Training: Epoch 0006 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.2018 | Iter Mean Loss 0.2071\n2024-03-31 18:13:17,973 - root - INFO - CF Training: Epoch 0006 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2060 | Iter Mean Loss 0.2071\n2024-03-31 18:13:36,001 - root - INFO - CF Training: Epoch 0006 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2072 | Iter Mean Loss 0.2071\n2024-03-31 18:13:54,014 - root - INFO - CF Training: Epoch 0006 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.2073 | Iter Mean Loss 0.2071\n2024-03-31 18:14:12,065 - root - INFO - CF Training: Epoch 0006 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2189 | Iter Mean Loss 0.2071\n2024-03-31 18:14:30,135 - root - INFO - CF Training: Epoch 0006 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2153 | Iter Mean Loss 0.2070\n2024-03-31 18:14:48,157 - root - INFO - CF Training: Epoch 0006 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2070\n2024-03-31 18:15:06,197 - root - INFO - CF Training: Epoch 0006 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2001 | Iter Mean Loss 0.2070\n2024-03-31 18:15:24,253 - root - INFO - CF Training: Epoch 0006 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2013 | Iter Mean Loss 0.2070\n2024-03-31 18:15:42,325 - root - INFO - CF Training: Epoch 0006 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.1983 | Iter Mean Loss 0.2069\n2024-03-31 18:16:00,371 - root - INFO - CF Training: Epoch 0006 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2023 | Iter Mean Loss 0.2069\n2024-03-31 18:16:18,421 - root - INFO - CF Training: Epoch 0006 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.1938 | Iter Mean Loss 0.2068\n2024-03-31 18:16:36,518 - root - INFO - CF Training: Epoch 0006 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2021 | Iter Mean Loss 0.2068\n2024-03-31 18:16:54,547 - root - INFO - CF Training: Epoch 0006 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.1984 | Iter Mean Loss 0.2068\n2024-03-31 18:17:12,593 - root - INFO - CF Training: Epoch 0006 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2038 | Iter Mean Loss 0.2068\n2024-03-31 18:17:30,631 - root - INFO - CF Training: Epoch 0006 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.1968 | Iter Mean Loss 0.2067\n2024-03-31 18:17:48,667 - root - INFO - CF Training: Epoch 0006 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2110 | Iter Mean Loss 0.2067\n2024-03-31 18:18:06,744 - root - INFO - CF Training: Epoch 0006 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.2043 | Iter Mean Loss 0.2067\n2024-03-31 18:18:24,834 - root - INFO - CF Training: Epoch 0006 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.1988 | Iter Mean Loss 0.2067\n2024-03-31 18:18:42,907 - root - INFO - CF Training: Epoch 0006 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.2098 | Iter Mean Loss 0.2067\n2024-03-31 18:19:01,008 - root - INFO - CF Training: Epoch 0006 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2017 | Iter Mean Loss 0.2066\n2024-03-31 18:19:19,061 - root - INFO - CF Training: Epoch 0006 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2077 | Iter Mean Loss 0.2066\n2024-03-31 18:19:37,152 - root - INFO - CF Training: Epoch 0006 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2037 | Iter Mean Loss 0.2065\n2024-03-31 18:19:55,220 - root - INFO - CF Training: Epoch 0006 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.1955 | Iter Mean Loss 0.2066\n2024-03-31 18:20:13,298 - root - INFO - CF Training: Epoch 0006 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.1889 | Iter Mean Loss 0.2065\n2024-03-31 18:20:31,399 - root - INFO - CF Training: Epoch 0006 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2165 | Iter Mean Loss 0.2065\n2024-03-31 18:20:49,484 - root - INFO - CF Training: Epoch 0006 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2065\n2024-03-31 18:21:07,581 - root - INFO - CF Training: Epoch 0006 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2049 | Iter Mean Loss 0.2065\n2024-03-31 18:21:25,681 - root - INFO - CF Training: Epoch 0006 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.1953 | Iter Mean Loss 0.2065\n2024-03-31 18:21:43,833 - root - INFO - CF Training: Epoch 0006 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2076 | Iter Mean Loss 0.2065\n2024-03-31 18:22:01,974 - root - INFO - CF Training: Epoch 0006 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2072 | Iter Mean Loss 0.2065\n2024-03-31 18:22:20,069 - root - INFO - CF Training: Epoch 0006 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.2064\n2024-03-31 18:22:38,194 - root - INFO - CF Training: Epoch 0006 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.2072 | Iter Mean Loss 0.2064\n2024-03-31 18:22:56,293 - root - INFO - CF Training: Epoch 0006 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.1822 | Iter Mean Loss 0.2064\n2024-03-31 18:23:14,393 - root - INFO - CF Training: Epoch 0006 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2092 | Iter Mean Loss 0.2063\n2024-03-31 18:23:32,469 - root - INFO - CF Training: Epoch 0006 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.1861 | Iter Mean Loss 0.2063\n2024-03-31 18:23:50,530 - root - INFO - CF Training: Epoch 0006 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.1864 | Iter Mean Loss 0.2063\n2024-03-31 18:24:08,580 - root - INFO - CF Training: Epoch 0006 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.1932 | Iter Mean Loss 0.2063\n2024-03-31 18:24:26,624 - root - INFO - CF Training: Epoch 0006 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.1970 | Iter Mean Loss 0.2062\n2024-03-31 18:24:44,680 - root - INFO - CF Training: Epoch 0006 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.1958 | Iter Mean Loss 0.2062\n2024-03-31 18:25:02,707 - root - INFO - CF Training: Epoch 0006 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.1945 | Iter Mean Loss 0.2062\n2024-03-31 18:25:20,738 - root - INFO - CF Training: Epoch 0006 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.1987 | Iter Mean Loss 0.2062\n2024-03-31 18:25:38,813 - root - INFO - CF Training: Epoch 0006 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2057 | Iter Mean Loss 0.2062\n2024-03-31 18:25:56,880 - root - INFO - CF Training: Epoch 0006 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2015 | Iter Mean Loss 0.2061\n2024-03-31 18:26:14,940 - root - INFO - CF Training: Epoch 0006 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.1956 | Iter Mean Loss 0.2061\n2024-03-31 18:26:32,962 - root - INFO - CF Training: Epoch 0006 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2214 | Iter Mean Loss 0.2061\n2024-03-31 18:26:51,028 - root - INFO - CF Training: Epoch 0006 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.2037 | Iter Mean Loss 0.2061\n2024-03-31 18:27:09,098 - root - INFO - CF Training: Epoch 0006 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2121 | Iter Mean Loss 0.2061\n2024-03-31 18:27:27,161 - root - INFO - CF Training: Epoch 0006 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.1890 | Iter Mean Loss 0.2061\n2024-03-31 18:27:45,244 - root - INFO - CF Training: Epoch 0006 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.1959 | Iter Mean Loss 0.2061\n2024-03-31 18:28:03,279 - root - INFO - CF Training: Epoch 0006 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2008 | Iter Mean Loss 0.2060\n2024-03-31 18:28:21,372 - root - INFO - CF Training: Epoch 0006 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2089 | Iter Mean Loss 0.2060\n2024-03-31 18:28:39,468 - root - INFO - CF Training: Epoch 0006 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.1941 | Iter Mean Loss 0.2060\n2024-03-31 18:28:57,577 - root - INFO - CF Training: Epoch 0006 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2183 | Iter Mean Loss 0.2059\n2024-03-31 18:29:15,701 - root - INFO - CF Training: Epoch 0006 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2180 | Iter Mean Loss 0.2059\n2024-03-31 18:29:33,791 - root - INFO - CF Training: Epoch 0006 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2174 | Iter Mean Loss 0.2059\n2024-03-31 18:29:51,835 - root - INFO - CF Training: Epoch 0006 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2105 | Iter Mean Loss 0.2059\n2024-03-31 18:29:55,468 - root - INFO - CF Training: Epoch 0006 Total Iter 5410 | Total Time 1953.3s | Iter Mean Loss 0.2059\n2024-03-31 18:30:01,149 - root - INFO - KG Training: Epoch 0006 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0088\n2024-03-31 18:30:06,664 - root - INFO - KG Training: Epoch 0006 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0088\n2024-03-31 18:30:12,232 - root - INFO - KG Training: Epoch 0006 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0117 | Iter Mean Loss 0.0089\n2024-03-31 18:30:17,717 - root - INFO - KG Training: Epoch 0006 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0087\n2024-03-31 18:30:23,192 - root - INFO - KG Training: Epoch 0006 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0088\n2024-03-31 18:30:28,678 - root - INFO - KG Training: Epoch 0006 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0088\n2024-03-31 18:30:34,266 - root - INFO - KG Training: Epoch 0006 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0088\n2024-03-31 18:30:39,963 - root - INFO - KG Training: Epoch 0006 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0088\n2024-03-31 18:30:45,632 - root - INFO - KG Training: Epoch 0006 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0088\n2024-03-31 18:30:51,185 - root - INFO - KG Training: Epoch 0006 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0087\n2024-03-31 18:30:56,786 - root - INFO - KG Training: Epoch 0006 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0087\n2024-03-31 18:31:02,365 - root - INFO - KG Training: Epoch 0006 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0087\n2024-03-31 18:31:07,922 - root - INFO - KG Training: Epoch 0006 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0087\n2024-03-31 18:31:13,474 - root - INFO - KG Training: Epoch 0006 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0087\n2024-03-31 18:31:19,116 - root - INFO - KG Training: Epoch 0006 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0087\n2024-03-31 18:31:24,710 - root - INFO - KG Training: Epoch 0006 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0087\n2024-03-31 18:31:30,275 - root - INFO - KG Training: Epoch 0006 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0087\n2024-03-31 18:31:35,761 - root - INFO - KG Training: Epoch 0006 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0087\n2024-03-31 18:31:41,274 - root - INFO - KG Training: Epoch 0006 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0087\n2024-03-31 18:31:46,994 - root - INFO - KG Training: Epoch 0006 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0087\n2024-03-31 18:31:52,718 - root - INFO - KG Training: Epoch 0006 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0087\n2024-03-31 18:31:58,284 - root - INFO - KG Training: Epoch 0006 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0120 | Iter Mean Loss 0.0087\n2024-03-31 18:32:03,925 - root - INFO - KG Training: Epoch 0006 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0087\n2024-03-31 18:32:09,554 - root - INFO - KG Training: Epoch 0006 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0087\n2024-03-31 18:32:15,150 - root - INFO - KG Training: Epoch 0006 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0087\n2024-03-31 18:32:20,793 - root - INFO - KG Training: Epoch 0006 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0086\n2024-03-31 18:32:26,368 - root - INFO - KG Training: Epoch 0006 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0086\n2024-03-31 18:32:31,954 - root - INFO - KG Training: Epoch 0006 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0086\n2024-03-31 18:32:37,536 - root - INFO - KG Training: Epoch 0006 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0086\n2024-03-31 18:32:43,038 - root - INFO - KG Training: Epoch 0006 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0086\n2024-03-31 18:32:48,749 - root - INFO - KG Training: Epoch 0006 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0086\n2024-03-31 18:32:54,421 - root - INFO - KG Training: Epoch 0006 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0086\n2024-03-31 18:33:00,184 - root - INFO - KG Training: Epoch 0006 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0086\n2024-03-31 18:33:05,891 - root - INFO - KG Training: Epoch 0006 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0086\n2024-03-31 18:33:11,666 - root - INFO - KG Training: Epoch 0006 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0086\n2024-03-31 18:33:17,402 - root - INFO - KG Training: Epoch 0006 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0086\n2024-03-31 18:33:23,129 - root - INFO - KG Training: Epoch 0006 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0086\n2024-03-31 18:33:28,882 - root - INFO - KG Training: Epoch 0006 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0138 | Iter Mean Loss 0.0086\n2024-03-31 18:33:34,566 - root - INFO - KG Training: Epoch 0006 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0086\n2024-03-31 18:33:40,196 - root - INFO - KG Training: Epoch 0006 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0086\n2024-03-31 18:33:45,840 - root - INFO - KG Training: Epoch 0006 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0086\n2024-03-31 18:33:51,673 - root - INFO - KG Training: Epoch 0006 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0086\n2024-03-31 18:33:57,345 - root - INFO - KG Training: Epoch 0006 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0086\n2024-03-31 18:34:02,969 - root - INFO - KG Training: Epoch 0006 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0086\n2024-03-31 18:34:08,684 - root - INFO - KG Training: Epoch 0006 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0086\n2024-03-31 18:34:14,538 - root - INFO - KG Training: Epoch 0006 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0085\n2024-03-31 18:34:20,326 - root - INFO - KG Training: Epoch 0006 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0085\n2024-03-31 18:34:26,277 - root - INFO - KG Training: Epoch 0006 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0040 | Iter Mean Loss 0.0085\n2024-03-31 18:34:32,206 - root - INFO - KG Training: Epoch 0006 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0085\n2024-03-31 18:34:38,108 - root - INFO - KG Training: Epoch 0006 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0085\n2024-03-31 18:34:43,998 - root - INFO - KG Training: Epoch 0006 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0085\n2024-03-31 18:34:49,952 - root - INFO - KG Training: Epoch 0006 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0085\n2024-03-31 18:34:55,945 - root - INFO - KG Training: Epoch 0006 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0085\n2024-03-31 18:35:01,814 - root - INFO - KG Training: Epoch 0006 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0133 | Iter Mean Loss 0.0085\n2024-03-31 18:35:07,718 - root - INFO - KG Training: Epoch 0006 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0085\n2024-03-31 18:35:13,664 - root - INFO - KG Training: Epoch 0006 Iter 2800 / 5442 | Time 0.2s | Iter Loss 0.0100 | Iter Mean Loss 0.0085\n2024-03-31 18:35:19,236 - root - INFO - KG Training: Epoch 0006 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0085\n2024-03-31 18:35:24,957 - root - INFO - KG Training: Epoch 0006 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0085\n2024-03-31 18:35:30,522 - root - INFO - KG Training: Epoch 0006 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0085\n2024-03-31 18:35:36,162 - root - INFO - KG Training: Epoch 0006 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0085\n2024-03-31 18:35:41,928 - root - INFO - KG Training: Epoch 0006 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0085\n2024-03-31 18:35:47,572 - root - INFO - KG Training: Epoch 0006 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0085\n2024-03-31 18:35:53,113 - root - INFO - KG Training: Epoch 0006 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0112 | Iter Mean Loss 0.0085\n2024-03-31 18:35:58,700 - root - INFO - KG Training: Epoch 0006 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0085\n2024-03-31 18:36:04,294 - root - INFO - KG Training: Epoch 0006 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0156 | Iter Mean Loss 0.0085\n2024-03-31 18:36:09,801 - root - INFO - KG Training: Epoch 0006 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0085\n2024-03-31 18:36:15,306 - root - INFO - KG Training: Epoch 0006 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0085\n2024-03-31 18:36:20,768 - root - INFO - KG Training: Epoch 0006 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0085\n2024-03-31 18:36:26,474 - root - INFO - KG Training: Epoch 0006 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0085\n2024-03-31 18:36:31,989 - root - INFO - KG Training: Epoch 0006 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0085\n2024-03-31 18:36:37,547 - root - INFO - KG Training: Epoch 0006 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0085\n2024-03-31 18:36:43,077 - root - INFO - KG Training: Epoch 0006 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0085\n2024-03-31 18:36:48,591 - root - INFO - KG Training: Epoch 0006 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0085\n2024-03-31 18:36:54,253 - root - INFO - KG Training: Epoch 0006 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0085\n2024-03-31 18:36:59,849 - root - INFO - KG Training: Epoch 0006 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0085\n2024-03-31 18:37:05,484 - root - INFO - KG Training: Epoch 0006 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0085\n2024-03-31 18:37:11,060 - root - INFO - KG Training: Epoch 0006 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0085\n2024-03-31 18:37:16,658 - root - INFO - KG Training: Epoch 0006 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0085\n2024-03-31 18:37:22,240 - root - INFO - KG Training: Epoch 0006 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0085\n2024-03-31 18:37:27,786 - root - INFO - KG Training: Epoch 0006 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0085\n2024-03-31 18:37:33,339 - root - INFO - KG Training: Epoch 0006 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0046 | Iter Mean Loss 0.0085\n2024-03-31 18:37:38,866 - root - INFO - KG Training: Epoch 0006 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0085\n2024-03-31 18:37:44,360 - root - INFO - KG Training: Epoch 0006 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0085\n2024-03-31 18:37:49,823 - root - INFO - KG Training: Epoch 0006 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0085\n2024-03-31 18:37:55,424 - root - INFO - KG Training: Epoch 0006 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0085\n2024-03-31 18:38:01,057 - root - INFO - KG Training: Epoch 0006 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0085\n2024-03-31 18:38:06,569 - root - INFO - KG Training: Epoch 0006 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0085\n2024-03-31 18:38:12,051 - root - INFO - KG Training: Epoch 0006 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0085\n2024-03-31 18:38:17,495 - root - INFO - KG Training: Epoch 0006 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0085\n2024-03-31 18:38:22,968 - root - INFO - KG Training: Epoch 0006 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0085\n2024-03-31 18:38:28,490 - root - INFO - KG Training: Epoch 0006 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0085\n2024-03-31 18:38:34,018 - root - INFO - KG Training: Epoch 0006 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0085\n2024-03-31 18:38:39,491 - root - INFO - KG Training: Epoch 0006 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0085\n2024-03-31 18:38:44,968 - root - INFO - KG Training: Epoch 0006 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0085\n2024-03-31 18:38:50,386 - root - INFO - KG Training: Epoch 0006 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0085\n2024-03-31 18:38:55,895 - root - INFO - KG Training: Epoch 0006 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0085\n2024-03-31 18:39:01,538 - root - INFO - KG Training: Epoch 0006 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0085\n2024-03-31 18:39:07,201 - root - INFO - KG Training: Epoch 0006 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0085\n2024-03-31 18:39:12,722 - root - INFO - KG Training: Epoch 0006 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0085\n2024-03-31 18:39:18,168 - root - INFO - KG Training: Epoch 0006 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0085\n2024-03-31 18:39:23,653 - root - INFO - KG Training: Epoch 0006 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0085\n2024-03-31 18:39:29,248 - root - INFO - KG Training: Epoch 0006 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0085\n2024-03-31 18:39:34,737 - root - INFO - KG Training: Epoch 0006 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0085\n2024-03-31 18:39:40,191 - root - INFO - KG Training: Epoch 0006 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0085\n2024-03-31 18:39:45,693 - root - INFO - KG Training: Epoch 0006 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0085\n2024-03-31 18:39:51,207 - root - INFO - KG Training: Epoch 0006 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0085\n2024-03-31 18:39:56,743 - root - INFO - KG Training: Epoch 0006 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0044 | Iter Mean Loss 0.0085\n2024-03-31 18:40:02,295 - root - INFO - KG Training: Epoch 0006 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0147 | Iter Mean Loss 0.0085\n2024-03-31 18:40:07,116 - root - INFO - KG Training: Epoch 0006 Total Iter 5442 | Total Time 611.6s | Iter Mean Loss 0.0085\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 18:40:09,696 - root - INFO - Update Attention: Epoch 0006 | Total Time 2.6s\n2024-03-31 18:40:09,696 - root - INFO - CF + KG Training: Epoch 0006 | Total Time 2567.6s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:11<00:00,  5.42it/s]\n2024-03-31 18:42:21,199 - root - INFO - CF Evaluation: Epoch 0006 | Total Time 131.5s | Precision [0.0263, 0.0165], Recall [0.1616, 0.4559], NDCG [0.0897, 0.1674]\n2024-03-31 18:42:21,710 - root - INFO - Save model on epoch 0006!\n2024-03-31 18:42:39,798 - root - INFO - CF Training: Epoch 0007 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.1981 | Iter Mean Loss 0.2111\n2024-03-31 18:42:57,808 - root - INFO - CF Training: Epoch 0007 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2066 | Iter Mean Loss 0.2096\n2024-03-31 18:43:15,828 - root - INFO - CF Training: Epoch 0007 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2137 | Iter Mean Loss 0.2082\n2024-03-31 18:43:33,788 - root - INFO - CF Training: Epoch 0007 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.1992 | Iter Mean Loss 0.2076\n2024-03-31 18:43:51,772 - root - INFO - CF Training: Epoch 0007 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2100 | Iter Mean Loss 0.2069\n2024-03-31 18:44:09,788 - root - INFO - CF Training: Epoch 0007 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2085 | Iter Mean Loss 0.2066\n2024-03-31 18:44:27,753 - root - INFO - CF Training: Epoch 0007 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.1979 | Iter Mean Loss 0.2065\n2024-03-31 18:44:45,729 - root - INFO - CF Training: Epoch 0007 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2007 | Iter Mean Loss 0.2063\n2024-03-31 18:45:03,722 - root - INFO - CF Training: Epoch 0007 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.2057\n2024-03-31 18:45:21,733 - root - INFO - CF Training: Epoch 0007 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2144 | Iter Mean Loss 0.2054\n2024-03-31 18:45:39,744 - root - INFO - CF Training: Epoch 0007 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2058 | Iter Mean Loss 0.2054\n2024-03-31 18:45:57,777 - root - INFO - CF Training: Epoch 0007 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.2183 | Iter Mean Loss 0.2054\n2024-03-31 18:46:15,794 - root - INFO - CF Training: Epoch 0007 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.1901 | Iter Mean Loss 0.2052\n2024-03-31 18:46:33,744 - root - INFO - CF Training: Epoch 0007 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2007 | Iter Mean Loss 0.2052\n2024-03-31 18:46:51,735 - root - INFO - CF Training: Epoch 0007 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2265 | Iter Mean Loss 0.2051\n2024-03-31 18:47:09,779 - root - INFO - CF Training: Epoch 0007 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2080 | Iter Mean Loss 0.2052\n2024-03-31 18:47:27,848 - root - INFO - CF Training: Epoch 0007 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2002 | Iter Mean Loss 0.2051\n2024-03-31 18:47:45,951 - root - INFO - CF Training: Epoch 0007 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2141 | Iter Mean Loss 0.2050\n2024-03-31 18:48:03,972 - root - INFO - CF Training: Epoch 0007 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.1960 | Iter Mean Loss 0.2049\n2024-03-31 18:48:21,966 - root - INFO - CF Training: Epoch 0007 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.1915 | Iter Mean Loss 0.2050\n2024-03-31 18:48:39,940 - root - INFO - CF Training: Epoch 0007 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.2018 | Iter Mean Loss 0.2049\n2024-03-31 18:48:57,930 - root - INFO - CF Training: Epoch 0007 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.1915 | Iter Mean Loss 0.2050\n2024-03-31 18:49:15,959 - root - INFO - CF Training: Epoch 0007 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.1843 | Iter Mean Loss 0.2049\n2024-03-31 18:49:33,945 - root - INFO - CF Training: Epoch 0007 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.1909 | Iter Mean Loss 0.2048\n2024-03-31 18:49:51,949 - root - INFO - CF Training: Epoch 0007 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.1926 | Iter Mean Loss 0.2047\n2024-03-31 18:50:09,970 - root - INFO - CF Training: Epoch 0007 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2103 | Iter Mean Loss 0.2047\n2024-03-31 18:50:27,991 - root - INFO - CF Training: Epoch 0007 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.2021 | Iter Mean Loss 0.2046\n2024-03-31 18:50:46,053 - root - INFO - CF Training: Epoch 0007 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2205 | Iter Mean Loss 0.2046\n2024-03-31 18:51:04,072 - root - INFO - CF Training: Epoch 0007 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1944 | Iter Mean Loss 0.2046\n2024-03-31 18:51:22,104 - root - INFO - CF Training: Epoch 0007 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2252 | Iter Mean Loss 0.2046\n2024-03-31 18:51:40,175 - root - INFO - CF Training: Epoch 0007 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2024 | Iter Mean Loss 0.2045\n2024-03-31 18:51:58,215 - root - INFO - CF Training: Epoch 0007 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1965 | Iter Mean Loss 0.2045\n2024-03-31 18:52:16,231 - root - INFO - CF Training: Epoch 0007 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2127 | Iter Mean Loss 0.2044\n2024-03-31 18:52:34,268 - root - INFO - CF Training: Epoch 0007 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2013 | Iter Mean Loss 0.2044\n2024-03-31 18:52:52,360 - root - INFO - CF Training: Epoch 0007 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2061 | Iter Mean Loss 0.2043\n2024-03-31 18:53:10,428 - root - INFO - CF Training: Epoch 0007 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.1956 | Iter Mean Loss 0.2044\n2024-03-31 18:53:28,454 - root - INFO - CF Training: Epoch 0007 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.2087 | Iter Mean Loss 0.2043\n2024-03-31 18:53:46,433 - root - INFO - CF Training: Epoch 0007 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.1971 | Iter Mean Loss 0.2043\n2024-03-31 18:54:04,438 - root - INFO - CF Training: Epoch 0007 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2074 | Iter Mean Loss 0.2043\n2024-03-31 18:54:22,444 - root - INFO - CF Training: Epoch 0007 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.1967 | Iter Mean Loss 0.2042\n2024-03-31 18:54:40,418 - root - INFO - CF Training: Epoch 0007 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2166 | Iter Mean Loss 0.2041\n2024-03-31 18:54:58,453 - root - INFO - CF Training: Epoch 0007 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.2253 | Iter Mean Loss 0.2042\n2024-03-31 18:55:16,450 - root - INFO - CF Training: Epoch 0007 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.1897 | Iter Mean Loss 0.2041\n2024-03-31 18:55:34,450 - root - INFO - CF Training: Epoch 0007 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2040\n2024-03-31 18:55:52,485 - root - INFO - CF Training: Epoch 0007 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2251 | Iter Mean Loss 0.2039\n2024-03-31 18:56:10,509 - root - INFO - CF Training: Epoch 0007 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.1916 | Iter Mean Loss 0.2039\n2024-03-31 18:56:28,569 - root - INFO - CF Training: Epoch 0007 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.2104 | Iter Mean Loss 0.2039\n2024-03-31 18:56:46,587 - root - INFO - CF Training: Epoch 0007 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2063 | Iter Mean Loss 0.2040\n2024-03-31 18:57:04,582 - root - INFO - CF Training: Epoch 0007 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.1986 | Iter Mean Loss 0.2039\n2024-03-31 18:57:22,560 - root - INFO - CF Training: Epoch 0007 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.1946 | Iter Mean Loss 0.2038\n2024-03-31 18:57:40,591 - root - INFO - CF Training: Epoch 0007 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.1980 | Iter Mean Loss 0.2038\n2024-03-31 18:57:58,604 - root - INFO - CF Training: Epoch 0007 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.1933 | Iter Mean Loss 0.2038\n2024-03-31 18:58:16,611 - root - INFO - CF Training: Epoch 0007 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2102 | Iter Mean Loss 0.2038\n2024-03-31 18:58:34,622 - root - INFO - CF Training: Epoch 0007 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2091 | Iter Mean Loss 0.2038\n2024-03-31 18:58:52,616 - root - INFO - CF Training: Epoch 0007 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.1833 | Iter Mean Loss 0.2037\n2024-03-31 18:59:10,618 - root - INFO - CF Training: Epoch 0007 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.1961 | Iter Mean Loss 0.2037\n2024-03-31 18:59:28,614 - root - INFO - CF Training: Epoch 0007 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2037\n2024-03-31 18:59:46,647 - root - INFO - CF Training: Epoch 0007 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.1916 | Iter Mean Loss 0.2036\n2024-03-31 19:00:04,676 - root - INFO - CF Training: Epoch 0007 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2174 | Iter Mean Loss 0.2036\n2024-03-31 19:00:22,659 - root - INFO - CF Training: Epoch 0007 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2123 | Iter Mean Loss 0.2036\n2024-03-31 19:00:40,718 - root - INFO - CF Training: Epoch 0007 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.1990 | Iter Mean Loss 0.2036\n2024-03-31 19:00:58,721 - root - INFO - CF Training: Epoch 0007 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2015 | Iter Mean Loss 0.2035\n2024-03-31 19:01:16,714 - root - INFO - CF Training: Epoch 0007 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.2035\n2024-03-31 19:01:34,758 - root - INFO - CF Training: Epoch 0007 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2208 | Iter Mean Loss 0.2035\n2024-03-31 19:01:52,762 - root - INFO - CF Training: Epoch 0007 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2043 | Iter Mean Loss 0.2035\n2024-03-31 19:02:10,769 - root - INFO - CF Training: Epoch 0007 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2176 | Iter Mean Loss 0.2035\n2024-03-31 19:02:28,763 - root - INFO - CF Training: Epoch 0007 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.2143 | Iter Mean Loss 0.2034\n2024-03-31 19:02:46,795 - root - INFO - CF Training: Epoch 0007 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.1999 | Iter Mean Loss 0.2034\n2024-03-31 19:03:04,842 - root - INFO - CF Training: Epoch 0007 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.1986 | Iter Mean Loss 0.2034\n2024-03-31 19:03:22,865 - root - INFO - CF Training: Epoch 0007 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.2251 | Iter Mean Loss 0.2034\n2024-03-31 19:03:40,893 - root - INFO - CF Training: Epoch 0007 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.1866 | Iter Mean Loss 0.2034\n2024-03-31 19:03:58,890 - root - INFO - CF Training: Epoch 0007 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.1906 | Iter Mean Loss 0.2033\n2024-03-31 19:04:16,891 - root - INFO - CF Training: Epoch 0007 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.2077 | Iter Mean Loss 0.2033\n2024-03-31 19:04:34,885 - root - INFO - CF Training: Epoch 0007 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2067 | Iter Mean Loss 0.2034\n2024-03-31 19:04:52,914 - root - INFO - CF Training: Epoch 0007 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2082 | Iter Mean Loss 0.2033\n2024-03-31 19:05:10,916 - root - INFO - CF Training: Epoch 0007 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2126 | Iter Mean Loss 0.2033\n2024-03-31 19:05:28,906 - root - INFO - CF Training: Epoch 0007 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.1942 | Iter Mean Loss 0.2033\n2024-03-31 19:05:46,955 - root - INFO - CF Training: Epoch 0007 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2105 | Iter Mean Loss 0.2032\n2024-03-31 19:06:04,984 - root - INFO - CF Training: Epoch 0007 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.1939 | Iter Mean Loss 0.2032\n2024-03-31 19:06:23,021 - root - INFO - CF Training: Epoch 0007 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2069 | Iter Mean Loss 0.2032\n2024-03-31 19:06:41,013 - root - INFO - CF Training: Epoch 0007 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.1997 | Iter Mean Loss 0.2032\n2024-03-31 19:06:59,042 - root - INFO - CF Training: Epoch 0007 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.2032\n2024-03-31 19:07:17,018 - root - INFO - CF Training: Epoch 0007 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.2039 | Iter Mean Loss 0.2032\n2024-03-31 19:07:35,088 - root - INFO - CF Training: Epoch 0007 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.1996 | Iter Mean Loss 0.2031\n2024-03-31 19:07:53,125 - root - INFO - CF Training: Epoch 0007 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.1943 | Iter Mean Loss 0.2031\n2024-03-31 19:08:11,142 - root - INFO - CF Training: Epoch 0007 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2207 | Iter Mean Loss 0.2031\n2024-03-31 19:08:29,151 - root - INFO - CF Training: Epoch 0007 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.2031\n2024-03-31 19:08:47,173 - root - INFO - CF Training: Epoch 0007 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2170 | Iter Mean Loss 0.2030\n2024-03-31 19:09:05,190 - root - INFO - CF Training: Epoch 0007 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2087 | Iter Mean Loss 0.2030\n2024-03-31 19:09:23,189 - root - INFO - CF Training: Epoch 0007 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.1879 | Iter Mean Loss 0.2030\n2024-03-31 19:09:41,182 - root - INFO - CF Training: Epoch 0007 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.1825 | Iter Mean Loss 0.2029\n2024-03-31 19:09:59,210 - root - INFO - CF Training: Epoch 0007 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2131 | Iter Mean Loss 0.2029\n2024-03-31 19:10:17,228 - root - INFO - CF Training: Epoch 0007 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2186 | Iter Mean Loss 0.2029\n2024-03-31 19:10:35,282 - root - INFO - CF Training: Epoch 0007 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.1983 | Iter Mean Loss 0.2029\n2024-03-31 19:10:53,358 - root - INFO - CF Training: Epoch 0007 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2178 | Iter Mean Loss 0.2029\n2024-03-31 19:11:11,383 - root - INFO - CF Training: Epoch 0007 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.1908 | Iter Mean Loss 0.2029\n2024-03-31 19:11:29,421 - root - INFO - CF Training: Epoch 0007 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.1975 | Iter Mean Loss 0.2029\n2024-03-31 19:11:47,460 - root - INFO - CF Training: Epoch 0007 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1981 | Iter Mean Loss 0.2029\n2024-03-31 19:12:05,510 - root - INFO - CF Training: Epoch 0007 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.2105 | Iter Mean Loss 0.2029\n2024-03-31 19:12:23,524 - root - INFO - CF Training: Epoch 0007 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.1857 | Iter Mean Loss 0.2029\n2024-03-31 19:12:41,541 - root - INFO - CF Training: Epoch 0007 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.1975 | Iter Mean Loss 0.2028\n2024-03-31 19:12:59,574 - root - INFO - CF Training: Epoch 0007 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2005 | Iter Mean Loss 0.2028\n2024-03-31 19:13:17,608 - root - INFO - CF Training: Epoch 0007 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2248 | Iter Mean Loss 0.2028\n2024-03-31 19:13:35,632 - root - INFO - CF Training: Epoch 0007 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2204 | Iter Mean Loss 0.2028\n2024-03-31 19:13:53,646 - root - INFO - CF Training: Epoch 0007 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.2173 | Iter Mean Loss 0.2028\n2024-03-31 19:14:11,688 - root - INFO - CF Training: Epoch 0007 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2081 | Iter Mean Loss 0.2027\n2024-03-31 19:14:29,697 - root - INFO - CF Training: Epoch 0007 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2071 | Iter Mean Loss 0.2027\n2024-03-31 19:14:47,742 - root - INFO - CF Training: Epoch 0007 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2203 | Iter Mean Loss 0.2027\n2024-03-31 19:14:51,339 - root - INFO - CF Training: Epoch 0007 Total Iter 5410 | Total Time 1949.6s | Iter Mean Loss 0.2027\n2024-03-31 19:14:57,135 - root - INFO - KG Training: Epoch 0007 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0087\n2024-03-31 19:15:02,829 - root - INFO - KG Training: Epoch 0007 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0086\n2024-03-31 19:15:08,547 - root - INFO - KG Training: Epoch 0007 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0083\n2024-03-31 19:15:14,224 - root - INFO - KG Training: Epoch 0007 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0083\n2024-03-31 19:15:19,837 - root - INFO - KG Training: Epoch 0007 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0082\n2024-03-31 19:15:25,409 - root - INFO - KG Training: Epoch 0007 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0083\n2024-03-31 19:15:31,005 - root - INFO - KG Training: Epoch 0007 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0082\n2024-03-31 19:15:36,560 - root - INFO - KG Training: Epoch 0007 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0082\n2024-03-31 19:15:42,305 - root - INFO - KG Training: Epoch 0007 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0083\n2024-03-31 19:15:48,091 - root - INFO - KG Training: Epoch 0007 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0083\n2024-03-31 19:15:53,852 - root - INFO - KG Training: Epoch 0007 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0083\n2024-03-31 19:15:59,620 - root - INFO - KG Training: Epoch 0007 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0083\n2024-03-31 19:16:05,303 - root - INFO - KG Training: Epoch 0007 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0083\n2024-03-31 19:16:10,964 - root - INFO - KG Training: Epoch 0007 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0083\n2024-03-31 19:16:16,721 - root - INFO - KG Training: Epoch 0007 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0083\n2024-03-31 19:16:22,372 - root - INFO - KG Training: Epoch 0007 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0083\n2024-03-31 19:16:28,078 - root - INFO - KG Training: Epoch 0007 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0083\n2024-03-31 19:16:33,754 - root - INFO - KG Training: Epoch 0007 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0083\n2024-03-31 19:16:39,319 - root - INFO - KG Training: Epoch 0007 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0083\n2024-03-31 19:16:44,926 - root - INFO - KG Training: Epoch 0007 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0083\n2024-03-31 19:16:50,507 - root - INFO - KG Training: Epoch 0007 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0083\n2024-03-31 19:16:56,141 - root - INFO - KG Training: Epoch 0007 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0083\n2024-03-31 19:17:01,750 - root - INFO - KG Training: Epoch 0007 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0083\n2024-03-31 19:17:07,410 - root - INFO - KG Training: Epoch 0007 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0083\n2024-03-31 19:17:13,143 - root - INFO - KG Training: Epoch 0007 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0142 | Iter Mean Loss 0.0083\n2024-03-31 19:17:18,881 - root - INFO - KG Training: Epoch 0007 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0083\n2024-03-31 19:17:24,495 - root - INFO - KG Training: Epoch 0007 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0083\n2024-03-31 19:17:30,112 - root - INFO - KG Training: Epoch 0007 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0083\n2024-03-31 19:17:35,732 - root - INFO - KG Training: Epoch 0007 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0084\n2024-03-31 19:17:41,406 - root - INFO - KG Training: Epoch 0007 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0084\n2024-03-31 19:17:46,993 - root - INFO - KG Training: Epoch 0007 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0084\n2024-03-31 19:17:52,655 - root - INFO - KG Training: Epoch 0007 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0084\n2024-03-31 19:17:58,342 - root - INFO - KG Training: Epoch 0007 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0084\n2024-03-31 19:18:04,034 - root - INFO - KG Training: Epoch 0007 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0084\n2024-03-31 19:18:09,716 - root - INFO - KG Training: Epoch 0007 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0084\n2024-03-31 19:18:15,348 - root - INFO - KG Training: Epoch 0007 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0084\n2024-03-31 19:18:21,020 - root - INFO - KG Training: Epoch 0007 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0084\n2024-03-31 19:18:26,746 - root - INFO - KG Training: Epoch 0007 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0084\n2024-03-31 19:18:32,451 - root - INFO - KG Training: Epoch 0007 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0084\n2024-03-31 19:18:38,227 - root - INFO - KG Training: Epoch 0007 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0084\n2024-03-31 19:18:43,873 - root - INFO - KG Training: Epoch 0007 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0084\n2024-03-31 19:18:49,645 - root - INFO - KG Training: Epoch 0007 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0111 | Iter Mean Loss 0.0084\n2024-03-31 19:18:55,367 - root - INFO - KG Training: Epoch 0007 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0083\n2024-03-31 19:19:01,077 - root - INFO - KG Training: Epoch 0007 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0083\n2024-03-31 19:19:06,805 - root - INFO - KG Training: Epoch 0007 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0083\n2024-03-31 19:19:12,362 - root - INFO - KG Training: Epoch 0007 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0083\n2024-03-31 19:19:18,068 - root - INFO - KG Training: Epoch 0007 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0083\n2024-03-31 19:19:23,837 - root - INFO - KG Training: Epoch 0007 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0083\n2024-03-31 19:19:29,542 - root - INFO - KG Training: Epoch 0007 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0083\n2024-03-31 19:19:35,262 - root - INFO - KG Training: Epoch 0007 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0048 | Iter Mean Loss 0.0083\n2024-03-31 19:19:40,926 - root - INFO - KG Training: Epoch 0007 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0083\n2024-03-31 19:19:46,508 - root - INFO - KG Training: Epoch 0007 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0083\n2024-03-31 19:19:52,084 - root - INFO - KG Training: Epoch 0007 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0083\n2024-03-31 19:19:57,649 - root - INFO - KG Training: Epoch 0007 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0083\n2024-03-31 19:20:03,361 - root - INFO - KG Training: Epoch 0007 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0083\n2024-03-31 19:20:09,177 - root - INFO - KG Training: Epoch 0007 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0083\n2024-03-31 19:20:14,842 - root - INFO - KG Training: Epoch 0007 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0083\n2024-03-31 19:20:20,565 - root - INFO - KG Training: Epoch 0007 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0083\n2024-03-31 19:20:26,237 - root - INFO - KG Training: Epoch 0007 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0083\n2024-03-31 19:20:31,753 - root - INFO - KG Training: Epoch 0007 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0083\n2024-03-31 19:20:37,402 - root - INFO - KG Training: Epoch 0007 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0083\n2024-03-31 19:20:43,221 - root - INFO - KG Training: Epoch 0007 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0083\n2024-03-31 19:20:48,858 - root - INFO - KG Training: Epoch 0007 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0083\n2024-03-31 19:20:54,541 - root - INFO - KG Training: Epoch 0007 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0083\n2024-03-31 19:21:00,279 - root - INFO - KG Training: Epoch 0007 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0104 | Iter Mean Loss 0.0083\n2024-03-31 19:21:05,850 - root - INFO - KG Training: Epoch 0007 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0083\n2024-03-31 19:21:11,464 - root - INFO - KG Training: Epoch 0007 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0083\n2024-03-31 19:21:17,040 - root - INFO - KG Training: Epoch 0007 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0083\n2024-03-31 19:21:22,647 - root - INFO - KG Training: Epoch 0007 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0083\n2024-03-31 19:21:28,312 - root - INFO - KG Training: Epoch 0007 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0083\n2024-03-31 19:21:34,003 - root - INFO - KG Training: Epoch 0007 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0116 | Iter Mean Loss 0.0083\n2024-03-31 19:21:39,696 - root - INFO - KG Training: Epoch 0007 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0083\n2024-03-31 19:21:45,403 - root - INFO - KG Training: Epoch 0007 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0083\n2024-03-31 19:21:51,036 - root - INFO - KG Training: Epoch 0007 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0083\n2024-03-31 19:21:56,749 - root - INFO - KG Training: Epoch 0007 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0083\n2024-03-31 19:22:02,396 - root - INFO - KG Training: Epoch 0007 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0083\n2024-03-31 19:22:08,060 - root - INFO - KG Training: Epoch 0007 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0123 | Iter Mean Loss 0.0083\n2024-03-31 19:22:13,615 - root - INFO - KG Training: Epoch 0007 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0083\n2024-03-31 19:22:19,205 - root - INFO - KG Training: Epoch 0007 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0083\n2024-03-31 19:22:24,840 - root - INFO - KG Training: Epoch 0007 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0083\n2024-03-31 19:22:30,513 - root - INFO - KG Training: Epoch 0007 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0083\n2024-03-31 19:22:36,140 - root - INFO - KG Training: Epoch 0007 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0083\n2024-03-31 19:22:41,837 - root - INFO - KG Training: Epoch 0007 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0083\n2024-03-31 19:22:47,362 - root - INFO - KG Training: Epoch 0007 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0083\n2024-03-31 19:22:53,035 - root - INFO - KG Training: Epoch 0007 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0083\n2024-03-31 19:22:58,501 - root - INFO - KG Training: Epoch 0007 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0119 | Iter Mean Loss 0.0082\n2024-03-31 19:23:04,086 - root - INFO - KG Training: Epoch 0007 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0082\n2024-03-31 19:23:09,596 - root - INFO - KG Training: Epoch 0007 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0039 | Iter Mean Loss 0.0082\n2024-03-31 19:23:15,125 - root - INFO - KG Training: Epoch 0007 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0048 | Iter Mean Loss 0.0082\n2024-03-31 19:23:20,575 - root - INFO - KG Training: Epoch 0007 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0134 | Iter Mean Loss 0.0082\n2024-03-31 19:23:26,316 - root - INFO - KG Training: Epoch 0007 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0082\n2024-03-31 19:23:32,131 - root - INFO - KG Training: Epoch 0007 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0082\n2024-03-31 19:23:37,983 - root - INFO - KG Training: Epoch 0007 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0082\n2024-03-31 19:23:43,915 - root - INFO - KG Training: Epoch 0007 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0082\n2024-03-31 19:23:49,779 - root - INFO - KG Training: Epoch 0007 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0082\n2024-03-31 19:23:55,614 - root - INFO - KG Training: Epoch 0007 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0082\n2024-03-31 19:24:01,386 - root - INFO - KG Training: Epoch 0007 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0082\n2024-03-31 19:24:07,165 - root - INFO - KG Training: Epoch 0007 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0082\n2024-03-31 19:24:13,089 - root - INFO - KG Training: Epoch 0007 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0082\n2024-03-31 19:24:19,099 - root - INFO - KG Training: Epoch 0007 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0082\n2024-03-31 19:24:24,866 - root - INFO - KG Training: Epoch 0007 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0082\n2024-03-31 19:24:30,657 - root - INFO - KG Training: Epoch 0007 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0082\n2024-03-31 19:24:36,535 - root - INFO - KG Training: Epoch 0007 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0082\n2024-03-31 19:24:42,397 - root - INFO - KG Training: Epoch 0007 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0053 | Iter Mean Loss 0.0082\n2024-03-31 19:24:48,172 - root - INFO - KG Training: Epoch 0007 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0082\n2024-03-31 19:24:54,046 - root - INFO - KG Training: Epoch 0007 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0129 | Iter Mean Loss 0.0082\n2024-03-31 19:24:59,715 - root - INFO - KG Training: Epoch 0007 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0082\n2024-03-31 19:25:05,533 - root - INFO - KG Training: Epoch 0007 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0115 | Iter Mean Loss 0.0082\n2024-03-31 19:25:10,337 - root - INFO - KG Training: Epoch 0007 Total Iter 5442 | Total Time 619.0s | Iter Mean Loss 0.0082\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 19:25:13,026 - root - INFO - Update Attention: Epoch 0007 | Total Time 2.7s\n2024-03-31 19:25:13,027 - root - INFO - CF + KG Training: Epoch 0007 | Total Time 2571.3s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:12<00:00,  5.36it/s]\n2024-03-31 19:27:25,868 - root - INFO - CF Evaluation: Epoch 0007 | Total Time 132.8s | Precision [0.0276, 0.0166], Recall [0.1750, 0.4676], NDCG [0.0975, 0.1747]\n2024-03-31 19:27:26,370 - root - INFO - Save model on epoch 0007!\n2024-03-31 19:27:44,420 - root - INFO - CF Training: Epoch 0008 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2020 | Iter Mean Loss 0.2063\n2024-03-31 19:28:02,484 - root - INFO - CF Training: Epoch 0008 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2292 | Iter Mean Loss 0.2040\n2024-03-31 19:28:20,585 - root - INFO - CF Training: Epoch 0008 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2136 | Iter Mean Loss 0.2036\n2024-03-31 19:28:38,606 - root - INFO - CF Training: Epoch 0008 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2147 | Iter Mean Loss 0.2034\n2024-03-31 19:28:56,686 - root - INFO - CF Training: Epoch 0008 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2009 | Iter Mean Loss 0.2028\n2024-03-31 19:29:14,746 - root - INFO - CF Training: Epoch 0008 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.1854 | Iter Mean Loss 0.2030\n2024-03-31 19:29:32,783 - root - INFO - CF Training: Epoch 0008 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.2045 | Iter Mean Loss 0.2027\n2024-03-31 19:29:50,865 - root - INFO - CF Training: Epoch 0008 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2000 | Iter Mean Loss 0.2025\n2024-03-31 19:30:08,911 - root - INFO - CF Training: Epoch 0008 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.2025\n2024-03-31 19:30:26,974 - root - INFO - CF Training: Epoch 0008 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.1884 | Iter Mean Loss 0.2025\n2024-03-31 19:30:45,027 - root - INFO - CF Training: Epoch 0008 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.1982 | Iter Mean Loss 0.2024\n2024-03-31 19:31:03,106 - root - INFO - CF Training: Epoch 0008 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.1936 | Iter Mean Loss 0.2023\n2024-03-31 19:31:21,151 - root - INFO - CF Training: Epoch 0008 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.2048 | Iter Mean Loss 0.2023\n2024-03-31 19:31:39,241 - root - INFO - CF Training: Epoch 0008 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.1959 | Iter Mean Loss 0.2023\n2024-03-31 19:31:57,379 - root - INFO - CF Training: Epoch 0008 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2005 | Iter Mean Loss 0.2025\n2024-03-31 19:32:15,470 - root - INFO - CF Training: Epoch 0008 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.1943 | Iter Mean Loss 0.2024\n2024-03-31 19:32:33,530 - root - INFO - CF Training: Epoch 0008 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2035 | Iter Mean Loss 0.2024\n2024-03-31 19:32:51,592 - root - INFO - CF Training: Epoch 0008 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.1946 | Iter Mean Loss 0.2024\n2024-03-31 19:33:09,688 - root - INFO - CF Training: Epoch 0008 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.1985 | Iter Mean Loss 0.2023\n2024-03-31 19:33:27,790 - root - INFO - CF Training: Epoch 0008 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.1932 | Iter Mean Loss 0.2023\n2024-03-31 19:33:45,925 - root - INFO - CF Training: Epoch 0008 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.1979 | Iter Mean Loss 0.2021\n2024-03-31 19:34:04,046 - root - INFO - CF Training: Epoch 0008 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2058 | Iter Mean Loss 0.2021\n2024-03-31 19:34:22,141 - root - INFO - CF Training: Epoch 0008 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.1968 | Iter Mean Loss 0.2021\n2024-03-31 19:34:40,282 - root - INFO - CF Training: Epoch 0008 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.1984 | Iter Mean Loss 0.2020\n2024-03-31 19:34:58,402 - root - INFO - CF Training: Epoch 0008 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.1956 | Iter Mean Loss 0.2020\n2024-03-31 19:35:16,511 - root - INFO - CF Training: Epoch 0008 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.1911 | Iter Mean Loss 0.2019\n2024-03-31 19:35:34,614 - root - INFO - CF Training: Epoch 0008 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.1977 | Iter Mean Loss 0.2018\n2024-03-31 19:35:52,733 - root - INFO - CF Training: Epoch 0008 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.1992 | Iter Mean Loss 0.2017\n2024-03-31 19:36:10,898 - root - INFO - CF Training: Epoch 0008 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1999 | Iter Mean Loss 0.2016\n2024-03-31 19:36:28,978 - root - INFO - CF Training: Epoch 0008 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.2017\n2024-03-31 19:36:47,124 - root - INFO - CF Training: Epoch 0008 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.1876 | Iter Mean Loss 0.2017\n2024-03-31 19:37:05,269 - root - INFO - CF Training: Epoch 0008 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1904 | Iter Mean Loss 0.2016\n2024-03-31 19:37:23,391 - root - INFO - CF Training: Epoch 0008 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.2006 | Iter Mean Loss 0.2016\n2024-03-31 19:37:41,519 - root - INFO - CF Training: Epoch 0008 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.1814 | Iter Mean Loss 0.2015\n2024-03-31 19:37:59,607 - root - INFO - CF Training: Epoch 0008 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.1896 | Iter Mean Loss 0.2015\n2024-03-31 19:38:17,719 - root - INFO - CF Training: Epoch 0008 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.1990 | Iter Mean Loss 0.2014\n2024-03-31 19:38:35,765 - root - INFO - CF Training: Epoch 0008 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.1897 | Iter Mean Loss 0.2013\n2024-03-31 19:38:53,833 - root - INFO - CF Training: Epoch 0008 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.1924 | Iter Mean Loss 0.2013\n2024-03-31 19:39:11,920 - root - INFO - CF Training: Epoch 0008 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2085 | Iter Mean Loss 0.2013\n2024-03-31 19:39:30,021 - root - INFO - CF Training: Epoch 0008 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2078 | Iter Mean Loss 0.2013\n2024-03-31 19:39:48,117 - root - INFO - CF Training: Epoch 0008 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.2013\n2024-03-31 19:40:06,210 - root - INFO - CF Training: Epoch 0008 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.1875 | Iter Mean Loss 0.2013\n2024-03-31 19:40:24,306 - root - INFO - CF Training: Epoch 0008 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.1991 | Iter Mean Loss 0.2012\n2024-03-31 19:40:42,423 - root - INFO - CF Training: Epoch 0008 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2018 | Iter Mean Loss 0.2012\n2024-03-31 19:41:00,523 - root - INFO - CF Training: Epoch 0008 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.1943 | Iter Mean Loss 0.2012\n2024-03-31 19:41:18,612 - root - INFO - CF Training: Epoch 0008 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.2146 | Iter Mean Loss 0.2011\n2024-03-31 19:41:36,730 - root - INFO - CF Training: Epoch 0008 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.1903 | Iter Mean Loss 0.2011\n2024-03-31 19:41:54,866 - root - INFO - CF Training: Epoch 0008 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.1789 | Iter Mean Loss 0.2011\n2024-03-31 19:42:12,921 - root - INFO - CF Training: Epoch 0008 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.1882 | Iter Mean Loss 0.2010\n2024-03-31 19:42:30,961 - root - INFO - CF Training: Epoch 0008 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.2098 | Iter Mean Loss 0.2010\n2024-03-31 19:42:49,078 - root - INFO - CF Training: Epoch 0008 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.1900 | Iter Mean Loss 0.2010\n2024-03-31 19:43:07,177 - root - INFO - CF Training: Epoch 0008 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.1957 | Iter Mean Loss 0.2009\n2024-03-31 19:43:25,274 - root - INFO - CF Training: Epoch 0008 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.2082 | Iter Mean Loss 0.2008\n2024-03-31 19:43:43,354 - root - INFO - CF Training: Epoch 0008 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.2038 | Iter Mean Loss 0.2009\n2024-03-31 19:44:01,451 - root - INFO - CF Training: Epoch 0008 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.1917 | Iter Mean Loss 0.2009\n2024-03-31 19:44:19,609 - root - INFO - CF Training: Epoch 0008 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2091 | Iter Mean Loss 0.2008\n2024-03-31 19:44:37,725 - root - INFO - CF Training: Epoch 0008 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2059 | Iter Mean Loss 0.2008\n2024-03-31 19:44:55,832 - root - INFO - CF Training: Epoch 0008 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.2143 | Iter Mean Loss 0.2008\n2024-03-31 19:45:13,965 - root - INFO - CF Training: Epoch 0008 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2299 | Iter Mean Loss 0.2008\n2024-03-31 19:45:32,113 - root - INFO - CF Training: Epoch 0008 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.1948 | Iter Mean Loss 0.2008\n2024-03-31 19:45:50,267 - root - INFO - CF Training: Epoch 0008 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.1932 | Iter Mean Loss 0.2008\n2024-03-31 19:46:08,394 - root - INFO - CF Training: Epoch 0008 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.1889 | Iter Mean Loss 0.2007\n2024-03-31 19:46:26,554 - root - INFO - CF Training: Epoch 0008 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.1974 | Iter Mean Loss 0.2007\n2024-03-31 19:46:44,721 - root - INFO - CF Training: Epoch 0008 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.1923 | Iter Mean Loss 0.2007\n2024-03-31 19:47:02,851 - root - INFO - CF Training: Epoch 0008 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.1928 | Iter Mean Loss 0.2006\n2024-03-31 19:47:20,976 - root - INFO - CF Training: Epoch 0008 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2225 | Iter Mean Loss 0.2006\n2024-03-31 19:47:39,128 - root - INFO - CF Training: Epoch 0008 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.1940 | Iter Mean Loss 0.2006\n2024-03-31 19:47:57,272 - root - INFO - CF Training: Epoch 0008 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2040 | Iter Mean Loss 0.2006\n2024-03-31 19:48:15,414 - root - INFO - CF Training: Epoch 0008 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.1990 | Iter Mean Loss 0.2006\n2024-03-31 19:48:33,552 - root - INFO - CF Training: Epoch 0008 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.1935 | Iter Mean Loss 0.2006\n2024-03-31 19:48:51,676 - root - INFO - CF Training: Epoch 0008 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.1952 | Iter Mean Loss 0.2006\n2024-03-31 19:49:09,796 - root - INFO - CF Training: Epoch 0008 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2161 | Iter Mean Loss 0.2005\n2024-03-31 19:49:27,916 - root - INFO - CF Training: Epoch 0008 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.1949 | Iter Mean Loss 0.2005\n2024-03-31 19:49:46,088 - root - INFO - CF Training: Epoch 0008 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.2047 | Iter Mean Loss 0.2005\n2024-03-31 19:50:04,236 - root - INFO - CF Training: Epoch 0008 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.1952 | Iter Mean Loss 0.2005\n2024-03-31 19:50:22,355 - root - INFO - CF Training: Epoch 0008 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.1998 | Iter Mean Loss 0.2005\n2024-03-31 19:50:40,489 - root - INFO - CF Training: Epoch 0008 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.2040 | Iter Mean Loss 0.2004\n2024-03-31 19:50:58,620 - root - INFO - CF Training: Epoch 0008 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2107 | Iter Mean Loss 0.2005\n2024-03-31 19:51:16,771 - root - INFO - CF Training: Epoch 0008 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.2036 | Iter Mean Loss 0.2004\n2024-03-31 19:51:34,890 - root - INFO - CF Training: Epoch 0008 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.2229 | Iter Mean Loss 0.2004\n2024-03-31 19:51:53,002 - root - INFO - CF Training: Epoch 0008 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.1923 | Iter Mean Loss 0.2004\n2024-03-31 19:52:11,161 - root - INFO - CF Training: Epoch 0008 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.1963 | Iter Mean Loss 0.2004\n2024-03-31 19:52:29,319 - root - INFO - CF Training: Epoch 0008 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.1960 | Iter Mean Loss 0.2003\n2024-03-31 19:52:47,438 - root - INFO - CF Training: Epoch 0008 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.1927 | Iter Mean Loss 0.2003\n2024-03-31 19:53:05,599 - root - INFO - CF Training: Epoch 0008 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.2013 | Iter Mean Loss 0.2003\n2024-03-31 19:53:23,731 - root - INFO - CF Training: Epoch 0008 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2069 | Iter Mean Loss 0.2003\n2024-03-31 19:53:41,850 - root - INFO - CF Training: Epoch 0008 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.1998 | Iter Mean Loss 0.2003\n2024-03-31 19:53:59,965 - root - INFO - CF Training: Epoch 0008 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.1977 | Iter Mean Loss 0.2003\n2024-03-31 19:54:18,085 - root - INFO - CF Training: Epoch 0008 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.2017 | Iter Mean Loss 0.2002\n2024-03-31 19:54:36,244 - root - INFO - CF Training: Epoch 0008 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2038 | Iter Mean Loss 0.2002\n2024-03-31 19:54:54,418 - root - INFO - CF Training: Epoch 0008 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.1912 | Iter Mean Loss 0.2002\n2024-03-31 19:55:12,585 - root - INFO - CF Training: Epoch 0008 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.2064 | Iter Mean Loss 0.2002\n2024-03-31 19:55:30,728 - root - INFO - CF Training: Epoch 0008 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.2027 | Iter Mean Loss 0.2001\n2024-03-31 19:55:48,904 - root - INFO - CF Training: Epoch 0008 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.1886 | Iter Mean Loss 0.2001\n2024-03-31 19:56:07,112 - root - INFO - CF Training: Epoch 0008 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.1876 | Iter Mean Loss 0.2001\n2024-03-31 19:56:25,257 - root - INFO - CF Training: Epoch 0008 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.1834 | Iter Mean Loss 0.2001\n2024-03-31 19:56:43,435 - root - INFO - CF Training: Epoch 0008 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.2009 | Iter Mean Loss 0.2001\n2024-03-31 19:57:01,610 - root - INFO - CF Training: Epoch 0008 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1983 | Iter Mean Loss 0.2001\n2024-03-31 19:57:19,770 - root - INFO - CF Training: Epoch 0008 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.1928 | Iter Mean Loss 0.2000\n2024-03-31 19:57:37,889 - root - INFO - CF Training: Epoch 0008 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.1996 | Iter Mean Loss 0.2000\n2024-03-31 19:57:56,057 - root - INFO - CF Training: Epoch 0008 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.1909 | Iter Mean Loss 0.2000\n2024-03-31 19:58:14,258 - root - INFO - CF Training: Epoch 0008 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2198 | Iter Mean Loss 0.2000\n2024-03-31 19:58:32,428 - root - INFO - CF Training: Epoch 0008 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.1932 | Iter Mean Loss 0.2000\n2024-03-31 19:58:50,573 - root - INFO - CF Training: Epoch 0008 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2049 | Iter Mean Loss 0.1999\n2024-03-31 19:59:08,791 - root - INFO - CF Training: Epoch 0008 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.1973 | Iter Mean Loss 0.1999\n2024-03-31 19:59:27,018 - root - INFO - CF Training: Epoch 0008 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.2126 | Iter Mean Loss 0.1999\n2024-03-31 19:59:45,191 - root - INFO - CF Training: Epoch 0008 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.2003 | Iter Mean Loss 0.1999\n2024-03-31 20:00:03,403 - root - INFO - CF Training: Epoch 0008 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.1982 | Iter Mean Loss 0.1999\n2024-03-31 20:00:07,039 - root - INFO - CF Training: Epoch 0008 Total Iter 5410 | Total Time 1960.7s | Iter Mean Loss 0.1999\n2024-03-31 20:00:13,026 - root - INFO - KG Training: Epoch 0008 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0079\n2024-03-31 20:00:18,902 - root - INFO - KG Training: Epoch 0008 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0079\n2024-03-31 20:00:24,731 - root - INFO - KG Training: Epoch 0008 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0081\n2024-03-31 20:00:30,694 - root - INFO - KG Training: Epoch 0008 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0045 | Iter Mean Loss 0.0081\n2024-03-31 20:00:36,659 - root - INFO - KG Training: Epoch 0008 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0082\n2024-03-31 20:00:42,844 - root - INFO - KG Training: Epoch 0008 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0081\n2024-03-31 20:00:48,861 - root - INFO - KG Training: Epoch 0008 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0081\n2024-03-31 20:00:54,826 - root - INFO - KG Training: Epoch 0008 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0082\n2024-03-31 20:01:00,712 - root - INFO - KG Training: Epoch 0008 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0082\n2024-03-31 20:01:06,651 - root - INFO - KG Training: Epoch 0008 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0082\n2024-03-31 20:01:12,547 - root - INFO - KG Training: Epoch 0008 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0081\n2024-03-31 20:01:18,458 - root - INFO - KG Training: Epoch 0008 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0082\n2024-03-31 20:01:24,349 - root - INFO - KG Training: Epoch 0008 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0082\n2024-03-31 20:01:30,169 - root - INFO - KG Training: Epoch 0008 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0082\n2024-03-31 20:01:36,070 - root - INFO - KG Training: Epoch 0008 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0082\n2024-03-31 20:01:41,996 - root - INFO - KG Training: Epoch 0008 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0082\n2024-03-31 20:01:47,948 - root - INFO - KG Training: Epoch 0008 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0110 | Iter Mean Loss 0.0081\n2024-03-31 20:01:53,924 - root - INFO - KG Training: Epoch 0008 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0081\n2024-03-31 20:01:59,725 - root - INFO - KG Training: Epoch 0008 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0081\n2024-03-31 20:02:05,681 - root - INFO - KG Training: Epoch 0008 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0081\n2024-03-31 20:02:11,495 - root - INFO - KG Training: Epoch 0008 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0081\n2024-03-31 20:02:17,571 - root - INFO - KG Training: Epoch 0008 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0081\n2024-03-31 20:02:23,405 - root - INFO - KG Training: Epoch 0008 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0081\n2024-03-31 20:02:29,266 - root - INFO - KG Training: Epoch 0008 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0081\n2024-03-31 20:02:35,137 - root - INFO - KG Training: Epoch 0008 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0080\n2024-03-31 20:02:40,943 - root - INFO - KG Training: Epoch 0008 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0081\n2024-03-31 20:02:47,083 - root - INFO - KG Training: Epoch 0008 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0081\n2024-03-31 20:02:52,936 - root - INFO - KG Training: Epoch 0008 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0081\n2024-03-31 20:02:58,851 - root - INFO - KG Training: Epoch 0008 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0080\n2024-03-31 20:03:04,774 - root - INFO - KG Training: Epoch 0008 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0081\n2024-03-31 20:03:10,688 - root - INFO - KG Training: Epoch 0008 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0081\n2024-03-31 20:03:16,677 - root - INFO - KG Training: Epoch 0008 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0081\n2024-03-31 20:03:22,533 - root - INFO - KG Training: Epoch 0008 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0081\n2024-03-31 20:03:28,328 - root - INFO - KG Training: Epoch 0008 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0080\n2024-03-31 20:03:34,196 - root - INFO - KG Training: Epoch 0008 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0080\n2024-03-31 20:03:40,013 - root - INFO - KG Training: Epoch 0008 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0042 | Iter Mean Loss 0.0080\n2024-03-31 20:03:45,960 - root - INFO - KG Training: Epoch 0008 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0080\n2024-03-31 20:03:51,840 - root - INFO - KG Training: Epoch 0008 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0080\n2024-03-31 20:03:57,726 - root - INFO - KG Training: Epoch 0008 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0044 | Iter Mean Loss 0.0080\n2024-03-31 20:04:03,528 - root - INFO - KG Training: Epoch 0008 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0080\n2024-03-31 20:04:09,461 - root - INFO - KG Training: Epoch 0008 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0080\n2024-03-31 20:04:15,302 - root - INFO - KG Training: Epoch 0008 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0080\n2024-03-31 20:04:21,217 - root - INFO - KG Training: Epoch 0008 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0080\n2024-03-31 20:04:27,117 - root - INFO - KG Training: Epoch 0008 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0080\n2024-03-31 20:04:32,991 - root - INFO - KG Training: Epoch 0008 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0080\n2024-03-31 20:04:38,832 - root - INFO - KG Training: Epoch 0008 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0141 | Iter Mean Loss 0.0080\n2024-03-31 20:04:44,772 - root - INFO - KG Training: Epoch 0008 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0080\n2024-03-31 20:04:50,785 - root - INFO - KG Training: Epoch 0008 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0080\n2024-03-31 20:04:56,767 - root - INFO - KG Training: Epoch 0008 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0080\n2024-03-31 20:05:02,632 - root - INFO - KG Training: Epoch 0008 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0080\n2024-03-31 20:05:08,586 - root - INFO - KG Training: Epoch 0008 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0080\n2024-03-31 20:05:14,460 - root - INFO - KG Training: Epoch 0008 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0080\n2024-03-31 20:05:20,432 - root - INFO - KG Training: Epoch 0008 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0080\n2024-03-31 20:05:26,340 - root - INFO - KG Training: Epoch 0008 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0080\n2024-03-31 20:05:32,144 - root - INFO - KG Training: Epoch 0008 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0080\n2024-03-31 20:05:37,919 - root - INFO - KG Training: Epoch 0008 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0080\n2024-03-31 20:05:43,838 - root - INFO - KG Training: Epoch 0008 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0080\n2024-03-31 20:05:49,808 - root - INFO - KG Training: Epoch 0008 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0080\n2024-03-31 20:05:55,820 - root - INFO - KG Training: Epoch 0008 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0080\n2024-03-31 20:06:01,709 - root - INFO - KG Training: Epoch 0008 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0080\n2024-03-31 20:06:07,606 - root - INFO - KG Training: Epoch 0008 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0080\n2024-03-31 20:06:13,481 - root - INFO - KG Training: Epoch 0008 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0080\n2024-03-31 20:06:19,473 - root - INFO - KG Training: Epoch 0008 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0080\n2024-03-31 20:06:25,356 - root - INFO - KG Training: Epoch 0008 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0080\n2024-03-31 20:06:31,240 - root - INFO - KG Training: Epoch 0008 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0080\n2024-03-31 20:06:37,103 - root - INFO - KG Training: Epoch 0008 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0080\n2024-03-31 20:06:42,984 - root - INFO - KG Training: Epoch 0008 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0080\n2024-03-31 20:06:48,920 - root - INFO - KG Training: Epoch 0008 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0080\n2024-03-31 20:06:54,780 - root - INFO - KG Training: Epoch 0008 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0080\n2024-03-31 20:07:00,662 - root - INFO - KG Training: Epoch 0008 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0080\n2024-03-31 20:07:06,598 - root - INFO - KG Training: Epoch 0008 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0080\n2024-03-31 20:07:12,415 - root - INFO - KG Training: Epoch 0008 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0080\n2024-03-31 20:07:18,365 - root - INFO - KG Training: Epoch 0008 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0080\n2024-03-31 20:07:24,316 - root - INFO - KG Training: Epoch 0008 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0125 | Iter Mean Loss 0.0080\n2024-03-31 20:07:30,348 - root - INFO - KG Training: Epoch 0008 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0080\n2024-03-31 20:07:36,123 - root - INFO - KG Training: Epoch 0008 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0080\n2024-03-31 20:07:42,020 - root - INFO - KG Training: Epoch 0008 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0080\n2024-03-31 20:07:47,948 - root - INFO - KG Training: Epoch 0008 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0080\n2024-03-31 20:07:53,866 - root - INFO - KG Training: Epoch 0008 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0080\n2024-03-31 20:07:59,654 - root - INFO - KG Training: Epoch 0008 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0080\n2024-03-31 20:08:05,616 - root - INFO - KG Training: Epoch 0008 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0080\n2024-03-31 20:08:11,546 - root - INFO - KG Training: Epoch 0008 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0080\n2024-03-31 20:08:17,449 - root - INFO - KG Training: Epoch 0008 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0080\n2024-03-31 20:08:23,254 - root - INFO - KG Training: Epoch 0008 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0080\n2024-03-31 20:08:29,179 - root - INFO - KG Training: Epoch 0008 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0080\n2024-03-31 20:08:35,104 - root - INFO - KG Training: Epoch 0008 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0080\n2024-03-31 20:08:40,997 - root - INFO - KG Training: Epoch 0008 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0080\n2024-03-31 20:08:47,073 - root - INFO - KG Training: Epoch 0008 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0080\n2024-03-31 20:08:52,960 - root - INFO - KG Training: Epoch 0008 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0133 | Iter Mean Loss 0.0080\n2024-03-31 20:08:59,079 - root - INFO - KG Training: Epoch 0008 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0080\n2024-03-31 20:09:04,994 - root - INFO - KG Training: Epoch 0008 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0080\n2024-03-31 20:09:10,878 - root - INFO - KG Training: Epoch 0008 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0080\n2024-03-31 20:09:16,794 - root - INFO - KG Training: Epoch 0008 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0080\n2024-03-31 20:09:22,499 - root - INFO - KG Training: Epoch 0008 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0079\n2024-03-31 20:09:28,443 - root - INFO - KG Training: Epoch 0008 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0079\n2024-03-31 20:09:34,466 - root - INFO - KG Training: Epoch 0008 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0079\n2024-03-31 20:09:40,353 - root - INFO - KG Training: Epoch 0008 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0079\n2024-03-31 20:09:46,531 - root - INFO - KG Training: Epoch 0008 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0080\n2024-03-31 20:09:52,453 - root - INFO - KG Training: Epoch 0008 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0080\n2024-03-31 20:09:58,442 - root - INFO - KG Training: Epoch 0008 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0080\n2024-03-31 20:10:04,500 - root - INFO - KG Training: Epoch 0008 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0080\n2024-03-31 20:10:10,464 - root - INFO - KG Training: Epoch 0008 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0079\n2024-03-31 20:10:16,338 - root - INFO - KG Training: Epoch 0008 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0079\n2024-03-31 20:10:22,202 - root - INFO - KG Training: Epoch 0008 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0079\n2024-03-31 20:10:28,272 - root - INFO - KG Training: Epoch 0008 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0095 | Iter Mean Loss 0.0079\n2024-03-31 20:10:34,213 - root - INFO - KG Training: Epoch 0008 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0079\n2024-03-31 20:10:40,329 - root - INFO - KG Training: Epoch 0008 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0079\n2024-03-31 20:10:46,260 - root - INFO - KG Training: Epoch 0008 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0079\n2024-03-31 20:10:51,236 - root - INFO - KG Training: Epoch 0008 Total Iter 5442 | Total Time 644.2s | Iter Mean Loss 0.0079\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 20:10:53,945 - root - INFO - Update Attention: Epoch 0008 | Total Time 2.7s\n2024-03-31 20:10:53,946 - root - INFO - CF + KG Training: Epoch 0008 | Total Time 2607.6s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:15<00:00,  5.27it/s]\n2024-03-31 20:13:09,115 - root - INFO - CF Evaluation: Epoch 0008 | Total Time 135.2s | Precision [0.0281, 0.0168], Recall [0.1779, 0.4735], NDCG [0.0992, 0.1772]\n2024-03-31 20:13:09,627 - root - INFO - Save model on epoch 0008!\n2024-03-31 20:13:27,772 - root - INFO - CF Training: Epoch 0009 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.1862 | Iter Mean Loss 0.2014\n2024-03-31 20:13:45,896 - root - INFO - CF Training: Epoch 0009 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.2052 | Iter Mean Loss 0.2010\n2024-03-31 20:14:04,046 - root - INFO - CF Training: Epoch 0009 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.1932 | Iter Mean Loss 0.2011\n2024-03-31 20:14:22,130 - root - INFO - CF Training: Epoch 0009 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.2011 | Iter Mean Loss 0.2010\n2024-03-31 20:14:40,275 - root - INFO - CF Training: Epoch 0009 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2012 | Iter Mean Loss 0.2009\n2024-03-31 20:14:58,406 - root - INFO - CF Training: Epoch 0009 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.2073 | Iter Mean Loss 0.2007\n2024-03-31 20:15:16,588 - root - INFO - CF Training: Epoch 0009 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.1918 | Iter Mean Loss 0.2006\n2024-03-31 20:15:34,792 - root - INFO - CF Training: Epoch 0009 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.1960 | Iter Mean Loss 0.2000\n2024-03-31 20:15:53,001 - root - INFO - CF Training: Epoch 0009 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2150 | Iter Mean Loss 0.1998\n2024-03-31 20:16:11,179 - root - INFO - CF Training: Epoch 0009 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.2246 | Iter Mean Loss 0.2000\n2024-03-31 20:16:29,305 - root - INFO - CF Training: Epoch 0009 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.2042 | Iter Mean Loss 0.1997\n2024-03-31 20:16:47,513 - root - INFO - CF Training: Epoch 0009 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.1942 | Iter Mean Loss 0.1995\n2024-03-31 20:17:05,685 - root - INFO - CF Training: Epoch 0009 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.1952 | Iter Mean Loss 0.1994\n2024-03-31 20:17:23,808 - root - INFO - CF Training: Epoch 0009 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2154 | Iter Mean Loss 0.1993\n2024-03-31 20:17:41,954 - root - INFO - CF Training: Epoch 0009 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.1980 | Iter Mean Loss 0.1991\n2024-03-31 20:18:00,120 - root - INFO - CF Training: Epoch 0009 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.2041 | Iter Mean Loss 0.1990\n2024-03-31 20:18:18,253 - root - INFO - CF Training: Epoch 0009 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.2022 | Iter Mean Loss 0.1990\n2024-03-31 20:18:36,336 - root - INFO - CF Training: Epoch 0009 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.1989\n2024-03-31 20:18:54,481 - root - INFO - CF Training: Epoch 0009 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.1946 | Iter Mean Loss 0.1990\n2024-03-31 20:19:12,656 - root - INFO - CF Training: Epoch 0009 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.1906 | Iter Mean Loss 0.1989\n2024-03-31 20:19:30,784 - root - INFO - CF Training: Epoch 0009 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.1949 | Iter Mean Loss 0.1988\n2024-03-31 20:19:48,964 - root - INFO - CF Training: Epoch 0009 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.1989\n2024-03-31 20:20:07,116 - root - INFO - CF Training: Epoch 0009 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.1976 | Iter Mean Loss 0.1988\n2024-03-31 20:20:25,270 - root - INFO - CF Training: Epoch 0009 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.2056 | Iter Mean Loss 0.1987\n2024-03-31 20:20:43,481 - root - INFO - CF Training: Epoch 0009 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.1988 | Iter Mean Loss 0.1987\n2024-03-31 20:21:01,622 - root - INFO - CF Training: Epoch 0009 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.2135 | Iter Mean Loss 0.1987\n2024-03-31 20:21:19,785 - root - INFO - CF Training: Epoch 0009 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.1866 | Iter Mean Loss 0.1986\n2024-03-31 20:21:37,942 - root - INFO - CF Training: Epoch 0009 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.1911 | Iter Mean Loss 0.1986\n2024-03-31 20:21:56,101 - root - INFO - CF Training: Epoch 0009 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1927 | Iter Mean Loss 0.1986\n2024-03-31 20:22:14,276 - root - INFO - CF Training: Epoch 0009 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.1758 | Iter Mean Loss 0.1985\n2024-03-31 20:22:32,429 - root - INFO - CF Training: Epoch 0009 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.1881 | Iter Mean Loss 0.1986\n2024-03-31 20:22:50,633 - root - INFO - CF Training: Epoch 0009 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1888 | Iter Mean Loss 0.1985\n2024-03-31 20:23:08,770 - root - INFO - CF Training: Epoch 0009 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.1894 | Iter Mean Loss 0.1985\n2024-03-31 20:23:26,961 - root - INFO - CF Training: Epoch 0009 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.2125 | Iter Mean Loss 0.1985\n2024-03-31 20:23:45,145 - root - INFO - CF Training: Epoch 0009 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.1818 | Iter Mean Loss 0.1984\n2024-03-31 20:24:03,325 - root - INFO - CF Training: Epoch 0009 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.2026 | Iter Mean Loss 0.1983\n2024-03-31 20:24:21,550 - root - INFO - CF Training: Epoch 0009 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.1915 | Iter Mean Loss 0.1983\n2024-03-31 20:24:39,720 - root - INFO - CF Training: Epoch 0009 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.2217 | Iter Mean Loss 0.1982\n2024-03-31 20:24:57,862 - root - INFO - CF Training: Epoch 0009 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.1969 | Iter Mean Loss 0.1982\n2024-03-31 20:25:16,030 - root - INFO - CF Training: Epoch 0009 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.1891 | Iter Mean Loss 0.1983\n2024-03-31 20:25:34,183 - root - INFO - CF Training: Epoch 0009 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.1970 | Iter Mean Loss 0.1982\n2024-03-31 20:25:52,398 - root - INFO - CF Training: Epoch 0009 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.1879 | Iter Mean Loss 0.1981\n2024-03-31 20:26:10,572 - root - INFO - CF Training: Epoch 0009 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.1980\n2024-03-31 20:26:28,751 - root - INFO - CF Training: Epoch 0009 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.1842 | Iter Mean Loss 0.1980\n2024-03-31 20:26:46,896 - root - INFO - CF Training: Epoch 0009 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.2069 | Iter Mean Loss 0.1980\n2024-03-31 20:27:05,102 - root - INFO - CF Training: Epoch 0009 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.1812 | Iter Mean Loss 0.1980\n2024-03-31 20:27:23,242 - root - INFO - CF Training: Epoch 0009 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.1864 | Iter Mean Loss 0.1980\n2024-03-31 20:27:41,406 - root - INFO - CF Training: Epoch 0009 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.2047 | Iter Mean Loss 0.1980\n2024-03-31 20:27:59,560 - root - INFO - CF Training: Epoch 0009 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.1980\n2024-03-31 20:28:17,709 - root - INFO - CF Training: Epoch 0009 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.1741 | Iter Mean Loss 0.1980\n2024-03-31 20:28:35,854 - root - INFO - CF Training: Epoch 0009 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.2068 | Iter Mean Loss 0.1979\n2024-03-31 20:28:53,989 - root - INFO - CF Training: Epoch 0009 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.1978 | Iter Mean Loss 0.1979\n2024-03-31 20:29:12,122 - root - INFO - CF Training: Epoch 0009 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.1856 | Iter Mean Loss 0.1979\n2024-03-31 20:29:30,251 - root - INFO - CF Training: Epoch 0009 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.1963 | Iter Mean Loss 0.1978\n2024-03-31 20:29:48,422 - root - INFO - CF Training: Epoch 0009 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.1891 | Iter Mean Loss 0.1978\n2024-03-31 20:30:06,597 - root - INFO - CF Training: Epoch 0009 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.2035 | Iter Mean Loss 0.1977\n2024-03-31 20:30:24,763 - root - INFO - CF Training: Epoch 0009 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.2063 | Iter Mean Loss 0.1977\n2024-03-31 20:30:43,099 - root - INFO - CF Training: Epoch 0009 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.1936 | Iter Mean Loss 0.1977\n2024-03-31 20:31:01,392 - root - INFO - CF Training: Epoch 0009 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.1935 | Iter Mean Loss 0.1977\n2024-03-31 20:31:19,664 - root - INFO - CF Training: Epoch 0009 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.2107 | Iter Mean Loss 0.1977\n2024-03-31 20:31:37,939 - root - INFO - CF Training: Epoch 0009 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.1998 | Iter Mean Loss 0.1977\n2024-03-31 20:31:56,220 - root - INFO - CF Training: Epoch 0009 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.2034 | Iter Mean Loss 0.1976\n2024-03-31 20:32:14,545 - root - INFO - CF Training: Epoch 0009 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.1980 | Iter Mean Loss 0.1976\n2024-03-31 20:32:32,737 - root - INFO - CF Training: Epoch 0009 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.1915 | Iter Mean Loss 0.1976\n2024-03-31 20:32:50,929 - root - INFO - CF Training: Epoch 0009 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.1988 | Iter Mean Loss 0.1976\n2024-03-31 20:33:09,127 - root - INFO - CF Training: Epoch 0009 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.1995 | Iter Mean Loss 0.1975\n2024-03-31 20:33:27,299 - root - INFO - CF Training: Epoch 0009 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.1820 | Iter Mean Loss 0.1975\n2024-03-31 20:33:45,484 - root - INFO - CF Training: Epoch 0009 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2156 | Iter Mean Loss 0.1975\n2024-03-31 20:34:03,672 - root - INFO - CF Training: Epoch 0009 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.1930 | Iter Mean Loss 0.1975\n2024-03-31 20:34:21,847 - root - INFO - CF Training: Epoch 0009 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.1881 | Iter Mean Loss 0.1975\n2024-03-31 20:34:39,998 - root - INFO - CF Training: Epoch 0009 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.1998 | Iter Mean Loss 0.1975\n2024-03-31 20:34:58,217 - root - INFO - CF Training: Epoch 0009 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.1903 | Iter Mean Loss 0.1974\n2024-03-31 20:35:16,383 - root - INFO - CF Training: Epoch 0009 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.1871 | Iter Mean Loss 0.1974\n2024-03-31 20:35:34,556 - root - INFO - CF Training: Epoch 0009 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.1939 | Iter Mean Loss 0.1974\n2024-03-31 20:35:52,717 - root - INFO - CF Training: Epoch 0009 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.2024 | Iter Mean Loss 0.1974\n2024-03-31 20:36:10,912 - root - INFO - CF Training: Epoch 0009 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.2115 | Iter Mean Loss 0.1973\n2024-03-31 20:36:29,086 - root - INFO - CF Training: Epoch 0009 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.1801 | Iter Mean Loss 0.1973\n2024-03-31 20:36:47,284 - root - INFO - CF Training: Epoch 0009 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.2030 | Iter Mean Loss 0.1973\n2024-03-31 20:37:05,506 - root - INFO - CF Training: Epoch 0009 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.1896 | Iter Mean Loss 0.1973\n2024-03-31 20:37:23,665 - root - INFO - CF Training: Epoch 0009 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.1850 | Iter Mean Loss 0.1972\n2024-03-31 20:37:41,821 - root - INFO - CF Training: Epoch 0009 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.2011 | Iter Mean Loss 0.1972\n2024-03-31 20:38:00,016 - root - INFO - CF Training: Epoch 0009 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.1907 | Iter Mean Loss 0.1972\n2024-03-31 20:38:18,228 - root - INFO - CF Training: Epoch 0009 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.1882 | Iter Mean Loss 0.1972\n2024-03-31 20:38:36,429 - root - INFO - CF Training: Epoch 0009 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.1935 | Iter Mean Loss 0.1972\n2024-03-31 20:38:54,611 - root - INFO - CF Training: Epoch 0009 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.1979 | Iter Mean Loss 0.1972\n2024-03-31 20:39:12,824 - root - INFO - CF Training: Epoch 0009 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.2002 | Iter Mean Loss 0.1972\n2024-03-31 20:39:31,031 - root - INFO - CF Training: Epoch 0009 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.1935 | Iter Mean Loss 0.1972\n2024-03-31 20:39:49,229 - root - INFO - CF Training: Epoch 0009 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.2044 | Iter Mean Loss 0.1971\n2024-03-31 20:40:07,429 - root - INFO - CF Training: Epoch 0009 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.1943 | Iter Mean Loss 0.1971\n2024-03-31 20:40:25,610 - root - INFO - CF Training: Epoch 0009 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.2252 | Iter Mean Loss 0.1971\n2024-03-31 20:40:43,809 - root - INFO - CF Training: Epoch 0009 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.2269 | Iter Mean Loss 0.1971\n2024-03-31 20:41:02,011 - root - INFO - CF Training: Epoch 0009 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.1969 | Iter Mean Loss 0.1971\n2024-03-31 20:41:20,226 - root - INFO - CF Training: Epoch 0009 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.1949 | Iter Mean Loss 0.1971\n2024-03-31 20:41:38,428 - root - INFO - CF Training: Epoch 0009 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.2064 | Iter Mean Loss 0.1971\n2024-03-31 20:41:56,634 - root - INFO - CF Training: Epoch 0009 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.1893 | Iter Mean Loss 0.1971\n2024-03-31 20:42:14,837 - root - INFO - CF Training: Epoch 0009 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.1928 | Iter Mean Loss 0.1971\n2024-03-31 20:42:32,999 - root - INFO - CF Training: Epoch 0009 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.1938 | Iter Mean Loss 0.1971\n2024-03-31 20:42:51,169 - root - INFO - CF Training: Epoch 0009 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1739 | Iter Mean Loss 0.1971\n2024-03-31 20:43:09,342 - root - INFO - CF Training: Epoch 0009 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.1909 | Iter Mean Loss 0.1970\n2024-03-31 20:43:27,526 - root - INFO - CF Training: Epoch 0009 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2003 | Iter Mean Loss 0.1970\n2024-03-31 20:43:45,715 - root - INFO - CF Training: Epoch 0009 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.1967 | Iter Mean Loss 0.1970\n2024-03-31 20:44:03,880 - root - INFO - CF Training: Epoch 0009 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.2059 | Iter Mean Loss 0.1970\n2024-03-31 20:44:22,049 - root - INFO - CF Training: Epoch 0009 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2067 | Iter Mean Loss 0.1970\n2024-03-31 20:44:40,230 - root - INFO - CF Training: Epoch 0009 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.1998 | Iter Mean Loss 0.1970\n2024-03-31 20:44:58,414 - root - INFO - CF Training: Epoch 0009 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.1894 | Iter Mean Loss 0.1970\n2024-03-31 20:45:16,579 - root - INFO - CF Training: Epoch 0009 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.1924 | Iter Mean Loss 0.1969\n2024-03-31 20:45:34,775 - root - INFO - CF Training: Epoch 0009 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.1920 | Iter Mean Loss 0.1970\n2024-03-31 20:45:52,974 - root - INFO - CF Training: Epoch 0009 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.2045 | Iter Mean Loss 0.1970\n2024-03-31 20:45:56,618 - root - INFO - CF Training: Epoch 0009 Total Iter 5410 | Total Time 1967.0s | Iter Mean Loss 0.1970\n2024-03-31 20:46:02,577 - root - INFO - KG Training: Epoch 0009 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0078\n2024-03-31 20:46:08,479 - root - INFO - KG Training: Epoch 0009 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0076\n2024-03-31 20:46:14,421 - root - INFO - KG Training: Epoch 0009 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0076\n2024-03-31 20:46:20,412 - root - INFO - KG Training: Epoch 0009 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0076\n2024-03-31 20:46:26,440 - root - INFO - KG Training: Epoch 0009 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0077\n2024-03-31 20:46:32,471 - root - INFO - KG Training: Epoch 0009 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0101 | Iter Mean Loss 0.0077\n2024-03-31 20:46:38,442 - root - INFO - KG Training: Epoch 0009 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0078\n2024-03-31 20:46:44,411 - root - INFO - KG Training: Epoch 0009 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0078\n2024-03-31 20:46:50,391 - root - INFO - KG Training: Epoch 0009 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0078\n2024-03-31 20:46:56,327 - root - INFO - KG Training: Epoch 0009 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0078\n2024-03-31 20:47:02,111 - root - INFO - KG Training: Epoch 0009 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0077\n2024-03-31 20:47:08,044 - root - INFO - KG Training: Epoch 0009 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0077\n2024-03-31 20:47:13,972 - root - INFO - KG Training: Epoch 0009 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0067 | Iter Mean Loss 0.0077\n2024-03-31 20:47:19,878 - root - INFO - KG Training: Epoch 0009 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0077\n2024-03-31 20:47:25,699 - root - INFO - KG Training: Epoch 0009 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0077\n2024-03-31 20:47:31,539 - root - INFO - KG Training: Epoch 0009 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0077\n2024-03-31 20:47:37,424 - root - INFO - KG Training: Epoch 0009 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0107 | Iter Mean Loss 0.0077\n2024-03-31 20:47:43,351 - root - INFO - KG Training: Epoch 0009 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0077\n2024-03-31 20:47:49,320 - root - INFO - KG Training: Epoch 0009 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0077\n2024-03-31 20:47:55,274 - root - INFO - KG Training: Epoch 0009 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0077\n2024-03-31 20:48:01,249 - root - INFO - KG Training: Epoch 0009 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0078\n2024-03-31 20:48:07,170 - root - INFO - KG Training: Epoch 0009 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0078\n2024-03-31 20:48:13,140 - root - INFO - KG Training: Epoch 0009 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0113 | Iter Mean Loss 0.0078\n2024-03-31 20:48:19,134 - root - INFO - KG Training: Epoch 0009 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0078\n2024-03-31 20:48:25,102 - root - INFO - KG Training: Epoch 0009 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0109 | Iter Mean Loss 0.0078\n2024-03-31 20:48:31,015 - root - INFO - KG Training: Epoch 0009 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0078\n2024-03-31 20:48:36,901 - root - INFO - KG Training: Epoch 0009 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0078\n2024-03-31 20:48:42,741 - root - INFO - KG Training: Epoch 0009 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0038 | Iter Mean Loss 0.0077\n2024-03-31 20:48:48,610 - root - INFO - KG Training: Epoch 0009 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0077\n2024-03-31 20:48:54,661 - root - INFO - KG Training: Epoch 0009 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0078\n2024-03-31 20:49:00,582 - root - INFO - KG Training: Epoch 0009 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0078\n2024-03-31 20:49:06,537 - root - INFO - KG Training: Epoch 0009 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0078\n2024-03-31 20:49:12,449 - root - INFO - KG Training: Epoch 0009 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0045 | Iter Mean Loss 0.0078\n2024-03-31 20:49:18,327 - root - INFO - KG Training: Epoch 0009 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0078\n2024-03-31 20:49:24,270 - root - INFO - KG Training: Epoch 0009 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0077\n2024-03-31 20:49:30,180 - root - INFO - KG Training: Epoch 0009 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0077\n2024-03-31 20:49:36,084 - root - INFO - KG Training: Epoch 0009 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0077\n2024-03-31 20:49:41,978 - root - INFO - KG Training: Epoch 0009 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0077\n2024-03-31 20:49:47,891 - root - INFO - KG Training: Epoch 0009 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0077\n2024-03-31 20:49:53,793 - root - INFO - KG Training: Epoch 0009 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0077\n2024-03-31 20:49:59,749 - root - INFO - KG Training: Epoch 0009 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0077\n2024-03-31 20:50:05,641 - root - INFO - KG Training: Epoch 0009 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0108 | Iter Mean Loss 0.0077\n2024-03-31 20:50:11,530 - root - INFO - KG Training: Epoch 0009 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0077\n2024-03-31 20:50:17,403 - root - INFO - KG Training: Epoch 0009 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0077\n2024-03-31 20:50:23,382 - root - INFO - KG Training: Epoch 0009 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0114 | Iter Mean Loss 0.0077\n2024-03-31 20:50:29,341 - root - INFO - KG Training: Epoch 0009 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0077\n2024-03-31 20:50:35,316 - root - INFO - KG Training: Epoch 0009 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0077\n2024-03-31 20:50:41,308 - root - INFO - KG Training: Epoch 0009 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0077\n2024-03-31 20:50:47,170 - root - INFO - KG Training: Epoch 0009 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0077\n2024-03-31 20:50:53,056 - root - INFO - KG Training: Epoch 0009 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0077\n2024-03-31 20:50:59,067 - root - INFO - KG Training: Epoch 0009 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0077\n2024-03-31 20:51:05,010 - root - INFO - KG Training: Epoch 0009 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0077\n2024-03-31 20:51:10,932 - root - INFO - KG Training: Epoch 0009 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0077\n2024-03-31 20:51:16,965 - root - INFO - KG Training: Epoch 0009 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0077\n2024-03-31 20:51:22,837 - root - INFO - KG Training: Epoch 0009 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0077\n2024-03-31 20:51:28,785 - root - INFO - KG Training: Epoch 0009 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0077\n2024-03-31 20:51:34,772 - root - INFO - KG Training: Epoch 0009 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0076\n2024-03-31 20:51:40,664 - root - INFO - KG Training: Epoch 0009 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0076\n2024-03-31 20:51:46,648 - root - INFO - KG Training: Epoch 0009 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0076\n2024-03-31 20:51:52,542 - root - INFO - KG Training: Epoch 0009 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0076\n2024-03-31 20:51:58,485 - root - INFO - KG Training: Epoch 0009 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0039 | Iter Mean Loss 0.0076\n2024-03-31 20:52:04,541 - root - INFO - KG Training: Epoch 0009 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0072 | Iter Mean Loss 0.0076\n2024-03-31 20:52:10,437 - root - INFO - KG Training: Epoch 0009 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0047 | Iter Mean Loss 0.0076\n2024-03-31 20:52:16,347 - root - INFO - KG Training: Epoch 0009 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0076\n2024-03-31 20:52:22,282 - root - INFO - KG Training: Epoch 0009 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0076\n2024-03-31 20:52:28,214 - root - INFO - KG Training: Epoch 0009 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0076\n2024-03-31 20:52:34,293 - root - INFO - KG Training: Epoch 0009 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0076\n2024-03-31 20:52:40,292 - root - INFO - KG Training: Epoch 0009 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0076\n2024-03-31 20:52:46,156 - root - INFO - KG Training: Epoch 0009 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0076\n2024-03-31 20:52:52,058 - root - INFO - KG Training: Epoch 0009 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0076\n2024-03-31 20:52:57,959 - root - INFO - KG Training: Epoch 0009 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0081 | Iter Mean Loss 0.0076\n2024-03-31 20:53:03,908 - root - INFO - KG Training: Epoch 0009 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0076\n2024-03-31 20:53:09,843 - root - INFO - KG Training: Epoch 0009 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0076\n2024-03-31 20:53:15,788 - root - INFO - KG Training: Epoch 0009 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0076\n2024-03-31 20:53:21,620 - root - INFO - KG Training: Epoch 0009 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0076\n2024-03-31 20:53:27,488 - root - INFO - KG Training: Epoch 0009 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0076\n2024-03-31 20:53:33,330 - root - INFO - KG Training: Epoch 0009 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0076\n2024-03-31 20:53:39,329 - root - INFO - KG Training: Epoch 0009 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0076\n2024-03-31 20:53:45,299 - root - INFO - KG Training: Epoch 0009 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0076\n2024-03-31 20:53:51,176 - root - INFO - KG Training: Epoch 0009 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0076\n2024-03-31 20:53:57,084 - root - INFO - KG Training: Epoch 0009 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0076\n2024-03-31 20:54:03,126 - root - INFO - KG Training: Epoch 0009 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0076\n2024-03-31 20:54:09,327 - root - INFO - KG Training: Epoch 0009 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0076\n2024-03-31 20:54:15,211 - root - INFO - KG Training: Epoch 0009 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0076\n2024-03-31 20:54:21,157 - root - INFO - KG Training: Epoch 0009 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0076\n2024-03-31 20:54:27,164 - root - INFO - KG Training: Epoch 0009 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0076\n2024-03-31 20:54:33,058 - root - INFO - KG Training: Epoch 0009 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0028 | Iter Mean Loss 0.0076\n2024-03-31 20:54:39,083 - root - INFO - KG Training: Epoch 0009 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0076\n2024-03-31 20:54:45,001 - root - INFO - KG Training: Epoch 0009 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0076\n2024-03-31 20:54:50,935 - root - INFO - KG Training: Epoch 0009 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0076\n2024-03-31 20:54:56,920 - root - INFO - KG Training: Epoch 0009 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0076\n2024-03-31 20:55:02,784 - root - INFO - KG Training: Epoch 0009 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0118 | Iter Mean Loss 0.0076\n2024-03-31 20:55:08,790 - root - INFO - KG Training: Epoch 0009 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0076\n2024-03-31 20:55:14,758 - root - INFO - KG Training: Epoch 0009 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0076\n2024-03-31 20:55:20,635 - root - INFO - KG Training: Epoch 0009 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0076\n2024-03-31 20:55:26,705 - root - INFO - KG Training: Epoch 0009 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0076\n2024-03-31 20:55:32,622 - root - INFO - KG Training: Epoch 0009 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0074 | Iter Mean Loss 0.0076\n2024-03-31 20:55:38,680 - root - INFO - KG Training: Epoch 0009 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0076\n2024-03-31 20:55:44,647 - root - INFO - KG Training: Epoch 0009 Iter 4950 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0076\n2024-03-31 20:55:50,624 - root - INFO - KG Training: Epoch 0009 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0075\n2024-03-31 20:55:56,483 - root - INFO - KG Training: Epoch 0009 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0075\n2024-03-31 20:56:02,360 - root - INFO - KG Training: Epoch 0009 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0075\n2024-03-31 20:56:08,336 - root - INFO - KG Training: Epoch 0009 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0075\n2024-03-31 20:56:14,347 - root - INFO - KG Training: Epoch 0009 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0075\n2024-03-31 20:56:20,316 - root - INFO - KG Training: Epoch 0009 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0075\n2024-03-31 20:56:26,160 - root - INFO - KG Training: Epoch 0009 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0075\n2024-03-31 20:56:32,021 - root - INFO - KG Training: Epoch 0009 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0075\n2024-03-31 20:56:37,828 - root - INFO - KG Training: Epoch 0009 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0038 | Iter Mean Loss 0.0075\n2024-03-31 20:56:42,839 - root - INFO - KG Training: Epoch 0009 Total Iter 5442 | Total Time 646.2s | Iter Mean Loss 0.0075\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 20:56:45,599 - root - INFO - Update Attention: Epoch 0009 | Total Time 2.8s\n2024-03-31 20:56:45,600 - root - INFO - CF + KG Training: Epoch 0009 | Total Time 2616.0s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:15<00:00,  5.27it/s]\n2024-03-31 20:59:00,709 - root - INFO - CF Evaluation: Epoch 0009 | Total Time 135.1s | Precision [0.0280, 0.0168], Recall [0.1800, 0.4757], NDCG [0.1009, 0.1790]\n2024-03-31 20:59:01,218 - root - INFO - Save model on epoch 0009!\n2024-03-31 20:59:19,382 - root - INFO - CF Training: Epoch 0010 Iter 0050 / 5410 | Time 0.4s | Iter Loss 0.2101 | Iter Mean Loss 0.2004\n2024-03-31 20:59:37,510 - root - INFO - CF Training: Epoch 0010 Iter 0100 / 5410 | Time 0.4s | Iter Loss 0.1959 | Iter Mean Loss 0.1995\n2024-03-31 20:59:55,692 - root - INFO - CF Training: Epoch 0010 Iter 0150 / 5410 | Time 0.4s | Iter Loss 0.2099 | Iter Mean Loss 0.1990\n2024-03-31 21:00:13,838 - root - INFO - CF Training: Epoch 0010 Iter 0200 / 5410 | Time 0.4s | Iter Loss 0.1977 | Iter Mean Loss 0.1986\n2024-03-31 21:00:31,991 - root - INFO - CF Training: Epoch 0010 Iter 0250 / 5410 | Time 0.4s | Iter Loss 0.2025 | Iter Mean Loss 0.1984\n2024-03-31 21:00:50,195 - root - INFO - CF Training: Epoch 0010 Iter 0300 / 5410 | Time 0.4s | Iter Loss 0.1929 | Iter Mean Loss 0.1985\n2024-03-31 21:01:08,582 - root - INFO - CF Training: Epoch 0010 Iter 0350 / 5410 | Time 0.4s | Iter Loss 0.1863 | Iter Mean Loss 0.1982\n2024-03-31 21:01:26,968 - root - INFO - CF Training: Epoch 0010 Iter 0400 / 5410 | Time 0.4s | Iter Loss 0.2014 | Iter Mean Loss 0.1977\n2024-03-31 21:01:45,104 - root - INFO - CF Training: Epoch 0010 Iter 0450 / 5410 | Time 0.4s | Iter Loss 0.2061 | Iter Mean Loss 0.1973\n2024-03-31 21:02:03,278 - root - INFO - CF Training: Epoch 0010 Iter 0500 / 5410 | Time 0.4s | Iter Loss 0.1987 | Iter Mean Loss 0.1973\n2024-03-31 21:02:21,464 - root - INFO - CF Training: Epoch 0010 Iter 0550 / 5410 | Time 0.4s | Iter Loss 0.1848 | Iter Mean Loss 0.1974\n2024-03-31 21:02:39,636 - root - INFO - CF Training: Epoch 0010 Iter 0600 / 5410 | Time 0.4s | Iter Loss 0.1937 | Iter Mean Loss 0.1972\n2024-03-31 21:02:57,817 - root - INFO - CF Training: Epoch 0010 Iter 0650 / 5410 | Time 0.4s | Iter Loss 0.1920 | Iter Mean Loss 0.1972\n2024-03-31 21:03:15,988 - root - INFO - CF Training: Epoch 0010 Iter 0700 / 5410 | Time 0.4s | Iter Loss 0.2013 | Iter Mean Loss 0.1971\n2024-03-31 21:03:34,196 - root - INFO - CF Training: Epoch 0010 Iter 0750 / 5410 | Time 0.4s | Iter Loss 0.2100 | Iter Mean Loss 0.1968\n2024-03-31 21:03:52,347 - root - INFO - CF Training: Epoch 0010 Iter 0800 / 5410 | Time 0.4s | Iter Loss 0.1844 | Iter Mean Loss 0.1968\n2024-03-31 21:04:10,472 - root - INFO - CF Training: Epoch 0010 Iter 0850 / 5410 | Time 0.4s | Iter Loss 0.1892 | Iter Mean Loss 0.1966\n2024-03-31 21:04:28,597 - root - INFO - CF Training: Epoch 0010 Iter 0900 / 5410 | Time 0.4s | Iter Loss 0.2087 | Iter Mean Loss 0.1966\n2024-03-31 21:04:46,779 - root - INFO - CF Training: Epoch 0010 Iter 0950 / 5410 | Time 0.4s | Iter Loss 0.1980 | Iter Mean Loss 0.1966\n2024-03-31 21:05:04,920 - root - INFO - CF Training: Epoch 0010 Iter 1000 / 5410 | Time 0.4s | Iter Loss 0.2051 | Iter Mean Loss 0.1965\n2024-03-31 21:05:23,071 - root - INFO - CF Training: Epoch 0010 Iter 1050 / 5410 | Time 0.4s | Iter Loss 0.1999 | Iter Mean Loss 0.1965\n2024-03-31 21:05:41,205 - root - INFO - CF Training: Epoch 0010 Iter 1100 / 5410 | Time 0.4s | Iter Loss 0.1908 | Iter Mean Loss 0.1965\n2024-03-31 21:05:59,344 - root - INFO - CF Training: Epoch 0010 Iter 1150 / 5410 | Time 0.4s | Iter Loss 0.1976 | Iter Mean Loss 0.1965\n2024-03-31 21:06:17,456 - root - INFO - CF Training: Epoch 0010 Iter 1200 / 5410 | Time 0.4s | Iter Loss 0.1914 | Iter Mean Loss 0.1965\n2024-03-31 21:06:35,561 - root - INFO - CF Training: Epoch 0010 Iter 1250 / 5410 | Time 0.4s | Iter Loss 0.1860 | Iter Mean Loss 0.1965\n2024-03-31 21:06:53,696 - root - INFO - CF Training: Epoch 0010 Iter 1300 / 5410 | Time 0.4s | Iter Loss 0.1705 | Iter Mean Loss 0.1964\n2024-03-31 21:07:11,843 - root - INFO - CF Training: Epoch 0010 Iter 1350 / 5410 | Time 0.4s | Iter Loss 0.1912 | Iter Mean Loss 0.1963\n2024-03-31 21:07:29,972 - root - INFO - CF Training: Epoch 0010 Iter 1400 / 5410 | Time 0.4s | Iter Loss 0.2015 | Iter Mean Loss 0.1963\n2024-03-31 21:07:48,102 - root - INFO - CF Training: Epoch 0010 Iter 1450 / 5410 | Time 0.4s | Iter Loss 0.1962 | Iter Mean Loss 0.1963\n2024-03-31 21:08:06,215 - root - INFO - CF Training: Epoch 0010 Iter 1500 / 5410 | Time 0.4s | Iter Loss 0.1924 | Iter Mean Loss 0.1963\n2024-03-31 21:08:24,338 - root - INFO - CF Training: Epoch 0010 Iter 1550 / 5410 | Time 0.4s | Iter Loss 0.2073 | Iter Mean Loss 0.1963\n2024-03-31 21:08:42,440 - root - INFO - CF Training: Epoch 0010 Iter 1600 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.1963\n2024-03-31 21:09:00,578 - root - INFO - CF Training: Epoch 0010 Iter 1650 / 5410 | Time 0.4s | Iter Loss 0.1966 | Iter Mean Loss 0.1963\n2024-03-31 21:09:18,763 - root - INFO - CF Training: Epoch 0010 Iter 1700 / 5410 | Time 0.4s | Iter Loss 0.1898 | Iter Mean Loss 0.1963\n2024-03-31 21:09:36,922 - root - INFO - CF Training: Epoch 0010 Iter 1750 / 5410 | Time 0.4s | Iter Loss 0.2031 | Iter Mean Loss 0.1962\n2024-03-31 21:09:54,999 - root - INFO - CF Training: Epoch 0010 Iter 1800 / 5410 | Time 0.4s | Iter Loss 0.1792 | Iter Mean Loss 0.1962\n2024-03-31 21:10:13,079 - root - INFO - CF Training: Epoch 0010 Iter 1850 / 5410 | Time 0.4s | Iter Loss 0.1990 | Iter Mean Loss 0.1961\n2024-03-31 21:10:31,134 - root - INFO - CF Training: Epoch 0010 Iter 1900 / 5410 | Time 0.4s | Iter Loss 0.1800 | Iter Mean Loss 0.1961\n2024-03-31 21:10:49,247 - root - INFO - CF Training: Epoch 0010 Iter 1950 / 5410 | Time 0.4s | Iter Loss 0.2000 | Iter Mean Loss 0.1961\n2024-03-31 21:11:07,428 - root - INFO - CF Training: Epoch 0010 Iter 2000 / 5410 | Time 0.4s | Iter Loss 0.2202 | Iter Mean Loss 0.1960\n2024-03-31 21:11:25,553 - root - INFO - CF Training: Epoch 0010 Iter 2050 / 5410 | Time 0.4s | Iter Loss 0.1875 | Iter Mean Loss 0.1959\n2024-03-31 21:11:43,662 - root - INFO - CF Training: Epoch 0010 Iter 2100 / 5410 | Time 0.4s | Iter Loss 0.1929 | Iter Mean Loss 0.1959\n2024-03-31 21:12:01,778 - root - INFO - CF Training: Epoch 0010 Iter 2150 / 5410 | Time 0.4s | Iter Loss 0.1757 | Iter Mean Loss 0.1959\n2024-03-31 21:12:19,915 - root - INFO - CF Training: Epoch 0010 Iter 2200 / 5410 | Time 0.4s | Iter Loss 0.2063 | Iter Mean Loss 0.1959\n2024-03-31 21:12:38,077 - root - INFO - CF Training: Epoch 0010 Iter 2250 / 5410 | Time 0.4s | Iter Loss 0.1958 | Iter Mean Loss 0.1959\n2024-03-31 21:12:56,148 - root - INFO - CF Training: Epoch 0010 Iter 2300 / 5410 | Time 0.4s | Iter Loss 0.1883 | Iter Mean Loss 0.1959\n2024-03-31 21:13:14,240 - root - INFO - CF Training: Epoch 0010 Iter 2350 / 5410 | Time 0.4s | Iter Loss 0.1931 | Iter Mean Loss 0.1958\n2024-03-31 21:13:32,253 - root - INFO - CF Training: Epoch 0010 Iter 2400 / 5410 | Time 0.4s | Iter Loss 0.1790 | Iter Mean Loss 0.1957\n2024-03-31 21:13:50,299 - root - INFO - CF Training: Epoch 0010 Iter 2450 / 5410 | Time 0.4s | Iter Loss 0.1892 | Iter Mean Loss 0.1957\n2024-03-31 21:14:08,342 - root - INFO - CF Training: Epoch 0010 Iter 2500 / 5410 | Time 0.4s | Iter Loss 0.1946 | Iter Mean Loss 0.1957\n2024-03-31 21:14:26,386 - root - INFO - CF Training: Epoch 0010 Iter 2550 / 5410 | Time 0.4s | Iter Loss 0.1970 | Iter Mean Loss 0.1957\n2024-03-31 21:14:44,448 - root - INFO - CF Training: Epoch 0010 Iter 2600 / 5410 | Time 0.4s | Iter Loss 0.1928 | Iter Mean Loss 0.1957\n2024-03-31 21:15:02,508 - root - INFO - CF Training: Epoch 0010 Iter 2650 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.1957\n2024-03-31 21:15:20,604 - root - INFO - CF Training: Epoch 0010 Iter 2700 / 5410 | Time 0.4s | Iter Loss 0.1729 | Iter Mean Loss 0.1956\n2024-03-31 21:15:38,688 - root - INFO - CF Training: Epoch 0010 Iter 2750 / 5410 | Time 0.4s | Iter Loss 0.1843 | Iter Mean Loss 0.1956\n2024-03-31 21:15:56,770 - root - INFO - CF Training: Epoch 0010 Iter 2800 / 5410 | Time 0.4s | Iter Loss 0.1982 | Iter Mean Loss 0.1956\n2024-03-31 21:16:14,876 - root - INFO - CF Training: Epoch 0010 Iter 2850 / 5410 | Time 0.4s | Iter Loss 0.1992 | Iter Mean Loss 0.1956\n2024-03-31 21:16:32,948 - root - INFO - CF Training: Epoch 0010 Iter 2900 / 5410 | Time 0.4s | Iter Loss 0.1986 | Iter Mean Loss 0.1955\n2024-03-31 21:16:51,013 - root - INFO - CF Training: Epoch 0010 Iter 2950 / 5410 | Time 0.4s | Iter Loss 0.2064 | Iter Mean Loss 0.1956\n2024-03-31 21:17:09,089 - root - INFO - CF Training: Epoch 0010 Iter 3000 / 5410 | Time 0.4s | Iter Loss 0.1833 | Iter Mean Loss 0.1955\n2024-03-31 21:17:27,217 - root - INFO - CF Training: Epoch 0010 Iter 3050 / 5410 | Time 0.4s | Iter Loss 0.2111 | Iter Mean Loss 0.1955\n2024-03-31 21:17:45,317 - root - INFO - CF Training: Epoch 0010 Iter 3100 / 5410 | Time 0.4s | Iter Loss 0.1874 | Iter Mean Loss 0.1955\n2024-03-31 21:18:03,433 - root - INFO - CF Training: Epoch 0010 Iter 3150 / 5410 | Time 0.4s | Iter Loss 0.1920 | Iter Mean Loss 0.1954\n2024-03-31 21:18:21,505 - root - INFO - CF Training: Epoch 0010 Iter 3200 / 5410 | Time 0.4s | Iter Loss 0.2050 | Iter Mean Loss 0.1954\n2024-03-31 21:18:39,584 - root - INFO - CF Training: Epoch 0010 Iter 3250 / 5410 | Time 0.4s | Iter Loss 0.2029 | Iter Mean Loss 0.1954\n2024-03-31 21:18:57,677 - root - INFO - CF Training: Epoch 0010 Iter 3300 / 5410 | Time 0.4s | Iter Loss 0.2047 | Iter Mean Loss 0.1953\n2024-03-31 21:19:15,751 - root - INFO - CF Training: Epoch 0010 Iter 3350 / 5410 | Time 0.4s | Iter Loss 0.1949 | Iter Mean Loss 0.1953\n2024-03-31 21:19:33,833 - root - INFO - CF Training: Epoch 0010 Iter 3400 / 5410 | Time 0.4s | Iter Loss 0.2019 | Iter Mean Loss 0.1953\n2024-03-31 21:19:51,995 - root - INFO - CF Training: Epoch 0010 Iter 3450 / 5410 | Time 0.4s | Iter Loss 0.1939 | Iter Mean Loss 0.1952\n2024-03-31 21:20:10,080 - root - INFO - CF Training: Epoch 0010 Iter 3500 / 5410 | Time 0.4s | Iter Loss 0.1964 | Iter Mean Loss 0.1952\n2024-03-31 21:20:28,177 - root - INFO - CF Training: Epoch 0010 Iter 3550 / 5410 | Time 0.4s | Iter Loss 0.1951 | Iter Mean Loss 0.1952\n2024-03-31 21:20:46,266 - root - INFO - CF Training: Epoch 0010 Iter 3600 / 5410 | Time 0.4s | Iter Loss 0.2021 | Iter Mean Loss 0.1952\n2024-03-31 21:21:04,383 - root - INFO - CF Training: Epoch 0010 Iter 3650 / 5410 | Time 0.4s | Iter Loss 0.1938 | Iter Mean Loss 0.1952\n2024-03-31 21:21:22,473 - root - INFO - CF Training: Epoch 0010 Iter 3700 / 5410 | Time 0.4s | Iter Loss 0.1842 | Iter Mean Loss 0.1951\n2024-03-31 21:21:40,563 - root - INFO - CF Training: Epoch 0010 Iter 3750 / 5410 | Time 0.4s | Iter Loss 0.1999 | Iter Mean Loss 0.1951\n2024-03-31 21:21:58,681 - root - INFO - CF Training: Epoch 0010 Iter 3800 / 5410 | Time 0.4s | Iter Loss 0.1944 | Iter Mean Loss 0.1950\n2024-03-31 21:22:16,781 - root - INFO - CF Training: Epoch 0010 Iter 3850 / 5410 | Time 0.4s | Iter Loss 0.1895 | Iter Mean Loss 0.1950\n2024-03-31 21:22:34,881 - root - INFO - CF Training: Epoch 0010 Iter 3900 / 5410 | Time 0.4s | Iter Loss 0.1824 | Iter Mean Loss 0.1950\n2024-03-31 21:22:52,943 - root - INFO - CF Training: Epoch 0010 Iter 3950 / 5410 | Time 0.4s | Iter Loss 0.1908 | Iter Mean Loss 0.1950\n2024-03-31 21:23:11,043 - root - INFO - CF Training: Epoch 0010 Iter 4000 / 5410 | Time 0.4s | Iter Loss 0.1954 | Iter Mean Loss 0.1950\n2024-03-31 21:23:29,160 - root - INFO - CF Training: Epoch 0010 Iter 4050 / 5410 | Time 0.4s | Iter Loss 0.1989 | Iter Mean Loss 0.1949\n2024-03-31 21:23:47,266 - root - INFO - CF Training: Epoch 0010 Iter 4100 / 5410 | Time 0.4s | Iter Loss 0.2062 | Iter Mean Loss 0.1949\n2024-03-31 21:24:05,367 - root - INFO - CF Training: Epoch 0010 Iter 4150 / 5410 | Time 0.4s | Iter Loss 0.1908 | Iter Mean Loss 0.1948\n2024-03-31 21:24:23,444 - root - INFO - CF Training: Epoch 0010 Iter 4200 / 5410 | Time 0.4s | Iter Loss 0.1997 | Iter Mean Loss 0.1949\n2024-03-31 21:24:41,548 - root - INFO - CF Training: Epoch 0010 Iter 4250 / 5410 | Time 0.4s | Iter Loss 0.1858 | Iter Mean Loss 0.1949\n2024-03-31 21:24:59,685 - root - INFO - CF Training: Epoch 0010 Iter 4300 / 5410 | Time 0.4s | Iter Loss 0.1864 | Iter Mean Loss 0.1948\n2024-03-31 21:25:17,771 - root - INFO - CF Training: Epoch 0010 Iter 4350 / 5410 | Time 0.4s | Iter Loss 0.2069 | Iter Mean Loss 0.1948\n2024-03-31 21:25:35,870 - root - INFO - CF Training: Epoch 0010 Iter 4400 / 5410 | Time 0.4s | Iter Loss 0.1869 | Iter Mean Loss 0.1948\n2024-03-31 21:25:54,004 - root - INFO - CF Training: Epoch 0010 Iter 4450 / 5410 | Time 0.4s | Iter Loss 0.1990 | Iter Mean Loss 0.1948\n2024-03-31 21:26:12,117 - root - INFO - CF Training: Epoch 0010 Iter 4500 / 5410 | Time 0.4s | Iter Loss 0.1997 | Iter Mean Loss 0.1948\n2024-03-31 21:26:30,197 - root - INFO - CF Training: Epoch 0010 Iter 4550 / 5410 | Time 0.4s | Iter Loss 0.1904 | Iter Mean Loss 0.1948\n2024-03-31 21:26:48,276 - root - INFO - CF Training: Epoch 0010 Iter 4600 / 5410 | Time 0.4s | Iter Loss 0.1939 | Iter Mean Loss 0.1948\n2024-03-31 21:27:06,425 - root - INFO - CF Training: Epoch 0010 Iter 4650 / 5410 | Time 0.4s | Iter Loss 0.1937 | Iter Mean Loss 0.1948\n2024-03-31 21:27:24,518 - root - INFO - CF Training: Epoch 0010 Iter 4700 / 5410 | Time 0.4s | Iter Loss 0.1801 | Iter Mean Loss 0.1947\n2024-03-31 21:27:42,639 - root - INFO - CF Training: Epoch 0010 Iter 4750 / 5410 | Time 0.4s | Iter Loss 0.2104 | Iter Mean Loss 0.1947\n2024-03-31 21:28:00,741 - root - INFO - CF Training: Epoch 0010 Iter 4800 / 5410 | Time 0.4s | Iter Loss 0.1805 | Iter Mean Loss 0.1947\n2024-03-31 21:28:18,849 - root - INFO - CF Training: Epoch 0010 Iter 4850 / 5410 | Time 0.4s | Iter Loss 0.1936 | Iter Mean Loss 0.1947\n2024-03-31 21:28:36,998 - root - INFO - CF Training: Epoch 0010 Iter 4900 / 5410 | Time 0.4s | Iter Loss 0.1963 | Iter Mean Loss 0.1947\n2024-03-31 21:28:55,251 - root - INFO - CF Training: Epoch 0010 Iter 4950 / 5410 | Time 0.4s | Iter Loss 0.1930 | Iter Mean Loss 0.1947\n2024-03-31 21:29:13,539 - root - INFO - CF Training: Epoch 0010 Iter 5000 / 5410 | Time 0.4s | Iter Loss 0.2017 | Iter Mean Loss 0.1947\n2024-03-31 21:29:31,802 - root - INFO - CF Training: Epoch 0010 Iter 5050 / 5410 | Time 0.4s | Iter Loss 0.1784 | Iter Mean Loss 0.1947\n2024-03-31 21:29:50,135 - root - INFO - CF Training: Epoch 0010 Iter 5100 / 5410 | Time 0.4s | Iter Loss 0.1935 | Iter Mean Loss 0.1946\n2024-03-31 21:30:08,391 - root - INFO - CF Training: Epoch 0010 Iter 5150 / 5410 | Time 0.4s | Iter Loss 0.2079 | Iter Mean Loss 0.1946\n2024-03-31 21:30:26,664 - root - INFO - CF Training: Epoch 0010 Iter 5200 / 5410 | Time 0.4s | Iter Loss 0.2033 | Iter Mean Loss 0.1946\n2024-03-31 21:30:44,956 - root - INFO - CF Training: Epoch 0010 Iter 5250 / 5410 | Time 0.4s | Iter Loss 0.1754 | Iter Mean Loss 0.1946\n2024-03-31 21:31:03,123 - root - INFO - CF Training: Epoch 0010 Iter 5300 / 5410 | Time 0.4s | Iter Loss 0.1862 | Iter Mean Loss 0.1946\n2024-03-31 21:31:21,291 - root - INFO - CF Training: Epoch 0010 Iter 5350 / 5410 | Time 0.4s | Iter Loss 0.1847 | Iter Mean Loss 0.1945\n2024-03-31 21:31:39,465 - root - INFO - CF Training: Epoch 0010 Iter 5400 / 5410 | Time 0.4s | Iter Loss 0.1966 | Iter Mean Loss 0.1945\n2024-03-31 21:31:43,085 - root - INFO - CF Training: Epoch 0010 Total Iter 5410 | Total Time 1961.9s | Iter Mean Loss 0.1945\n2024-03-31 21:31:49,083 - root - INFO - KG Training: Epoch 0010 Iter 0050 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0076\n2024-03-31 21:31:55,075 - root - INFO - KG Training: Epoch 0010 Iter 0100 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0073\n2024-03-31 21:32:01,070 - root - INFO - KG Training: Epoch 0010 Iter 0150 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0073\n2024-03-31 21:32:06,896 - root - INFO - KG Training: Epoch 0010 Iter 0200 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0073\n2024-03-31 21:32:12,804 - root - INFO - KG Training: Epoch 0010 Iter 0250 / 5442 | Time 0.1s | Iter Loss 0.0106 | Iter Mean Loss 0.0074\n2024-03-31 21:32:18,610 - root - INFO - KG Training: Epoch 0010 Iter 0300 / 5442 | Time 0.1s | Iter Loss 0.0098 | Iter Mean Loss 0.0073\n2024-03-31 21:32:24,550 - root - INFO - KG Training: Epoch 0010 Iter 0350 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0073\n2024-03-31 21:32:30,386 - root - INFO - KG Training: Epoch 0010 Iter 0400 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0074\n2024-03-31 21:32:36,379 - root - INFO - KG Training: Epoch 0010 Iter 0450 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0074\n2024-03-31 21:32:42,274 - root - INFO - KG Training: Epoch 0010 Iter 0500 / 5442 | Time 0.1s | Iter Loss 0.0091 | Iter Mean Loss 0.0074\n2024-03-31 21:32:48,159 - root - INFO - KG Training: Epoch 0010 Iter 0550 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0074\n2024-03-31 21:32:54,140 - root - INFO - KG Training: Epoch 0010 Iter 0600 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0075\n2024-03-31 21:33:00,027 - root - INFO - KG Training: Epoch 0010 Iter 0650 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0075\n2024-03-31 21:33:05,930 - root - INFO - KG Training: Epoch 0010 Iter 0700 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0074\n2024-03-31 21:33:11,801 - root - INFO - KG Training: Epoch 0010 Iter 0750 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0074\n2024-03-31 21:33:17,671 - root - INFO - KG Training: Epoch 0010 Iter 0800 / 5442 | Time 0.1s | Iter Loss 0.0064 | Iter Mean Loss 0.0074\n2024-03-31 21:33:23,438 - root - INFO - KG Training: Epoch 0010 Iter 0850 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0074\n2024-03-31 21:33:29,244 - root - INFO - KG Training: Epoch 0010 Iter 0900 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0074\n2024-03-31 21:33:34,847 - root - INFO - KG Training: Epoch 0010 Iter 0950 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0074\n2024-03-31 21:33:40,566 - root - INFO - KG Training: Epoch 0010 Iter 1000 / 5442 | Time 0.1s | Iter Loss 0.0092 | Iter Mean Loss 0.0074\n2024-03-31 21:33:46,080 - root - INFO - KG Training: Epoch 0010 Iter 1050 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0074\n2024-03-31 21:33:51,575 - root - INFO - KG Training: Epoch 0010 Iter 1100 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0074\n2024-03-31 21:33:57,124 - root - INFO - KG Training: Epoch 0010 Iter 1150 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0074\n2024-03-31 21:34:02,492 - root - INFO - KG Training: Epoch 0010 Iter 1200 / 5442 | Time 0.1s | Iter Loss 0.0085 | Iter Mean Loss 0.0074\n2024-03-31 21:34:07,801 - root - INFO - KG Training: Epoch 0010 Iter 1250 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0074\n2024-03-31 21:34:13,193 - root - INFO - KG Training: Epoch 0010 Iter 1300 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0074\n2024-03-31 21:34:18,744 - root - INFO - KG Training: Epoch 0010 Iter 1350 / 5442 | Time 0.1s | Iter Loss 0.0034 | Iter Mean Loss 0.0074\n2024-03-31 21:34:24,289 - root - INFO - KG Training: Epoch 0010 Iter 1400 / 5442 | Time 0.1s | Iter Loss 0.0083 | Iter Mean Loss 0.0074\n2024-03-31 21:34:29,682 - root - INFO - KG Training: Epoch 0010 Iter 1450 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0073\n2024-03-31 21:34:35,100 - root - INFO - KG Training: Epoch 0010 Iter 1500 / 5442 | Time 0.1s | Iter Loss 0.0054 | Iter Mean Loss 0.0074\n2024-03-31 21:34:40,718 - root - INFO - KG Training: Epoch 0010 Iter 1550 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0074\n2024-03-31 21:34:46,087 - root - INFO - KG Training: Epoch 0010 Iter 1600 / 5442 | Time 0.1s | Iter Loss 0.0094 | Iter Mean Loss 0.0073\n2024-03-31 21:34:51,364 - root - INFO - KG Training: Epoch 0010 Iter 1650 / 5442 | Time 0.1s | Iter Loss 0.0043 | Iter Mean Loss 0.0073\n2024-03-31 21:34:56,874 - root - INFO - KG Training: Epoch 0010 Iter 1700 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0073\n2024-03-31 21:35:02,309 - root - INFO - KG Training: Epoch 0010 Iter 1750 / 5442 | Time 0.1s | Iter Loss 0.0097 | Iter Mean Loss 0.0073\n2024-03-31 21:35:07,806 - root - INFO - KG Training: Epoch 0010 Iter 1800 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0073\n2024-03-31 21:35:13,216 - root - INFO - KG Training: Epoch 0010 Iter 1850 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0073\n2024-03-31 21:35:18,586 - root - INFO - KG Training: Epoch 0010 Iter 1900 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0073\n2024-03-31 21:35:24,010 - root - INFO - KG Training: Epoch 0010 Iter 1950 / 5442 | Time 0.1s | Iter Loss 0.0051 | Iter Mean Loss 0.0073\n2024-03-31 21:35:29,540 - root - INFO - KG Training: Epoch 0010 Iter 2000 / 5442 | Time 0.1s | Iter Loss 0.0052 | Iter Mean Loss 0.0073\n2024-03-31 21:35:34,941 - root - INFO - KG Training: Epoch 0010 Iter 2050 / 5442 | Time 0.1s | Iter Loss 0.0053 | Iter Mean Loss 0.0073\n2024-03-31 21:35:40,499 - root - INFO - KG Training: Epoch 0010 Iter 2100 / 5442 | Time 0.1s | Iter Loss 0.0033 | Iter Mean Loss 0.0073\n2024-03-31 21:35:45,996 - root - INFO - KG Training: Epoch 0010 Iter 2150 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0073\n2024-03-31 21:35:51,430 - root - INFO - KG Training: Epoch 0010 Iter 2200 / 5442 | Time 0.1s | Iter Loss 0.0055 | Iter Mean Loss 0.0073\n2024-03-31 21:35:56,987 - root - INFO - KG Training: Epoch 0010 Iter 2250 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0073\n2024-03-31 21:36:02,366 - root - INFO - KG Training: Epoch 0010 Iter 2300 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0073\n2024-03-31 21:36:07,924 - root - INFO - KG Training: Epoch 0010 Iter 2350 / 5442 | Time 0.1s | Iter Loss 0.0065 | Iter Mean Loss 0.0073\n2024-03-31 21:36:13,306 - root - INFO - KG Training: Epoch 0010 Iter 2400 / 5442 | Time 0.1s | Iter Loss 0.0105 | Iter Mean Loss 0.0073\n2024-03-31 21:36:18,752 - root - INFO - KG Training: Epoch 0010 Iter 2450 / 5442 | Time 0.1s | Iter Loss 0.0080 | Iter Mean Loss 0.0073\n2024-03-31 21:36:24,395 - root - INFO - KG Training: Epoch 0010 Iter 2500 / 5442 | Time 0.1s | Iter Loss 0.0088 | Iter Mean Loss 0.0073\n2024-03-31 21:36:29,801 - root - INFO - KG Training: Epoch 0010 Iter 2550 / 5442 | Time 0.1s | Iter Loss 0.0056 | Iter Mean Loss 0.0073\n2024-03-31 21:36:35,180 - root - INFO - KG Training: Epoch 0010 Iter 2600 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0073\n2024-03-31 21:36:40,533 - root - INFO - KG Training: Epoch 0010 Iter 2650 / 5442 | Time 0.1s | Iter Loss 0.0034 | Iter Mean Loss 0.0073\n2024-03-31 21:36:46,006 - root - INFO - KG Training: Epoch 0010 Iter 2700 / 5442 | Time 0.1s | Iter Loss 0.0089 | Iter Mean Loss 0.0073\n2024-03-31 21:36:51,461 - root - INFO - KG Training: Epoch 0010 Iter 2750 / 5442 | Time 0.1s | Iter Loss 0.0073 | Iter Mean Loss 0.0073\n2024-03-31 21:36:56,918 - root - INFO - KG Training: Epoch 0010 Iter 2800 / 5442 | Time 0.1s | Iter Loss 0.0070 | Iter Mean Loss 0.0073\n2024-03-31 21:37:02,318 - root - INFO - KG Training: Epoch 0010 Iter 2850 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0073\n2024-03-31 21:37:07,495 - root - INFO - KG Training: Epoch 0010 Iter 2900 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0073\n2024-03-31 21:37:12,811 - root - INFO - KG Training: Epoch 0010 Iter 2950 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0073\n2024-03-31 21:37:18,312 - root - INFO - KG Training: Epoch 0010 Iter 3000 / 5442 | Time 0.1s | Iter Loss 0.0057 | Iter Mean Loss 0.0073\n2024-03-31 21:37:23,843 - root - INFO - KG Training: Epoch 0010 Iter 3050 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0073\n2024-03-31 21:37:29,265 - root - INFO - KG Training: Epoch 0010 Iter 3100 / 5442 | Time 0.1s | Iter Loss 0.0053 | Iter Mean Loss 0.0073\n2024-03-31 21:37:34,678 - root - INFO - KG Training: Epoch 0010 Iter 3150 / 5442 | Time 0.1s | Iter Loss 0.0090 | Iter Mean Loss 0.0073\n2024-03-31 21:37:39,909 - root - INFO - KG Training: Epoch 0010 Iter 3200 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0073\n2024-03-31 21:37:45,356 - root - INFO - KG Training: Epoch 0010 Iter 3250 / 5442 | Time 0.1s | Iter Loss 0.0077 | Iter Mean Loss 0.0073\n2024-03-31 21:37:50,864 - root - INFO - KG Training: Epoch 0010 Iter 3300 / 5442 | Time 0.1s | Iter Loss 0.0050 | Iter Mean Loss 0.0072\n2024-03-31 21:37:56,109 - root - INFO - KG Training: Epoch 0010 Iter 3350 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0072\n2024-03-31 21:38:01,425 - root - INFO - KG Training: Epoch 0010 Iter 3400 / 5442 | Time 0.1s | Iter Loss 0.0063 | Iter Mean Loss 0.0072\n2024-03-31 21:38:06,814 - root - INFO - KG Training: Epoch 0010 Iter 3450 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0072\n2024-03-31 21:38:12,229 - root - INFO - KG Training: Epoch 0010 Iter 3500 / 5442 | Time 0.1s | Iter Loss 0.0061 | Iter Mean Loss 0.0072\n2024-03-31 21:38:17,827 - root - INFO - KG Training: Epoch 0010 Iter 3550 / 5442 | Time 0.1s | Iter Loss 0.0078 | Iter Mean Loss 0.0072\n2024-03-31 21:38:23,263 - root - INFO - KG Training: Epoch 0010 Iter 3600 / 5442 | Time 0.1s | Iter Loss 0.0076 | Iter Mean Loss 0.0072\n2024-03-31 21:38:28,614 - root - INFO - KG Training: Epoch 0010 Iter 3650 / 5442 | Time 0.1s | Iter Loss 0.0099 | Iter Mean Loss 0.0072\n2024-03-31 21:38:34,166 - root - INFO - KG Training: Epoch 0010 Iter 3700 / 5442 | Time 0.1s | Iter Loss 0.0071 | Iter Mean Loss 0.0072\n2024-03-31 21:38:39,657 - root - INFO - KG Training: Epoch 0010 Iter 3750 / 5442 | Time 0.1s | Iter Loss 0.0084 | Iter Mean Loss 0.0072\n2024-03-31 21:38:44,963 - root - INFO - KG Training: Epoch 0010 Iter 3800 / 5442 | Time 0.1s | Iter Loss 0.0087 | Iter Mean Loss 0.0072\n2024-03-31 21:38:50,262 - root - INFO - KG Training: Epoch 0010 Iter 3850 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0072\n2024-03-31 21:38:55,582 - root - INFO - KG Training: Epoch 0010 Iter 3900 / 5442 | Time 0.1s | Iter Loss 0.0047 | Iter Mean Loss 0.0072\n2024-03-31 21:39:00,900 - root - INFO - KG Training: Epoch 0010 Iter 3950 / 5442 | Time 0.1s | Iter Loss 0.0058 | Iter Mean Loss 0.0072\n2024-03-31 21:39:06,423 - root - INFO - KG Training: Epoch 0010 Iter 4000 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0072\n2024-03-31 21:39:11,869 - root - INFO - KG Training: Epoch 0010 Iter 4050 / 5442 | Time 0.1s | Iter Loss 0.0034 | Iter Mean Loss 0.0072\n2024-03-31 21:39:17,140 - root - INFO - KG Training: Epoch 0010 Iter 4100 / 5442 | Time 0.1s | Iter Loss 0.0093 | Iter Mean Loss 0.0072\n2024-03-31 21:39:22,617 - root - INFO - KG Training: Epoch 0010 Iter 4150 / 5442 | Time 0.1s | Iter Loss 0.0059 | Iter Mean Loss 0.0072\n2024-03-31 21:39:28,016 - root - INFO - KG Training: Epoch 0010 Iter 4200 / 5442 | Time 0.1s | Iter Loss 0.0102 | Iter Mean Loss 0.0072\n2024-03-31 21:39:33,408 - root - INFO - KG Training: Epoch 0010 Iter 4250 / 5442 | Time 0.1s | Iter Loss 0.0069 | Iter Mean Loss 0.0072\n2024-03-31 21:39:38,778 - root - INFO - KG Training: Epoch 0010 Iter 4300 / 5442 | Time 0.1s | Iter Loss 0.0103 | Iter Mean Loss 0.0072\n2024-03-31 21:39:44,098 - root - INFO - KG Training: Epoch 0010 Iter 4350 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0072\n2024-03-31 21:39:49,428 - root - INFO - KG Training: Epoch 0010 Iter 4400 / 5442 | Time 0.1s | Iter Loss 0.0066 | Iter Mean Loss 0.0072\n2024-03-31 21:39:55,075 - root - INFO - KG Training: Epoch 0010 Iter 4450 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0072\n2024-03-31 21:40:00,493 - root - INFO - KG Training: Epoch 0010 Iter 4500 / 5442 | Time 0.1s | Iter Loss 0.0046 | Iter Mean Loss 0.0072\n2024-03-31 21:40:05,903 - root - INFO - KG Training: Epoch 0010 Iter 4550 / 5442 | Time 0.1s | Iter Loss 0.0082 | Iter Mean Loss 0.0072\n2024-03-31 21:40:11,450 - root - INFO - KG Training: Epoch 0010 Iter 4600 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0072\n2024-03-31 21:40:16,865 - root - INFO - KG Training: Epoch 0010 Iter 4650 / 5442 | Time 0.1s | Iter Loss 0.0062 | Iter Mean Loss 0.0072\n2024-03-31 21:40:22,338 - root - INFO - KG Training: Epoch 0010 Iter 4700 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0072\n2024-03-31 21:40:27,729 - root - INFO - KG Training: Epoch 0010 Iter 4750 / 5442 | Time 0.1s | Iter Loss 0.0060 | Iter Mean Loss 0.0072\n2024-03-31 21:40:33,395 - root - INFO - KG Training: Epoch 0010 Iter 4800 / 5442 | Time 0.1s | Iter Loss 0.0037 | Iter Mean Loss 0.0072\n2024-03-31 21:40:38,824 - root - INFO - KG Training: Epoch 0010 Iter 4850 / 5442 | Time 0.1s | Iter Loss 0.0122 | Iter Mean Loss 0.0072\n2024-03-31 21:40:44,503 - root - INFO - KG Training: Epoch 0010 Iter 4900 / 5442 | Time 0.1s | Iter Loss 0.0121 | Iter Mean Loss 0.0072\n2024-03-31 21:40:50,284 - root - INFO - KG Training: Epoch 0010 Iter 4950 / 5442 | Time 0.2s | Iter Loss 0.0042 | Iter Mean Loss 0.0072\n2024-03-31 21:40:55,995 - root - INFO - KG Training: Epoch 0010 Iter 5000 / 5442 | Time 0.1s | Iter Loss 0.0075 | Iter Mean Loss 0.0072\n2024-03-31 21:41:01,683 - root - INFO - KG Training: Epoch 0010 Iter 5050 / 5442 | Time 0.1s | Iter Loss 0.0096 | Iter Mean Loss 0.0072\n2024-03-31 21:41:07,390 - root - INFO - KG Training: Epoch 0010 Iter 5100 / 5442 | Time 0.1s | Iter Loss 0.0086 | Iter Mean Loss 0.0072\n2024-03-31 21:41:13,151 - root - INFO - KG Training: Epoch 0010 Iter 5150 / 5442 | Time 0.1s | Iter Loss 0.0049 | Iter Mean Loss 0.0072\n2024-03-31 21:41:18,745 - root - INFO - KG Training: Epoch 0010 Iter 5200 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0072\n2024-03-31 21:41:24,416 - root - INFO - KG Training: Epoch 0010 Iter 5250 / 5442 | Time 0.1s | Iter Loss 0.0048 | Iter Mean Loss 0.0072\n2024-03-31 21:41:29,939 - root - INFO - KG Training: Epoch 0010 Iter 5300 / 5442 | Time 0.1s | Iter Loss 0.0100 | Iter Mean Loss 0.0072\n2024-03-31 21:41:35,717 - root - INFO - KG Training: Epoch 0010 Iter 5350 / 5442 | Time 0.1s | Iter Loss 0.0068 | Iter Mean Loss 0.0072\n2024-03-31 21:41:41,311 - root - INFO - KG Training: Epoch 0010 Iter 5400 / 5442 | Time 0.1s | Iter Loss 0.0079 | Iter Mean Loss 0.0072\n2024-03-31 21:41:46,193 - root - INFO - KG Training: Epoch 0010 Total Iter 5442 | Total Time 603.1s | Iter Mean Loss 0.0072\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([354])\ntorch.Size([30388])\ntorch.Size([521])\ntorch.Size([1853])\ntorch.Size([5539469])\ntorch.Size([5539469])\n2024-03-31 21:41:48,789 - root - INFO - Update Attention: Epoch 0010 | Total Time 2.6s\n2024-03-31 21:41:48,790 - root - INFO - CF + KG Training: Epoch 0010 | Total Time 2567.6s\nEvaluating Iteration: 100%|███████████████████| 712/712 [02:11<00:00,  5.41it/s]\n2024-03-31 21:44:00,528 - root - INFO - CF Evaluation: Epoch 0010 | Total Time 131.7s | Precision [0.0290, 0.0170], Recall [0.1862, 0.4807], NDCG [0.1046, 0.1826]\n2024-03-31 21:44:01,028 - root - INFO - Save model on epoch 0010!\n2024-03-31 21:44:01,034 - root - INFO - Best CF Evaluation: Epoch 0010 | Precision [0.0290, 0.0170], Recall [0.1862, 0.4807], NDCG [0.1046, 0.1826]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**FM**\n","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:49:04.298941Z","iopub.execute_input":"2024-03-31T09:49:04.299201Z","iopub.status.idle":"2024-03-31T09:49:04.309072Z","shell.execute_reply.started":"2024-03-31T09:49:04.299178Z","shell.execute_reply":"2024-03-31T09:49:04.308073Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!python /kaggle/working/sample/KGAT-pytorch/main_nfm.py --data_dir \"/kaggle/input/\" \\\n                    --data_name mooccubex \\\n                    --use_pretrain 0 \\\n                    --n_epoch 10 \\\n                    --test_batch_size 128 \\\n                    --print_every 50 \\\n                    --evaluate_every 1 \\\n                    --model_type \"fm\"","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:49:04.310169Z","iopub.execute_input":"2024-03-31T09:49:04.310444Z","iopub.status.idle":"2024-03-31T09:49:26.358154Z","shell.execute_reply.started":"2024-03-31T09:49:04.310413Z","shell.execute_reply":"2024-03-31T09:49:26.357167Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"All logs will be saved to trained_model/NFM/mooccubex/fm_embed-dim64_64-32-16_lr0.0001_pretrain0/log0.log\n2024-03-31 09:49:10,578 - root - INFO - Namespace(seed=2019, model_type='fm', data_name='mooccubex', data_dir='/kaggle/input/', use_pretrain=0, pretrain_embedding_dir='datasets/pretrain/', pretrain_model_path='trained_model/model.pth', embed_dim=64, hidden_dim_list='[64, 32, 16]', mess_dropout='[0.1, 0.1, 0.1]', l2loss_lambda=1e-05, train_batch_size=1024, test_batch_size=128, test_cores=32, lr=0.0001, n_epoch=10, stopping_steps=10, print_every=50, evaluate_every=1, Ks='[20, 40, 60, 80, 100]', save_dir='trained_model/NFM/mooccubex/fm_embed-dim64_64-32-16_lr0.0001_pretrain0/')\n2024-03-31 09:49:21,418 - root - INFO - n_users:              373350\n2024-03-31 09:49:21,418 - root - INFO - n_items:              3118\n2024-03-31 09:49:21,418 - root - INFO - n_entities:           12722\n2024-03-31 09:49:21,418 - root - INFO - n_users_entities:     386072\n2024-03-31 09:49:21,418 - root - INFO - n_cf_train:           6569115\n2024-03-31 09:49:21,418 - root - INFO - n_cf_test:            901717\n2024-03-31 09:49:21,418 - root - INFO - shape of user_matrix: (373350, 373350)\n2024-03-31 09:49:21,418 - root - INFO - shape of feat_matrix: (3118, 12722)\n2024-03-31 09:49:21,865 - root - INFO - NFM(\n  (linear): Linear(in_features=386072, out_features=1, bias=True)\n  (h): Linear(in_features=64, out_features=1, bias=False)\n)\n2024-03-31 09:49:23,227 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.\n/kaggle/working/sample/KGAT-pytorch/data_loader/loader_nfm.py:60: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:605.)\n  return torch.sparse.FloatTensor(i, v, torch.Size(shape))\nTraceback (most recent call last):\n  File \"/kaggle/working/sample/KGAT-pytorch/main_nfm.py\", line 272, in <module>\n    train(args)\n  File \"/kaggle/working/sample/KGAT-pytorch/main_nfm.py\", line 182, in train\n    batch_loss = model(pos_feature_values, neg_feature_values, is_train=True)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/sample/KGAT-pytorch/model/NFM.py\", line 141, in forward\n    return self.calc_loss(*input)\n  File \"/kaggle/working/sample/KGAT-pytorch/model/NFM.py\", line 128, in calc_loss\n    pos_scores = self.calc_score(pos_feature_values)            # (batch_size)\n  File \"/kaggle/working/sample/KGAT-pytorch/model/NFM.py\", line 96, in calc_score\n    chunk = feature_values[start_idx:end_idx, :]  # (chunk_size, n_features)\nNotImplementedError: Could not run 'aten::as_strided' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::as_strided' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterCPU.cpp:31188 [kernel]\nCUDA: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44143 [kernel]\nMeta: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26829 [kernel]\nQuantizedCPU: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:944 [kernel]\nQuantizedCUDA: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:459 [kernel]\nBackendSelect: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:21905 [kernel]\nNamed: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/native/NegateFallback.cpp:23 [kernel]\nZeroTensor: registered at /usr/local/src/pytorch/build/aten/src/ATen/RegisterZeroTensor.cpp:161 [kernel]\nADInplaceOrView: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4733 [kernel]\nAutogradOther: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradCPU: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradCUDA: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradHIP: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradXLA: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradMPS: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradIPU: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradXPU: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradHPU: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradVE: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradLazy: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradMTIA: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradPrivateUse1: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradPrivateUse2: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradPrivateUse3: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradMeta: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nAutogradNestedTensor: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:16838 [autograd kernel]\nTracer: registered at /usr/local/src/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16725 [kernel]\nAutocastCPU: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:714 [kernel]\nFuncTorchVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /usr/local/src/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at /usr/local/src/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /usr/local/src/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /usr/local/src/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}